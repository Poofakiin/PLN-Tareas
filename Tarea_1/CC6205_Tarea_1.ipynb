{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AxrkZWMLZB8z"
   },
   "source": [
    "# Tarea 1: Introducci√≥n, Vector Space Models, Information Retrieval y Language Models</h1>\n",
    "**Procesamiento de Lenguaje Natural (CC6205-1 - Oto√±o 2024)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b97b4IJjZGxM"
   },
   "source": [
    "## Tarjeta de identificaci√≥n\n",
    "\n",
    "**Nombres:** ```Diego Acevedo, Benjam√≠n Aguilar y Luis Montero```\n",
    "\n",
    "**Fecha l√≠mite de entrega üìÜ:** 10/04.\n",
    "\n",
    "**Tiempo estimado de dedicaci√≥n:** 4 horas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKcZMFlmZ3b9"
   },
   "source": [
    "## Instrucciones\n",
    "Bienvenid@s a la primera tarea en el curso de Natural Language Processing (NLP). Esta tarea tiene como objetivo evaluar los contenidos te√≥ricos de las primeras semanas de clases, enfocado principalmente en **Information Retrieval (IR)**, **Vector Space Models** y **Language Models**. Si a√∫n no has visto las clases, se recomienda visitar los links de las referencias.\n",
    "\n",
    "La tarea consta de una parte te√≥rica que busca evaluar conceptos vistos en clases. Seguido por una parte pr√°ctica con el f√≠n de introducirlos a la programaci√≥n en Python enfocada en NLP.\n",
    "\n",
    "* La tarea es en **grupo** (maximo hasta 3 personas).\n",
    "* La entrega es a trav√©s de u-cursos a m√°s tardar el d√≠a estipulado arriba. No se aceptan atrasos.\n",
    "* El formato de entrega es este mismo Jupyter Notebook.\n",
    "* Al momento de la revisi√≥n su c√≥digo ser√° ejecutado. Por favor verifiquen que su entrega no tenga errores de compilaci√≥n.\n",
    "* Completar la tarjeta de identificaci√≥n. Sin ella no podr√° tener nota."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnTrhOKraAw2"
   },
   "source": [
    "## Material de referencia\n",
    "\n",
    "Diapositivas del curso üìÑ\n",
    "    \n",
    "- [Introducci√≥n al curso](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-introduction.pdf)\n",
    "- [Vector Space Model / Information Retrieval](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-IR.pdf)    \n",
    "- [Probabilistic Language Models](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-PLM.pdf)\n",
    "\n",
    "Videos del curso üì∫\n",
    "- Introducci√≥n  [Parte 1](https://www.youtube.com/watch?v=HEKTNOttGvU)  [Parte 2](https://www.youtube.com/watch?v=P8cwnI-f-Kg)\n",
    "\n",
    "- Information Retrieval [Parte 1](https://www.youtube.com/watch?v=FXIVClF370w&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=3) [Parte 2](https://www.youtube.com/watch?v=f8nG1EMmPZk&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=3)\n",
    "- Probabilistic Language Models [Parte 1](https://www.youtube.com/watch?v=9E2jJ6kcb4Y&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=3) [Parte 2](https://www.youtube.com/watch?v=ZWqbEQXLra0&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=5) [Parte 3](https://www.youtube.com/watch?v=tsumFqwFlaA&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=6) [Parte 4](https://www.youtube.com/watch?v=s3TWdv4sqkg&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7w4BT1qmChV"
   },
   "source": [
    "## P1. Tokenizaci√≥n\n",
    "\n",
    "En el primer ejercicio veremos la dificultad de tokenizar textos no estructurados, destacando la importancia de tener librer√≠as que realicen este trabajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qlgSZrB2oe1H",
    "outputId": "127d1932-3acd-4d02-ee91-2602ca1c7069"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# En caso de desarrollar la tarea desde colab, con el siguiente c√≥digo podemos cargar los archivos desde drive:\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\", force_remount=True)\n",
    "    path = '/content/drive/MyDrive/NLP 2024/oh_algoritmo.txt'\n",
    "except:\n",
    "    print('Ignorando conexi√≥n drive-colab')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RCKFrnZcoy2F"
   },
   "source": [
    "Ejecute el c√≥digo a continuaci√≥n para cargar el ejemplo. Recuerde realizar la modificaci√≥n al directorio en caso que el archivo no se encuentre en el mismo directorio del Jupyter Notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k9CteGwEmDKw",
    "outputId": "02b821c5-46aa-4564-abd1-7b691a10d527"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Letra de \"¬°Oh, Algoritmo!\" ft. Nora Erez]\n",
      "\n",
      "[Refr√°n: Jorge Drexler]\n",
      "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
      "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
      "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
      "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
      "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
      "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
      "\n",
      "[Estribillo: Jorge Drexler]\n",
      "Dime qu√© debo cantar\n",
      "Oh, algoritmo\n",
      "S√© que lo sabes mejor\n",
      "Incluso que yo mismo\n",
      "\n",
      "[Verso 1: Nora Erez]\n",
      "Wait, what's that money that you spent?\n",
      "What's that sitting on your plate?\n",
      "Do you want what you've been fed?\n",
      "Are you the fish or bait?\n",
      "Mmm, I'm on the top of the roof and I feel like a jail\n",
      "Rather not pay the bail\n",
      "To dangerous people with blood on their faces\n",
      "So I'm sharing a cell with the masses\n",
      "The underground always strive for the main\n",
      "Streaming like Grande's big-ass ring\n",
      "Screaming: I'll write you out my will\n",
      "Conscious is free, but not the will\n",
      "Conscious is free, but not the will\n",
      "You might also like\n",
      "Amor al Arte\n",
      "Jorge Drexler\n",
      "Tinta y Tiempo\n",
      "Jorge Drexler\n",
      "Asilo\n",
      "Jorge Drexler\n",
      "[Pre-Estribillo: Nora Erez]\n",
      "So if you want me to want what I believe that I want\n",
      "Can I choose to quit?\n",
      "\n",
      "[Estribillo: Jorge Drexler]\n",
      "Dime qu√© debo cantar\n",
      "Oh, algoritmo\n",
      "S√© que lo sabes mejor\n",
      "Incluso que yo mismo\n",
      "\n",
      "[Verso 2: Jorge Drexler]\n",
      "Por ejemplo, esta canci√≥n\n",
      "¬øQu√© algoritmo la pari√≥?\n",
      "Me pregunto si fui yo\n",
      "¬øLa elegiste o te eligi√≥?\n",
      "\n",
      "[Verso 3: Jorge Drexler]\n",
      "Dios era la letra chica al final del papel\n",
      "Ya no contamos con √âl\n",
      "Fin de la Luna de miel\n",
      "Y el libre albedr√≠o es un cauce vac√≠o\n",
      "Un barco que no tiene r√≠o\n",
      "Ni timonel\n",
      "\n",
      "[Verso 4: Jorge Drexler]\n",
      "Todos aplauden, t√∫ tambi√©n\n",
      "Pero no queda claro qui√©n\n",
      "Tiene del mango a la sart√©n\n",
      "Del sacrificio\n",
      "Piel o silicio\n",
      "Y el precipicio\n",
      "Dice: Ven, ven, ven\n",
      "[Refr√°n: Jorge Drexler]\n",
      "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
      "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
      "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
      "(Dime qu√© debo cantar)\n",
      "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
      "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
      "(Oh, algoritmo)\n",
      "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
      "(S√© que lo sabes mejor)\n",
      "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
      "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
      "(Incluso que yo mismo)\n",
      "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
      "(Dime qu√© debo cantar)\n",
      "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
      "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
      "(Oh, algoritmo)\n",
      "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
      "(S√© que lo sabes mejor)\n",
      "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
      "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
      "(Incluso que yo mismo)\n",
      "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
      "(Wow)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Abre el archivo en modo lectura (\"r\")\n",
    "    with open(\"/content/drive/MyDrive/NLP 2024/oh_algoritmo.txt\", \"r\") as archivo:\n",
    "        # Lee el contenido del archivo\n",
    "        texto = archivo.read()\n",
    "        # Imprime el contenido\n",
    "        print(texto)\n",
    "except FileNotFoundError:\n",
    "    print(\"El archivo no se encuentra.\")\n",
    "except Exception as e:\n",
    "    print(\"Ocurri√≥ un error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPSSO2kJoArL"
   },
   "source": [
    "Fuente: https://genius.com/Jorge-drexler-oh-algoritmo-lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-fG0hLbHg9dn"
   },
   "source": [
    "### Pregunta 1.a (0.25 puntos)\n",
    "\n",
    "Dise√±e una funci√≥n **`get_tokens()`** que reciba un texto y entregue una lista con sus tokens. Es libre de elegir la forma de tokenizar mientras no utilice librer√≠as con tokenizadores ya implementados. Puede utilizar la librer√≠a **re** importada para trabajar s√≠mbolos. Explique su razonamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5P7rk4VRm6Az"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qiRMkdjwazFT"
   },
   "outputs": [],
   "source": [
    "def get_tokens2(texto):\n",
    "  texto = re.sub('\\W+',' ',texto)\n",
    "  texto = re.sub('\\d+','',texto)\n",
    "  return texto.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TYMhKtWj9qY6"
   },
   "outputs": [],
   "source": [
    "def get_tokens(texto):\n",
    "    ### Aqu√≠ inicia tu c√≥digo ###\n",
    "    tokens = re.split(r'\\W+', texto)\n",
    "    return [token for token in tokens if token != '']\n",
    "    ### Aqu√≠ termina tu c√≥digo ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hDBZn4kOm7uH",
    "outputId": "dd04a2ca-1c66-4db5-e79e-4783a38b046b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Letra',\n",
       " 'de',\n",
       " 'Oh',\n",
       " 'Algoritmo',\n",
       " 'ft',\n",
       " 'Nora',\n",
       " 'Erez',\n",
       " 'Refr√°n',\n",
       " 'Jorge',\n",
       " 'Drexler',\n",
       " 'Qui√©n',\n",
       " 'quiere',\n",
       " 'que',\n",
       " 'yo',\n",
       " 'quiera',\n",
       " 'lo',\n",
       " 'que',\n",
       " 'creo',\n",
       " 'que',\n",
       " 'quiero',\n",
       " 'Qui√©n',\n",
       " 'quiere',\n",
       " 'que',\n",
       " 'yo',\n",
       " 'quiera',\n",
       " 'lo',\n",
       " 'que',\n",
       " 'creo',\n",
       " 'que',\n",
       " 'quiero',\n",
       " 'Qui√©n',\n",
       " 'quiere',\n",
       " 'que',\n",
       " 'yo',\n",
       " 'quiera',\n",
       " 'lo',\n",
       " 'que',\n",
       " 'creo',\n",
       " 'que',\n",
       " 'quiero',\n",
       " 'Qui√©n',\n",
       " 'quiere',\n",
       " 'que',\n",
       " 'yo',\n",
       " 'quiera',\n",
       " 'lo',\n",
       " 'que',\n",
       " 'creo',\n",
       " 'que',\n",
       " 'quiero',\n",
       " 'Qui√©n',\n",
       " 'quiere',\n",
       " 'que',\n",
       " 'yo',\n",
       " 'quiera',\n",
       " 'lo',\n",
       " 'que',\n",
       " 'creo',\n",
       " 'que',\n",
       " 'quiero',\n",
       " 'Qui√©n',\n",
       " 'quiere',\n",
       " 'que',\n",
       " 'yo',\n",
       " 'quiera',\n",
       " 'lo',\n",
       " 'que',\n",
       " 'creo',\n",
       " 'que',\n",
       " 'quiero',\n",
       " 'Estribillo',\n",
       " 'Jorge',\n",
       " 'Drexler',\n",
       " 'Dime',\n",
       " 'qu√©',\n",
       " 'debo',\n",
       " 'cantar',\n",
       " 'Oh',\n",
       " 'algoritmo',\n",
       " 'S√©',\n",
       " 'que',\n",
       " 'lo',\n",
       " 'sabes',\n",
       " 'mejor',\n",
       " 'Incluso',\n",
       " 'que',\n",
       " 'yo',\n",
       " 'mismo',\n",
       " 'Verso',\n",
       " '1',\n",
       " 'Nora',\n",
       " 'Erez',\n",
       " 'Wait',\n",
       " 'what',\n",
       " 's',\n",
       " 'that',\n",
       " 'money',\n",
       " 'that',\n",
       " 'you',\n",
       " 'spent',\n",
       " 'What',\n",
       " 's',\n",
       " 'that',\n",
       " 'sitting',\n",
       " 'on',\n",
       " 'your',\n",
       " 'plate',\n",
       " 'Do',\n",
       " 'you',\n",
       " 'want',\n",
       " 'what',\n",
       " 'you',\n",
       " 've',\n",
       " 'been',\n",
       " 'fed',\n",
       " 'Are',\n",
       " 'you',\n",
       " 'the',\n",
       " 'fish',\n",
       " 'or',\n",
       " 'bait',\n",
       " 'Mmm',\n",
       " 'I',\n",
       " 'm',\n",
       " 'on',\n",
       " 'the',\n",
       " 'top',\n",
       " 'of',\n",
       " 'the',\n",
       " 'roof',\n",
       " 'and',\n",
       " 'I',\n",
       " 'feel',\n",
       " 'like',\n",
       " 'a',\n",
       " 'jail',\n",
       " 'Rather',\n",
       " 'not',\n",
       " 'pay',\n",
       " 'the',\n",
       " 'bail',\n",
       " 'To',\n",
       " 'dangerous',\n",
       " 'people',\n",
       " 'with',\n",
       " 'blood',\n",
       " 'on',\n",
       " 'their',\n",
       " 'faces',\n",
       " 'So',\n",
       " 'I',\n",
       " 'm',\n",
       " 'sharing',\n",
       " 'a',\n",
       " 'cell',\n",
       " 'with',\n",
       " 'the',\n",
       " 'masses',\n",
       " 'The',\n",
       " 'underground',\n",
       " 'always',\n",
       " 'strive',\n",
       " 'for',\n",
       " 'the',\n",
       " 'main',\n",
       " 'Streaming',\n",
       " 'like',\n",
       " 'Grande',\n",
       " 's',\n",
       " 'big',\n",
       " 'ass',\n",
       " 'ring',\n",
       " 'Screaming',\n",
       " 'I',\n",
       " 'll',\n",
       " 'write',\n",
       " 'you',\n",
       " 'out',\n",
       " 'my',\n",
       " 'will',\n",
       " 'Conscious',\n",
       " 'is',\n",
       " 'free',\n",
       " 'but',\n",
       " 'not',\n",
       " 'the',\n",
       " 'will',\n",
       " 'Conscious',\n",
       " 'is',\n",
       " 'free',\n",
       " 'but',\n",
       " 'not',\n",
       " 'the',\n",
       " 'will',\n",
       " 'You',\n",
       " 'might',\n",
       " 'also',\n",
       " 'like',\n",
       " 'Amor',\n",
       " 'al',\n",
       " 'Arte',\n",
       " 'Jorge',\n",
       " 'Drexler',\n",
       " 'Tinta',\n",
       " 'y',\n",
       " 'Tiempo',\n",
       " 'Jorge',\n",
       " 'Drexler',\n",
       " 'Asilo',\n",
       " 'Jorge',\n",
       " 'Drexler',\n",
       " 'Pre',\n",
       " 'Estribillo',\n",
       " 'Nora',\n",
       " 'Erez',\n",
       " 'So',\n",
       " 'if',\n",
       " 'you',\n",
       " 'want',\n",
       " 'me',\n",
       " 'to',\n",
       " 'want',\n",
       " 'what',\n",
       " 'I',\n",
       " 'believe',\n",
       " 'that',\n",
       " 'I',\n",
       " 'want',\n",
       " 'Can',\n",
       " 'I',\n",
       " 'choose',\n",
       " 'to',\n",
       " 'quit',\n",
       " 'Estribillo',\n",
       " 'Jorge',\n",
       " 'Drexler',\n",
       " 'Dime',\n",
       " 'qu√©',\n",
       " 'debo',\n",
       " 'cantar',\n",
       " 'Oh',\n",
       " 'algoritmo',\n",
       " 'S√©',\n",
       " 'que',\n",
       " 'lo',\n",
       " 'sabes',\n",
       " 'mejor',\n",
       " 'Incluso',\n",
       " 'que',\n",
       " 'yo',\n",
       " 'mismo',\n",
       " 'Verso',\n",
       " '2',\n",
       " 'Jorge',\n",
       " 'Drexler',\n",
       " 'Por',\n",
       " 'ejemplo',\n",
       " 'esta',\n",
       " 'canci√≥n',\n",
       " 'Qu√©',\n",
       " 'algoritmo',\n",
       " 'la',\n",
       " 'pari√≥',\n",
       " 'Me',\n",
       " 'pregunto',\n",
       " 'si',\n",
       " 'fui',\n",
       " 'yo',\n",
       " 'La',\n",
       " 'elegiste',\n",
       " 'o',\n",
       " 'te',\n",
       " 'eligi√≥',\n",
       " 'Verso',\n",
       " '3',\n",
       " 'Jorge',\n",
       " 'Drexler',\n",
       " 'Dios',\n",
       " 'era',\n",
       " 'la',\n",
       " 'letra',\n",
       " 'chica',\n",
       " 'al',\n",
       " 'final',\n",
       " 'del',\n",
       " 'papel',\n",
       " 'Ya',\n",
       " 'no',\n",
       " 'contamos',\n",
       " 'con',\n",
       " '√âl',\n",
       " 'Fin',\n",
       " 'de',\n",
       " 'la',\n",
       " 'Luna',\n",
       " 'de',\n",
       " 'miel',\n",
       " 'Y',\n",
       " 'el',\n",
       " 'libre',\n",
       " 'albedr√≠o',\n",
       " 'es',\n",
       " 'un',\n",
       " 'cauce',\n",
       " 'vac√≠o',\n",
       " 'Un',\n",
       " 'barco',\n",
       " 'que',\n",
       " 'no',\n",
       " 'tiene',\n",
       " 'r√≠o',\n",
       " 'Ni',\n",
       " 'timonel',\n",
       " 'Verso',\n",
       " '4',\n",
       " 'Jorge',\n",
       " 'Drexler',\n",
       " 'Todos',\n",
       " 'aplauden',\n",
       " 't√∫',\n",
       " 'tambi√©n',\n",
       " 'Pero',\n",
       " 'no',\n",
       " 'queda',\n",
       " 'claro',\n",
       " 'qui√©n',\n",
       " 'Tiene',\n",
       " 'del',\n",
       " 'mango',\n",
       " 'a',\n",
       " 'la',\n",
       " 'sart√©n',\n",
       " 'Del',\n",
       " 'sacrificio',\n",
       " 'Piel',\n",
       " 'o',\n",
       " 'silicio',\n",
       " 'Y',\n",
       " 'el',\n",
       " 'precipicio',\n",
       " 'Dice',\n",
       " 'Ven',\n",
       " 'ven',\n",
       " 'ven',\n",
       " 'Refr√°n',\n",
       " 'Jorge',\n",
       " 'Drexler',\n",
       " 'Qui√©n',\n",
       " 'quiere',\n",
       " 'que',\n",
       " 'yo',\n",
       " 'quiera',\n",
       " 'lo',\n",
       " 'que',\n",
       " 'creo',\n",
       " 'que',\n",
       " 'quiero',\n",
       " 'Qui√©n',\n",
       " 'quiere',\n",
       " 'que',\n",
       " 'yo',\n",
       " 'quiera',\n",
       " 'lo',\n",
       " 'que',\n",
       " 'creo',\n",
       " 'que',\n",
       " 'quiero',\n",
       " 'Qui√©n',\n",
       " 'quiere',\n",
       " 'que',\n",
       " 'yo',\n",
       " 'quiera',\n",
       " 'lo',\n",
       " 'que',\n",
       " 'creo',\n",
       " 'que',\n",
       " 'quiero',\n",
       " 'Dime',\n",
       " 'qu√©',\n",
       " 'debo',\n",
       " 'cantar',\n",
       " 'Qui√©n',\n",
       " 'quiere',\n",
       " 'que',\n",
       " 'yo',\n",
       " 'quiera',\n",
       " 'lo',\n",
       " 'que',\n",
       " 'creo',\n",
       " 'que',\n",
       " 'quiero',\n",
       " 'Qui√©n',\n",
       " 'quiere',\n",
       " 'que',\n",
       " 'yo',\n",
       " 'quiera',\n",
       " 'lo',\n",
       " 'que',\n",
       " 'creo',\n",
       " 'que',\n",
       " 'quiero',\n",
       " 'Oh',\n",
       " 'algoritmo',\n",
       " 'Qui√©n',\n",
       " 'quiere',\n",
       " 'que',\n",
       " 'yo',\n",
       " 'quiera',\n",
       " 'lo',\n",
       " 'que',\n",
       " 'creo',\n",
       " 'que',\n",
       " 'quiero',\n",
       " 'S√©',\n",
       " 'que',\n",
       " 'lo',\n",
       " 'sabes',\n",
       " 'mejor',\n",
       " 'Qui√©n',\n",
       " 'quiere',\n",
       " 'que',\n",
       " 'yo',\n",
       " 'quiera',\n",
       " 'lo',\n",
       " 'que',\n",
       " 'creo',\n",
       " 'que',\n",
       " 'quiero',\n",
       " 'Qui√©n',\n",
       " 'quiere',\n",
       " 'que',\n",
       " 'yo',\n",
       " 'quiera',\n",
       " 'lo',\n",
       " 'que',\n",
       " 'creo',\n",
       " 'que',\n",
       " 'quiero',\n",
       " 'Incluso',\n",
       " 'que',\n",
       " 'yo',\n",
       " 'mismo',\n",
       " 'Qui√©n',\n",
       " 'quiere',\n",
       " 'que',\n",
       " 'yo',\n",
       " 'quiera',\n",
       " 'lo',\n",
       " 'que',\n",
       " 'creo',\n",
       " 'que',\n",
       " 'quiero',\n",
       " 'Dime',\n",
       " 'qu√©',\n",
       " 'debo',\n",
       " 'cantar',\n",
       " 'Qui√©n',\n",
       " 'quiere',\n",
       " 'que',\n",
       " 'yo',\n",
       " 'quiera',\n",
       " 'lo',\n",
       " 'que',\n",
       " 'creo',\n",
       " 'que',\n",
       " 'quiero',\n",
       " 'Qui√©n',\n",
       " 'quiere',\n",
       " 'que',\n",
       " 'yo',\n",
       " 'quiera',\n",
       " 'lo',\n",
       " 'que',\n",
       " 'creo',\n",
       " 'que',\n",
       " 'quiero',\n",
       " 'Oh',\n",
       " 'algoritmo',\n",
       " 'Qui√©n',\n",
       " 'quiere',\n",
       " 'que',\n",
       " 'yo',\n",
       " 'quiera',\n",
       " 'lo',\n",
       " 'que',\n",
       " 'creo',\n",
       " 'que',\n",
       " 'quiero',\n",
       " 'S√©',\n",
       " 'que',\n",
       " 'lo',\n",
       " 'sabes',\n",
       " 'mejor',\n",
       " 'Qui√©n',\n",
       " 'quiere',\n",
       " 'que',\n",
       " 'yo',\n",
       " 'quiera',\n",
       " 'lo',\n",
       " 'que',\n",
       " 'creo',\n",
       " 'que',\n",
       " 'quiero',\n",
       " 'Qui√©n',\n",
       " 'quiere',\n",
       " 'que',\n",
       " 'yo',\n",
       " 'quiera',\n",
       " 'lo',\n",
       " 'que',\n",
       " 'creo',\n",
       " 'que',\n",
       " 'quiero',\n",
       " 'Incluso',\n",
       " 'que',\n",
       " 'yo',\n",
       " 'mismo',\n",
       " 'Qui√©n',\n",
       " 'quiere',\n",
       " 'que',\n",
       " 'yo',\n",
       " 'quiera',\n",
       " 'lo',\n",
       " 'que',\n",
       " 'creo',\n",
       " 'que',\n",
       " 'quiero',\n",
       " 'Wow']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = get_tokens(texto)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CpZKljrotLa"
   },
   "source": [
    "### Pregunta 1.b (0.25 puntos)\n",
    "Explique su implementaci√≥n aqu√≠:\n",
    "> La implementaci√≥n de la funci√≥n mediante el m√©todo **sub()** de la librer√≠a de expresiones regulares (**re**), \"limpia\" el texto o corpus (documento -cadena de palabras) de aquellos elementos gr√°ficos presentes (par√©ntesis por ejemplo), de elementos contextuales del lenguaje que son propios del habla (inflexiones relacionadas a signos de exclamaci√≥n, interrogaci√≥n) y de redacci√≥n del texto (puntuaci√≥n). Mediante el m√©todo **split()** el texto ya limpio de los elementos indicados, es llevado a min√∫scula y luego separado en las cadenas de texto que lo componen (palabras). La funci√≥n retorna un documento tokenizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIwAKWZvofEp"
   },
   "source": [
    "Implementaci√≥n con la libreria NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_GR2Z0lnnPB9",
    "outputId": "b220e67a-f13d-497a-9dbe-3ad8a4395162"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'Letra', 'de', '\"¬°', 'Oh', ',', 'Algoritmo', '!\"', 'ft', '.', 'Nora', 'Erez', ']', '[', 'Refr√°n', ':', 'Jorge', 'Drexler', ']', '¬ø', 'Qui√©n', 'quiere', 'que', 'yo', 'quiera', 'lo', 'que', 'creo', 'que', 'quiero', '?', '¬ø', 'Qui√©n', 'quiere', 'que', 'yo', 'quiera', 'lo', 'que', 'creo', 'que', 'quiero', '?', '¬ø', 'Qui√©n', 'quiere', 'que', 'yo', 'quiera', 'lo', 'que', 'creo', 'que', 'quiero', '?', '¬ø', 'Qui√©n', 'quiere', 'que', 'yo', 'quiera', 'lo', 'que', 'creo', 'que', 'quiero', '?', '¬ø', 'Qui√©n', 'quiere', 'que', 'yo', 'quiera', 'lo', 'que', 'creo', 'que', 'quiero', '?', '¬ø', 'Qui√©n', 'quiere', 'que', 'yo', 'quiera', 'lo', 'que', 'creo', 'que', 'quiero', '?', '[', 'Estribillo', ':', 'Jorge', 'Drexler', ']', 'Dime', 'qu√©', 'debo', 'cantar', 'Oh', ',', 'algoritmo', 'S√©', 'que', 'lo', 'sabes', 'mejor', 'Incluso', 'que', 'yo', 'mismo', '[', 'Verso', '1', ':', 'Nora', 'Erez', ']', 'Wait', ',', 'what', \"'\", 's', 'that', 'money', 'that', 'you', 'spent', '?', 'What', \"'\", 's', 'that', 'sitting', 'on', 'your', 'plate', '?', 'Do', 'you', 'want', 'what', 'you', \"'\", 've', 'been', 'fed', '?', 'Are', 'you', 'the', 'fish', 'or', 'bait', '?', 'Mmm', ',', 'I', \"'\", 'm', 'on', 'the', 'top', 'of', 'the', 'roof', 'and', 'I', 'feel', 'like', 'a', 'jail', 'Rather', 'not', 'pay', 'the', 'bail', 'To', 'dangerous', 'people', 'with', 'blood', 'on', 'their', 'faces', 'So', 'I', \"'\", 'm', 'sharing', 'a', 'cell', 'with', 'the', 'masses', 'The', 'underground', 'always', 'strive', 'for', 'the', 'main', 'Streaming', 'like', 'Grande', \"'\", 's', 'big', '-', 'ass', 'ring', 'Screaming', ':', 'I', \"'\", 'll', 'write', 'you', 'out', 'my', 'will', 'Conscious', 'is', 'free', ',', 'but', 'not', 'the', 'will', 'Conscious', 'is', 'free', ',', 'but', 'not', 'the', 'will', 'You', 'might', 'also', 'like', 'Amor', 'al', 'Arte', 'Jorge', 'Drexler', 'Tinta', 'y', 'Tiempo', 'Jorge', 'Drexler', 'Asilo', 'Jorge', 'Drexler', '[', 'Pre', '-', 'Estribillo', ':', 'Nora', 'Erez', ']', 'So', 'if', 'you', 'want', 'me', 'to', 'want', 'what', 'I', 'believe', 'that', 'I', 'want', 'Can', 'I', 'choose', 'to', 'quit', '?', '[', 'Estribillo', ':', 'Jorge', 'Drexler', ']', 'Dime', 'qu√©', 'debo', 'cantar', 'Oh', ',', 'algoritmo', 'S√©', 'que', 'lo', 'sabes', 'mejor', 'Incluso', 'que', 'yo', 'mismo', '[', 'Verso', '2', ':', 'Jorge', 'Drexler', ']', 'Por', 'ejemplo', ',', 'esta', 'canci√≥n', '¬ø', 'Qu√©', 'algoritmo', 'la', 'pari√≥', '?', 'Me', 'pregunto', 'si', 'fui', 'yo', '¬ø', 'La', 'elegiste', 'o', 'te', 'eligi√≥', '?', '[', 'Verso', '3', ':', 'Jorge', 'Drexler', ']', 'Dios', 'era', 'la', 'letra', 'chica', 'al', 'final', 'del', 'papel', 'Ya', 'no', 'contamos', 'con', '√âl', 'Fin', 'de', 'la', 'Luna', 'de', 'miel', 'Y', 'el', 'libre', 'albedr√≠o', 'es', 'un', 'cauce', 'vac√≠o', 'Un', 'barco', 'que', 'no', 'tiene', 'r√≠o', 'Ni', 'timonel', '[', 'Verso', '4', ':', 'Jorge', 'Drexler', ']', 'Todos', 'aplauden', ',', 't√∫', 'tambi√©n', 'Pero', 'no', 'queda', 'claro', 'qui√©n', 'Tiene', 'del', 'mango', 'a', 'la', 'sart√©n', 'Del', 'sacrificio', 'Piel', 'o', 'silicio', 'Y', 'el', 'precipicio', 'Dice', ':', 'Ven', ',', 'ven', ',', 'ven', '[', 'Refr√°n', ':', 'Jorge', 'Drexler', ']', '¬ø', 'Qui√©n', 'quiere', 'que', 'yo', 'quiera', 'lo', 'que', 'creo', 'que', 'quiero', '?', '¬ø', 'Qui√©n', 'quiere', 'que', 'yo', 'quiera', 'lo', 'que', 'creo', 'que', 'quiero', '?', '¬ø', 'Qui√©n', 'quiere', 'que', 'yo', 'quiera', 'lo', 'que', 'creo', 'que', 'quiero', '?', '(', 'Dime', 'qu√©', 'debo', 'cantar', ')', '¬ø', 'Qui√©n', 'quiere', 'que', 'yo', 'quiera', 'lo', 'que', 'creo', 'que', 'quiero', '?', '¬ø', 'Qui√©n', 'quiere', 'que', 'yo', 'quiera', 'lo', 'que', 'creo', 'que', 'quiero', '?', '(', 'Oh', ',', 'algoritmo', ')', '¬ø', 'Qui√©n', 'quiere', 'que', 'yo', 'quiera', 'lo', 'que', 'creo', 'que', 'quiero', '?', '(', 'S√©', 'que', 'lo', 'sabes', 'mejor', ')', '¬ø', 'Qui√©n', 'quiere', 'que', 'yo', 'quiera', 'lo', 'que', 'creo', 'que', 'quiero', '?', '¬ø', 'Qui√©n', 'quiere', 'que', 'yo', 'quiera', 'lo', 'que', 'creo', 'que', 'quiero', '?', '(', 'Incluso', 'que', 'yo', 'mismo', ')', '¬ø', 'Qui√©n', 'quiere', 'que', 'yo', 'quiera', 'lo', 'que', 'creo', 'que', 'quiero', '?', '(', 'Dime', 'qu√©', 'debo', 'cantar', ')', '¬ø', 'Qui√©n', 'quiere', 'que', 'yo', 'quiera', 'lo', 'que', 'creo', 'que', 'quiero', '?', '¬ø', 'Qui√©n', 'quiere', 'que', 'yo', 'quiera', 'lo', 'que', 'creo', 'que', 'quiero', '?', '(', 'Oh', ',', 'algoritmo', ')', '¬ø', 'Qui√©n', 'quiere', 'que', 'yo', 'quiera', 'lo', 'que', 'creo', 'que', 'quiero', '?', '(', 'S√©', 'que', 'lo', 'sabes', 'mejor', ')', '¬ø', 'Qui√©n', 'quiere', 'que', 'yo', 'quiera', 'lo', 'que', 'creo', 'que', 'quiero', '?', '¬ø', 'Qui√©n', 'quiere', 'que', 'yo', 'quiera', 'lo', 'que', 'creo', 'que', 'quiero', '?', '(', 'Incluso', 'que', 'yo', 'mismo', ')', '¬ø', 'Qui√©n', 'quiere', 'que', 'yo', 'quiera', 'lo', 'que', 'creo', 'que', 'quiero', '?', '(', 'Wow', ')']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "nltk_tokens = wordpunct_tokenize(texto)\n",
    "print(nltk_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "so3P4OeGn-qo"
   },
   "source": [
    "### Pregunta 1.c (0.5 puntos)\n",
    "¬øQu√© diferencias y similitudes encontrase al comparar la funci√≥n de tokenizaci√≥n creada manualmente por ti contra la implementaci√≥n de NLTK, al tokenizar la letra de la canci√≥n \"Oh, algoritmo\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E12BZ29JoFCp"
   },
   "source": [
    "**R.** La funci√≥n de la librer√≠a NLTK si bien tokeniza el texto entregado, no elimina directamente expresiones de contexto o significado del texto (expresiones de exclamaci√≥n, interrogaci√≥n y otras como par√©ntesis o puntuaci√≥n), u otros elementos presentes en el texto (como por ejemplo, n√∫meros)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmUULnB6hWcl"
   },
   "source": [
    "## P2. Stemming y Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LskhxOLdpT9q"
   },
   "source": [
    "En esta secci√≥n debera implementar funciones de stemming y stopwords basado en lo visto en clase. En la siguiente celda tiene el corpus que usara en esta secci√≥n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "hj07_CmwhYxk"
   },
   "outputs": [],
   "source": [
    "# Corpus en espa√±ol\n",
    "corpus_espanol = [\n",
    "    \"¬øQui√©n quiere que yo quiera lo que creo que quiero?\",\n",
    "    \"Dime qu√© debo cantar\",\n",
    "    \"S√© que lo sabes mejor\"\n",
    "]\n",
    "\n",
    "# Corpus en ingl√©s\n",
    "corpus_ingles = [\n",
    "    \"What's that sitting on your plate?\",\n",
    "    \"Do you want what you've been fed?\",\n",
    "    \"Are you the fish or bait?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xRyOVbVWwJ5"
   },
   "source": [
    "### Pregunta 2.a (0.5 puntos)\n",
    "Implemente una funci√≥n **`get_vocab()`** que extraiga los tokens de un corpus. Puede utilizar la funci√≥n de la secci√≥n anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "F-727zL3ptDZ"
   },
   "outputs": [],
   "source": [
    "def get_vocab(corpus):\n",
    "  corpus = \" \".join(corpus)\n",
    "  return list(set(get_tokens(corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ciYGx92lPmNI",
    "outputId": "001bfc2e-e8b2-4a04-921f-6e940f32701a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cantar', 'Qui√©n', 'yo', 'lo', 'debo', 'mejor', 'S√©', 'quiera', 'creo', 'quiere', 'quiero', 'que', 'qu√©', 'Dime', 'sabes']\n"
     ]
    }
   ],
   "source": [
    "vocab_esp = get_vocab(corpus_espanol)\n",
    "print(vocab_esp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ge2cPS7fqYXy",
    "outputId": "470b0169-45d7-40c5-f15d-221f4802c702"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_espanol = get_vocab(corpus_espanol)\n",
    "len(vocab_espanol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lCFtzHUbzJqt"
   },
   "source": [
    "Resultado esperado (el orden puede variar):\n",
    "```\n",
    "['yo', 'debo', 'creo', 'Dime', 'lo', 'cantar', 'mejor', 'S√©', 'que', 'quiere', 'quiero', 'sabes', 'Qui√©n', 'quiera', 'qu√©']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0BHkK25_eR1F",
    "outputId": "d9648387-cf7c-4d27-d0a4-22bf4f8d1343"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plate', 'fed', 'Are', 'what', 's', 'want', 'bait', 'that', 've', 'fish', 'been', 'Do', 'on', 'you', 'your', 'What', 'or', 'sitting', 'the']\n"
     ]
    }
   ],
   "source": [
    "vocab_ing = get_vocab(corpus_ingles)\n",
    "print(vocab_ing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UnbjHDlqvKmP",
    "outputId": "11549be6-ab96-4f63-d6e8-3b879fd67554"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_ing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "apRK_d8uqlSm"
   },
   "source": [
    "vocab_ingles = get_vocab(corpus_ingles)\n",
    "vocab_ingles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvWMUQq5zPP8"
   },
   "source": [
    "Resultado esperado:\n",
    "```\n",
    "['fed', 'been', 'or', 'want', 'plate', 'the', 've', 'your', 's', 'you', 'what', 'Are', 'bait', 'What', 'fish', 'that', 'sitting', 'Do', 'on']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8FVjU3cAzDkw"
   },
   "source": [
    "### Pregunta 2.b (0.5 puntos)\n",
    "Ahora dise√±e reglas que usted estime convenientes tanto de **Stemming** como de **Stopwords**. Implemente una funci√≥n que reciba una lista con los elementos del vocabulario, le aplique sus reglas y devuelva el vocabulario preprocesado. Explique las reglas de stemming y elecci√≥n de stopwords:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZSeU-rDYbI1"
   },
   "source": [
    "Explique sus reglas aqu√≠:\n",
    "\n",
    "Para las STOPWORDS se utiliz√≥ como primer criterio, la frecuencia de las palabras presentes en los corpus. De esta forma, las palabras de mayor frecuencias fueron eliminadas. Este primer criterio hace referencia a la ley de Zipf. Como segundo criterio se utiliz√≥ la extensi√≥n de las palabras. En castellano (y en ingl√©s), muchas palabras de extensi√≥n reducida, adem√°s de ser de uso frecuente (lo que habla de poco contenido espec√≠fico), corresponden a art√≠culos, ilativos y proposiciones.\n",
    "\n",
    "En el caso del STEMMING, se usaron reglas diferentes, seg√∫n el idioma. Para el CASTELLANO, se suprimieron las vocales en caso que las palabras terminasen en vocal (como una forma de neutralizar el g√©nero); la letra 'S' en posici√≥n final (como una forma de neutralizar la referencia a la cantidad), y la terminaci√≥n 'AR' en el caso de los verbos terminados en dichas letras.\n",
    "\n",
    "En el caso del INGL√âS, el STEMMING definido suprimi√≥ las vocales y la letra 'R' en posiciones finales; la terminaci√≥n 'ER' que hace referencia a los sujetos agentes (ej: singer, player, runner, walker, etc.), y la terminaci√≥n 'ING' que es la terminaci√≥n en ese idioma del gerundio verbal (singing, player, running, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "MEjgmtJ-TzGB"
   },
   "outputs": [],
   "source": [
    "def pre_processing2(documentos, vocabulario, idioma):\n",
    "    \"\"\"\n",
    "    Funci√≥n que realiza un preprocesamiento del lenguaje natural, que aplica reglas para eliminar stopwors y realizar stemmig sobre las palabras\n",
    "    que integran los diferentes documentos del corpus.\n",
    "\n",
    "    Argumentos\n",
    "    -----------\n",
    "    La funci√≥n recibe como argumento un corpus (documentos), un vocabulario y un idioma (espa√±ol o ingl√©s)\n",
    "\n",
    "    Resultado\n",
    "    ----------\n",
    "    El resultado de la funci√≥n es un corpus tokenizado, donde los tokens o t√©rminos procesados, se almacenan en una lista\n",
    "\n",
    "    \"\"\"\n",
    "    corpus = \" \".join(documentos)\n",
    "    corpus = get_tokens(corpus)\n",
    "    lista = dict(zip(corpus,[corpus.count(palabra) for palabra in vocabulario])) # Conteo de las palabras del corpus con presencia en el diccionario\n",
    "    lista = dict(sorted(lista.items(), key=lambda item:item[1],reverse=True)) # Jerarquizaci√≥n de las palabras del diccionario seg√∫n su frecuencia en el corpus\n",
    "    lista = [f'{k}' for k,v in lista.items() if lista[k] < 2] # Elimina palabras con frecuencias mayores.\n",
    "    lista = [i for i in lista if len(i) > 3] # Se filtra palabras de menos de tres letras\n",
    "\n",
    "    if idioma == 'espanol':\n",
    "      nueva_lista = []\n",
    "      for palabra in lista:\n",
    "        if re.match(r'\\w*[aeiou√°√©√≠√≥√∫]$', palabra): # Resta la vocal si la palabra termina en vocal (neutralizar el g√©nero de las palabras)\n",
    "          palabra = palabra[:-1]\n",
    "        elif palabra.endswith('s'): # Elimina la √∫ltima letra si la palabra termina en 's' (plural de las palabras)\n",
    "          palabra = palabra[:-1]\n",
    "        elif palabra.endswith('ar'): # Elimina la terminaci√≥n 'ar' de la palabra (indicativo de los verbos)\n",
    "          palabra = palabra[:-2]\n",
    "\n",
    "        nueva_lista.append(palabra)\n",
    "\n",
    "    elif idioma == 'ingles':\n",
    "      nueva_lista = []\n",
    "      for palabra in lista:\n",
    "        if re.match(r'\\w*[aeiour]$', palabra): # Se elimina la vocal si la palabra termina en vocal y en 'r'.\n",
    "          palabra = palabra[:-1]\n",
    "        elif palabra.endswith('er'): # Se elimina la terminaci√≥n 'er' (contrae el agente)\n",
    "          palabra = palabra[:-2]\n",
    "        elif palabra.endswith('ing'): # Se elimina terminaci√≥n 'ing' (gerundio de los verbos)\n",
    "          palabra = palabra[:-3]\n",
    "\n",
    "        nueva_lista.append(palabra)\n",
    "\n",
    "    return nueva_lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "bHBb_-zX8Pjd"
   },
   "outputs": [],
   "source": [
    "def pre_processing(vocabulario, idioma):\n",
    "    \"\"\"\n",
    "    Funci√≥n que realiza un preprocesamiento del lenguaje natural, que aplica reglas para eliminar stopwors y realizar stemmig sobre las palabras\n",
    "    que integran un vocabulario.\n",
    "\n",
    "    Argumentos\n",
    "    -----------\n",
    "    La funci√≥n recibe como argumento un vocabulario y un idioma (espa√±ol o ingl√©s)\n",
    "\n",
    "    Resultado\n",
    "    ----------\n",
    "    El resultado de la funci√≥n es un vocabulario tokenizado, donde los tokens o t√©rminos procesados, se almacenan en una lista\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    vocabulario = [i for i in vocabulario if len(i) > 3]\n",
    "\n",
    "    if idioma == 'espanol':\n",
    "      nueva_lista = []\n",
    "      for palabra in vocabulario:\n",
    "        if re.match(r'\\w*[aeiou√°√©√≠√≥√∫]$', palabra): # Resta la vocal si la palabra termina en vocal (neutralizar el g√©nero de las palabras)\n",
    "          palabra = palabra[:-1]\n",
    "        elif palabra.endswith('s'): # Elimina la √∫ltima letra si la palabra termina en 's' (plural de las palabras)\n",
    "          palabra = palabra[:-1]\n",
    "        elif palabra.endswith('ar'): # Elimina la terminaci√≥n 'ar' de la palabra (indicativo de los verbos)\n",
    "          palabra = palabra[:-2]\n",
    "\n",
    "        nueva_lista.append(palabra)\n",
    "\n",
    "    elif idioma == 'ingles':\n",
    "      nueva_lista = []\n",
    "      for palabra in vocabulario:\n",
    "        if re.match(r'\\w*[aeiour]$', palabra): # Se elimina la vocal si la palabra termina en vocal y en 'r'.\n",
    "          palabra = palabra[:-1]\n",
    "        elif palabra.endswith('er'): # Se elimina la terminaci√≥n 'er' (contrae el agente)\n",
    "          palabra = palabra[:-2]\n",
    "        elif palabra.endswith('ing'): # Se elimina terminaci√≥n 'ing' (gerundio de los verbos)\n",
    "          palabra = palabra[:-3]\n",
    "\n",
    "        nueva_lista.append(palabra)\n",
    "\n",
    "    return nueva_lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xeWnb63VEbY-",
    "outputId": "54d12eda-d85b-4174-9e36-07682ee80cc9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What', 'that', 'sitt', 'you', 'plat', 'want', 'what', 'fish']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_processing2(corpus_ingles,vocab_ing,'ingles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dt42BYXolOfe",
    "outputId": "4b528fc5-c59a-4a8a-ee55-1f01311237d3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "82ZYXNcO9QLH"
   },
   "outputs": [],
   "source": [
    "def pre_processing_nltk(corpus,idioma):\n",
    "    \"\"\"\n",
    "    Funci√≥n que realiza un preprocesamiento del lenguaje natural, que aplica las stopwors y el stemmig de la librer√≠a NLTK.\n",
    "\n",
    "    Argumentos\n",
    "    -----------\n",
    "    La funci√≥n recibe como argumento un corpus y un idioma (espa√±ol o ingl√©s)\n",
    "\n",
    "\n",
    "    Resultado\n",
    "    ----------\n",
    "    El resultado de la funci√≥n es un vocabulario tokenizado, donde los tokens o t√©rminos procesados, se almacenan en una lista\n",
    "    \"\"\"\n",
    "\n",
    "    texto = \" \".join(corpus)\n",
    "    texto = re.sub('\\W+',' ',texto)\n",
    "    texto = re.sub('\\d+','',texto)\n",
    "\n",
    "    if idioma == 'english':\n",
    "      porter = PorterStemmer()\n",
    "      texto = [porter.stem(palabra) for palabra in texto.split()]\n",
    "      stop = stopwords.words('english')\n",
    "\n",
    "    elif idioma == 'spanish':\n",
    "      stemmer = SnowballStemmer('spanish')\n",
    "      texto = [stemmer.stem(palabra) for palabra in texto.split()]\n",
    "      stop = stopwords.words('spanish')\n",
    "\n",
    "    return [palabra for palabra in texto if palabra not in stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "FNVJp_EqAg-D"
   },
   "outputs": [],
   "source": [
    "def pre_processing_nltk_2(vocabulario,idioma):\n",
    "    \"\"\"\n",
    "    Funci√≥n que realiza un preprocesamiento del lenguaje natural, que aplica las stopwors y el stemmig de la librer√≠a NLTK.\n",
    "\n",
    "    Argumentos\n",
    "    -----------\n",
    "    La funci√≥n recibe como argumento un vocabulario y un idioma (espa√±ol o ingl√©s)\n",
    "\n",
    "\n",
    "    Resultado\n",
    "    ----------\n",
    "    El resultado de la funci√≥n es un vocabulario tokenizado, donde los tokens o t√©rminos procesados, se almacenan en una lista\n",
    "    \"\"\"\n",
    "\n",
    "    if idioma == 'english':\n",
    "      porter = PorterStemmer()\n",
    "      texto = [porter.stem(palabra) for palabra in vocabulario]\n",
    "      stop = stopwords.words('english')\n",
    "\n",
    "    elif idioma == 'spanish':\n",
    "      stemmer = SnowballStemmer('spanish')\n",
    "      texto = [stemmer.stem(palabra) for palabra in vocabulario]\n",
    "      stop = stopwords.words('spanish')\n",
    "\n",
    "    return [palabra for palabra in texto if palabra not in stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iT1Rr0das2Nb",
    "outputId": "c5b581d5-46e0-4c5d-bb6e-f7db6364e16c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APLICACI√ìN DE FUNCIONES PARA PRE-PROCESAMIENTO (STEMMING Y STOPWORS)\n",
      "\n",
      "1. Resultados stemming y stopwords con funci√≥n propia (argumentos = vocabulario, idioma):\n",
      "a) Vocabulario funci√≥n pre-procesado en espa√±ol: ['cant', 'Qui√©n', 'deb', 'mejor', 'quier', 'cre', 'quier', 'quier', 'Dim', 'sabe']\n",
      "b) Vocabulario funci√≥n pre-procesado en ingl√©s: ['plat', 'what', 'want', 'bait', 'that', 'fish', 'been', 'you', 'What', 'sitt'] \n",
      "\n",
      "2. Resultados stemming y stopwords con funci√≥n basada en NLTK:\n",
      "c) Vocabulario procesado en espa√±ol con NLTK: ['cant', 'Qui√©n', 'deb', 'mejor', 'quier', 'cre', 'quier', 'quier', 'Dim', 'sabe']\n",
      "d) Vocabulario procesado en ingl√©s con NLTK: ['plat', 'what', 'want', 'bait', 'that', 'fish', 'been', 'you', 'What', 'sitt'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicar preprocesamiento a los vocabularios de ejemplo con NLTK\n",
    "\n",
    "print('APLICACI√ìN DE FUNCIONES PARA PRE-PROCESAMIENTO (STEMMING Y STOPWORS)\\n')\n",
    "\n",
    "print('1. Resultados stemming y stopwords con funci√≥n propia (argumentos = vocabulario, idioma):')\n",
    "vocab_procesado_espanol = pre_processing(vocab_esp,'espanol')\n",
    "vocab_procesado_ingles = pre_processing(vocab_ing,'ingles')\n",
    "\n",
    "print(\"a) Vocabulario funci√≥n pre-procesado en espa√±ol:\", vocab_procesado_espanol)\n",
    "print(\"b) Vocabulario funci√≥n pre-procesado en ingl√©s:\", vocab_procesado_ingles, \"\\n\")\n",
    "\n",
    "\n",
    "print('2. Resultados stemming y stopwords con funci√≥n basada en NLTK:')\n",
    "vocab_procesado_espanol_nltk = pre_processing_nltk_2(vocab_esp, 'spanish')\n",
    "vocab_procesado_ingles_nltk = pre_processing_nltk_2(vocab_ing, 'english')\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"c) Vocabulario procesado en espa√±ol con NLTK:\", vocab_procesado_espanol)\n",
    "print(\"d) Vocabulario procesado en ingl√©s con NLTK:\", vocab_procesado_ingles, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ajmn1HaNhZE9"
   },
   "source": [
    "## P3. Bag of Words (0.5 puntos)\n",
    "Considere el siguiente corpus, donde cada elemento del arreglo representa un documento:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "vT0XQM2Ghlvy"
   },
   "outputs": [],
   "source": [
    "d0 = 'El p√°jaro come semillas'\n",
    "d1 = 'El p√°jaro se despierta y canta'\n",
    "d2 = 'El p√°jaro canta y come semillas'\n",
    "d3 = 'El pez come y nada en el agua'\n",
    "d4 = 'El pez empieza a nadar'\n",
    "d5 = 'El pez come alimento'\n",
    "corpus = [d0, d1, d2, d3, d4, d5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VeOOz1Su2ATf"
   },
   "source": [
    "El objetivo da las siguientes secciones es determinar cu√°les de  los documentos entregados son los m√°s similares entre s√≠. Para ello utilizaremos la t√©cnica **TF-IDF**.\n",
    "\n",
    "Como los algoritmos de Machine Learning no comprenden el texto en lenguaje natural, estos documentos deben ser convertidos a vectores num√©ricos. La representaci√≥n m√°s simple vista en clases es la de **Bag of Words**, m√©todo mediante el cual se cuentan las apariciones de cada palabra en cada uno de los documentos entregados.\n",
    "\n",
    "Implemente la funci√≥n **`bag_of_words()`**, que recibe como input un arreglo de documentos y devuelve un dataframe de pandas con la representaci√≥n Bag of Words de los documentos entregados. En esta representaci√≥n las columnas son el vocabulario y las filas representan las apariciones de cada una de las palabras en los documentos. En otras palabras, cada fila representa el BoW de un documento.\n",
    "\n",
    "***Disclaimer: el orden de los resultados pueden variar.***\n",
    "\n",
    "\n",
    "Por ejemplo para el siguiente corpus:\n",
    "\n",
    "```\n",
    "corpus = ['El perro ladra', 'El perro come']\n",
    "```\n",
    "\n",
    "Debiese entregarnos lo siguiente:\n",
    "\n",
    "\n",
    "|   | el | perro | ladra | come |\n",
    "|---|----|-------|------|-------|\n",
    "| 0 | 1  | 1     | 1    | 0     |\n",
    "| 1 | 1  | 1     | 0    | 1     |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "_njmcRPM2GpV"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MENCbDO8s_ls"
   },
   "source": [
    "Implementar funci√≥n `bag_of_words()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "C_eRRUvD2ChD"
   },
   "outputs": [],
   "source": [
    "def bag_of_words(corpus):\n",
    "    ### Aqu√≠ inicia tu c√≥digo ###\n",
    "    tokens = get_vocab(corpus)\n",
    "    #tokens = pre_processing(tokens, 'espanol')\n",
    "    df_corpus = pd.DataFrame([], columns=tokens)\n",
    "    #Se recorre el corpus de manera secuencial, creando una lista de las apariciones en los tokens y agregandolas al pandas final\n",
    "    for i in corpus:\n",
    "        #Calculamos el largo del dataframe, para poder rellenarlo inicilamente con 0¬¥s\n",
    "        df_corpus.loc[len(df_corpus)] = pd.Series([0] * len(df_corpus.columns), index=df_corpus.columns)\n",
    "        tokenizados = get_tokens(i)\n",
    "        for k in tokenizados:\n",
    "            if k in tokens:\n",
    "                #index = df_corpus.index(-1)\n",
    "                df_corpus.iloc[-1][k] += 1\n",
    "    return df_corpus\n",
    "    ### Aqu√≠ termina tu c√≥digo ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "jWZyXGra2FOw",
    "outputId": "02df51f0-d768-477d-e489-a49b9f41f5fa"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"dataset_bow\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nada\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"agua\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"despierta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pez\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"se\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"semillas\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"canta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"El\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"empieza\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p\\u00e1jaro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nadar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"alimento\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"a\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"el\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"en\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"come\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "dataset_bow"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-3ded448a-0e94-4cc4-9f15-c303ae538127\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>nada</th>\n",
       "      <th>agua</th>\n",
       "      <th>despierta</th>\n",
       "      <th>pez</th>\n",
       "      <th>se</th>\n",
       "      <th>semillas</th>\n",
       "      <th>canta</th>\n",
       "      <th>El</th>\n",
       "      <th>empieza</th>\n",
       "      <th>p√°jaro</th>\n",
       "      <th>nadar</th>\n",
       "      <th>alimento</th>\n",
       "      <th>a</th>\n",
       "      <th>el</th>\n",
       "      <th>en</th>\n",
       "      <th>come</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ded448a-0e94-4cc4-9f15-c303ae538127')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-3ded448a-0e94-4cc4-9f15-c303ae538127 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-3ded448a-0e94-4cc4-9f15-c303ae538127');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-b3b1f9a2-acf6-484d-a471-d03be36d540c\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b3b1f9a2-acf6-484d-a471-d03be36d540c')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-b3b1f9a2-acf6-484d-a471-d03be36d540c button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   y  nada  agua  despierta  pez  se  semillas  canta  El  empieza  p√°jaro  \\\n",
       "0  0     0     0          0    0   0         1      0   1        0       1   \n",
       "1  1     0     0          1    0   1         0      1   1        0       1   \n",
       "2  1     0     0          0    0   0         1      1   1        0       1   \n",
       "3  1     1     1          0    1   0         0      0   1        0       0   \n",
       "4  0     0     0          0    1   0         0      0   1        1       0   \n",
       "5  0     0     0          0    1   0         0      0   1        0       0   \n",
       "\n",
       "   nadar  alimento  a  el  en  come  \n",
       "0      0         0  0   0   0     1  \n",
       "1      0         0  0   0   0     0  \n",
       "2      0         0  0   0   0     1  \n",
       "3      0         0  0   1   1     1  \n",
       "4      1         0  1   0   0     0  \n",
       "5      0         1  0   0   0     1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_bow = bag_of_words(corpus)\n",
    "dataset_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTl8TgAPIpKF"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PiWA3qUE4NZ5",
    "outputId": "8753a47d-ff7b-4622-a9d6-34a6513939fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 17)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_bow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6qEA2Ic2sLlh"
   },
   "source": [
    "Soluci√≥n esperada:\n",
    "\n",
    "|    |   El |   p√°jaro |   despierta |   el |   come |   a |   nadar |   se |   en |   y |   alimento |   semillas |   pez |   empieza |   canta |   agua |   nada |\n",
    "|:---|-----:|---------:|------------:|-----:|-------:|----:|--------:|-----:|-----:|----:|-----------:|-----------:|------:|----------:|--------:|-------:|-------:|\n",
    "| d0 |    1 |        1 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   0 |          0 |          1 |     0 |         0 |       0 |      0 |      0 |\n",
    "| d1 |    1 |        1 |           1 |    0 |      0 |   0 |       0 |    1 |    0 |   1 |          0 |          0 |     0 |         0 |       1 |      0 |      0 |\n",
    "| d2 |    1 |        1 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   1 |          0 |          1 |     0 |         0 |       1 |      0 |      0 |\n",
    "| d3 |    1 |        0 |           0 |    1 |      1 |   0 |       0 |    0 |    1 |   1 |          0 |          0 |     1 |         0 |       0 |      1 |      1 |\n",
    "| d4 |    1 |        0 |           0 |    0 |      0 |   1 |       1 |    0 |    0 |   0 |          0 |          0 |     1 |         1 |       0 |      0 |      0 |\n",
    "| d5 |    1 |        0 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   0 |          1 |          0 |     1 |         0 |       0 |      0 |      0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMv3UZdRhgqT"
   },
   "source": [
    "## P4. TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4oxW5CZjhoE9"
   },
   "source": [
    "### 4.a TF (0.25 puntos)\n",
    "\n",
    "Ahora debemos usar el dataframe del ejercicio anterior para calcular la matriz de TF normalizada por la m√°xima frecuencia $\\max_i({\\text{tf}_{i,j}})$, donde\n",
    "$i$ corresponde al √≠ndice de las filas (BoW) y $j$ al de las columnas (palabras). Es decir, dividir cada BoW sobre la cantidad de veces de la palabra que aparezca m√°s veces en ese vector.\n",
    "\n",
    "\n",
    "$$\\text{nft}_{i,j} = \\frac{\\text{tf}_{i,j}}{\\max_i({\\text{tf}_{i,j})}}$$\n",
    "\n",
    "Implemente la funci√≥n `calc_tf(dataset_bow)`, que entrega la matriz de TF normalizada del BoW del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "qQhnJuuShmR5"
   },
   "outputs": [],
   "source": [
    "def calc_tf(dataset_bow):\n",
    "    ### Aqu√≠ inicia tu c√≥digo ###\n",
    "    for i in range(0, len(dataset_bow)):\n",
    "        max_value = dataset_bow.iloc[i].max()\n",
    "        dataset_bow.iloc[i] = dataset_bow.iloc[i]/max_value\n",
    "    return dataset_bow\n",
    "    ### Aqu√≠ termina tu c√≥digo ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "urDKFQVu2p3V",
    "outputId": "1957cd4d-4797-4fe4-8277-e9f62818cfef"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"dataset_bow\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nada\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"agua\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"despierta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pez\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"se\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"semillas\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"canta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"El\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"empieza\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p\\u00e1jaro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nadar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"alimento\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"a\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"el\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"en\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"come\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "dataset_bow"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-f6007597-6809-43b5-9600-0f3ae72b65d7\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>nada</th>\n",
       "      <th>agua</th>\n",
       "      <th>despierta</th>\n",
       "      <th>pez</th>\n",
       "      <th>se</th>\n",
       "      <th>semillas</th>\n",
       "      <th>canta</th>\n",
       "      <th>El</th>\n",
       "      <th>empieza</th>\n",
       "      <th>p√°jaro</th>\n",
       "      <th>nadar</th>\n",
       "      <th>alimento</th>\n",
       "      <th>a</th>\n",
       "      <th>el</th>\n",
       "      <th>en</th>\n",
       "      <th>come</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6007597-6809-43b5-9600-0f3ae72b65d7')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-f6007597-6809-43b5-9600-0f3ae72b65d7 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-f6007597-6809-43b5-9600-0f3ae72b65d7');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-74ea97ed-bffc-4de3-982e-ebcc2d774c9b\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-74ea97ed-bffc-4de3-982e-ebcc2d774c9b')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-74ea97ed-bffc-4de3-982e-ebcc2d774c9b button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   y  nada  agua  despierta  pez  se  semillas  canta  El  empieza  p√°jaro  \\\n",
       "0  0     0     0          0    0   0         1      0   1        0       1   \n",
       "1  1     0     0          1    0   1         0      1   1        0       1   \n",
       "2  1     0     0          0    0   0         1      1   1        0       1   \n",
       "3  1     1     1          0    1   0         0      0   1        0       0   \n",
       "4  0     0     0          0    1   0         0      0   1        1       0   \n",
       "5  0     0     0          0    1   0         0      0   1        0       0   \n",
       "\n",
       "   nadar  alimento  a  el  en  come  \n",
       "0      0         0  0   0   0     1  \n",
       "1      0         0  0   0   0     0  \n",
       "2      0         0  0   0   0     1  \n",
       "3      0         0  0   1   1     1  \n",
       "4      1         0  1   0   0     0  \n",
       "5      0         1  0   0   0     1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = calc_tf(dataset_bow)\n",
    "tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Swo3ZjwVtZlq"
   },
   "source": [
    "Soluci√≥n esperada:\n",
    "\n",
    "|    |   El |   p√°jaro |   despierta |   el |   come |   a |   nadar |   se |   en |   y |   alimento |   semillas |   pez |   empieza |   canta |   agua |   nada |\n",
    "|:---|-----:|---------:|------------:|-----:|-------:|----:|--------:|-----:|-----:|----:|-----------:|-----------:|------:|----------:|--------:|-------:|-------:|\n",
    "| d0 |    1 |        1 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   0 |          0 |          1 |     0 |         0 |       0 |      0 |      0 |\n",
    "| d1 |    1 |        1 |           1 |    0 |      0 |   0 |       0 |    1 |    0 |   1 |          0 |          0 |     0 |         0 |       1 |      0 |      0 |\n",
    "| d2 |    1 |        1 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   1 |          0 |          1 |     0 |         0 |       1 |      0 |      0 |\n",
    "| d3 |    1 |        0 |           0 |    1 |      1 |   0 |       0 |    0 |    1 |   1 |          0 |          0 |     1 |         0 |       0 |      1 |      1 |\n",
    "| d4 |    1 |        0 |           0 |    0 |      0 |   1 |       1 |    0 |    0 |   0 |          0 |          0 |     1 |         1 |       0 |      0 |      0 |\n",
    "| d5 |    1 |        0 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   0 |          1 |          0 |     1 |         0 |       0 |      0 |      0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sh2bFyHFhpbM"
   },
   "source": [
    "### 4.b IDF (0.5 puntos)\n",
    "\n",
    "Implementar `calc_idf(dataset_bow)`. √âsta debe retornar un diccionario en donde las llaves sean las palabras y los valores sean el c√°lculo de cada idf por palabra.\n",
    "\n",
    "Recordar que $\\text{idf}_{t_i} = \\log_{10}\\frac{N}{n_i}$ con $N = $ n√∫mero de documentos y $n_i = $ n√∫mero de documentos que contienen la palabra $t_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "tGLjlSY02usu"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "qoU4AIrm2sDT"
   },
   "outputs": [],
   "source": [
    "def calc_idf(dataset_bow):\n",
    "    ### Aqu√≠ inicia tu c√≥digo ###\n",
    "    N=len(dataset_bow)\n",
    "    lista_columnas = dataset_bow.columns\n",
    "    dicc_idf = {}\n",
    "    for i in lista_columnas:\n",
    "        n_i = dataset_bow[i].sum()\n",
    "        idf_i = np.log(N/n_i) / np.log(10)\n",
    "        dicc_idf[i]= idf_i\n",
    "    return dicc_idf\n",
    "    ### Aqu√≠ termina tu c√≥digo ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aXPErPdw2uQx",
    "outputId": "bec0ba10-22f7-438e-e53d-082e44b2993f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': 0.30102999566398114,\n",
       " 'nada': 0.7781512503836435,\n",
       " 'agua': 0.7781512503836435,\n",
       " 'despierta': 0.7781512503836435,\n",
       " 'pez': 0.30102999566398114,\n",
       " 'se': 0.7781512503836435,\n",
       " 'semillas': 0.47712125471966244,\n",
       " 'canta': 0.47712125471966244,\n",
       " 'El': 0.0,\n",
       " 'empieza': 0.7781512503836435,\n",
       " 'p√°jaro': 0.30102999566398114,\n",
       " 'nadar': 0.7781512503836435,\n",
       " 'alimento': 0.7781512503836435,\n",
       " 'a': 0.7781512503836435,\n",
       " 'el': 0.7781512503836435,\n",
       " 'en': 0.7781512503836435,\n",
       " 'come': 0.17609125905568124}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf = calc_idf(dataset_bow)\n",
    "idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nmp5lXdquAD1"
   },
   "source": [
    "Soluci√≥n esperada:\n",
    "```\n",
    "{'El': 0.0,\n",
    " 'p√°jaro': 0.3010299956639812,\n",
    " 'despierta': 0.7781512503836436,\n",
    " 'el': 0.7781512503836436,\n",
    " 'come': 0.17609125905568124,\n",
    " 'a': 0.7781512503836436,\n",
    " 'nadar': 0.7781512503836436,\n",
    " 'se': 0.7781512503836436,\n",
    " 'en': 0.7781512503836436,\n",
    " 'y': 0.3010299956639812,\n",
    " 'alimento': 0.7781512503836436,\n",
    " 'semillas': 0.47712125471966244,\n",
    " 'pez': 0.3010299956639812,\n",
    " 'empieza': 0.7781512503836436,\n",
    " 'canta': 0.47712125471966244,\n",
    " 'agua': 0.7781512503836436,\n",
    " 'nada': 0.7781512503836436}\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eC-_vwiV20XL"
   },
   "source": [
    "### 4.c TF-IDF (0.25 puntos)\n",
    "Programe la funci√≥n `calc_tf_idf(tf, idf)` que entrega el dataframe TF-IDF asociado al dataset que estamos analizando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "004IuUyt23_6"
   },
   "outputs": [],
   "source": [
    "def calc_tf_idf(tf, idf):\n",
    "    ### Aqu√≠ inicia tu c√≥digo ###\n",
    "    for i in tf.columns:\n",
    "        tf[i] = tf[i] * idf[i]\n",
    "    return tf\n",
    "    ### Aqu√≠ termina tu c√≥digo ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "KXjP0S3626dw",
    "outputId": "d67762cd-49be-4539-afd9-abe906cfe795"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"dataset_bow\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16488091911084482,\n        \"min\": 0.0,\n        \"max\": 0.30102999566398114,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.30102999566398114,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nada\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3176789176914399,\n        \"min\": 0.0,\n        \"max\": 0.7781512503836435,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.7781512503836435,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"agua\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3176789176914399,\n        \"min\": 0.0,\n        \"max\": 0.7781512503836435,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.7781512503836435,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"despierta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.31767891769143985,\n        \"min\": 0.0,\n        \"max\": 0.7781512503836435,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.7781512503836435,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pez\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16488091911084482,\n        \"min\": 0.0,\n        \"max\": 0.30102999566398114,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.30102999566398114,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"se\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.31767891769143985,\n        \"min\": 0.0,\n        \"max\": 0.7781512503836435,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.7781512503836435,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"semillas\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24638435648677856,\n        \"min\": 0.0,\n        \"max\": 0.47712125471966244,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          0.47712125471966244\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"canta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24638435648677856,\n        \"min\": 0.0,\n        \"max\": 0.47712125471966244,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.47712125471966244,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"El\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"empieza\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3176789176914399,\n        \"min\": 0.0,\n        \"max\": 0.7781512503836435,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.7781512503836435\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p\\u00e1jaro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16488091911084482,\n        \"min\": 0.0,\n        \"max\": 0.30102999566398114,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nadar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3176789176914399,\n        \"min\": 0.0,\n        \"max\": 0.7781512503836435,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.7781512503836435\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"alimento\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3176789176914399,\n        \"min\": 0.0,\n        \"max\": 0.7781512503836435,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.7781512503836435\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"a\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3176789176914399,\n        \"min\": 0.0,\n        \"max\": 0.7781512503836435,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.7781512503836435\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"el\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3176789176914399,\n        \"min\": 0.0,\n        \"max\": 0.7781512503836435,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.7781512503836435\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"en\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3176789176914399,\n        \"min\": 0.0,\n        \"max\": 0.7781512503836435,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.7781512503836435\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"come\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09093313516471326,\n        \"min\": 0.0,\n        \"max\": 0.17609125905568124,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "dataset_bow"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-128a5f53-4198-4cb1-9c72-0f6fadecb381\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>nada</th>\n",
       "      <th>agua</th>\n",
       "      <th>despierta</th>\n",
       "      <th>pez</th>\n",
       "      <th>se</th>\n",
       "      <th>semillas</th>\n",
       "      <th>canta</th>\n",
       "      <th>El</th>\n",
       "      <th>empieza</th>\n",
       "      <th>p√°jaro</th>\n",
       "      <th>nadar</th>\n",
       "      <th>alimento</th>\n",
       "      <th>a</th>\n",
       "      <th>el</th>\n",
       "      <th>en</th>\n",
       "      <th>come</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.477121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.778151</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.778151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.477121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.477121</td>\n",
       "      <td>0.477121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.778151</td>\n",
       "      <td>0.778151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.778151</td>\n",
       "      <td>0.778151</td>\n",
       "      <td>0.176091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778151</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.778151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.778151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.778151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-128a5f53-4198-4cb1-9c72-0f6fadecb381')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-128a5f53-4198-4cb1-9c72-0f6fadecb381 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-128a5f53-4198-4cb1-9c72-0f6fadecb381');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-5b0340ea-dee8-40cf-9ceb-059edfa957f4\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5b0340ea-dee8-40cf-9ceb-059edfa957f4')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-5b0340ea-dee8-40cf-9ceb-059edfa957f4 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "         y      nada      agua  despierta      pez        se  semillas  \\\n",
       "0  0.00000  0.000000  0.000000   0.000000  0.00000  0.000000  0.477121   \n",
       "1  0.30103  0.000000  0.000000   0.778151  0.00000  0.778151  0.000000   \n",
       "2  0.30103  0.000000  0.000000   0.000000  0.00000  0.000000  0.477121   \n",
       "3  0.30103  0.778151  0.778151   0.000000  0.30103  0.000000  0.000000   \n",
       "4  0.00000  0.000000  0.000000   0.000000  0.30103  0.000000  0.000000   \n",
       "5  0.00000  0.000000  0.000000   0.000000  0.30103  0.000000  0.000000   \n",
       "\n",
       "      canta   El   empieza   p√°jaro     nadar  alimento         a        el  \\\n",
       "0  0.000000  0.0  0.000000  0.30103  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.477121  0.0  0.000000  0.30103  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.477121  0.0  0.000000  0.30103  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.0  0.000000  0.00000  0.000000  0.000000  0.000000  0.778151   \n",
       "4  0.000000  0.0  0.778151  0.00000  0.778151  0.000000  0.778151  0.000000   \n",
       "5  0.000000  0.0  0.000000  0.00000  0.000000  0.778151  0.000000  0.000000   \n",
       "\n",
       "         en      come  \n",
       "0  0.000000  0.176091  \n",
       "1  0.000000  0.000000  \n",
       "2  0.000000  0.176091  \n",
       "3  0.778151  0.176091  \n",
       "4  0.000000  0.000000  \n",
       "5  0.000000  0.176091  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf = calc_tf_idf(tf, idf)\n",
    "tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNTa32IsuLWl"
   },
   "source": [
    "Soluci√≥n esperada:\n",
    "\n",
    "|    |   El |   p√°jaro |   despierta |       el |     come |        a |    nadar |       se |       en |       y |   alimento |   semillas |     pez |   empieza |    canta |     agua |     nada |\n",
    "|:---|-----:|---------:|------------:|---------:|---------:|---------:|---------:|---------:|---------:|--------:|-----------:|-----------:|--------:|----------:|---------:|---------:|---------:|\n",
    "| d0 |    0 |  0.30103 |    0        | 0        | 0.176091 | 0        | 0        | 0        | 0        | 0       |   0        |   0.477121 | 0       |  0        | 0        | 0        | 0        |\n",
    "| d1 |    0 |  0.30103 |    0.778151 | 0        | 0        | 0        | 0        | 0.778151 | 0        | 0.30103 |   0        |   0        | 0       |  0        | 0.477121 | 0        | 0        |\n",
    "| d2 |    0 |  0.30103 |    0        | 0        | 0.176091 | 0        | 0        | 0        | 0        | 0.30103 |   0        |   0.477121 | 0       |  0        | 0.477121 | 0        | 0        |\n",
    "| d3 |    0 |  0       |    0        | 0.778151 | 0.176091 | 0        | 0        | 0        | 0.778151 | 0.30103 |   0        |   0        | 0.30103 |  0        | 0        | 0.778151 | 0.778151 |\n",
    "| d4 |    0 |  0       |    0        | 0        | 0        | 0.778151 | 0.778151 | 0        | 0        | 0       |   0        |   0        | 0.30103 |  0.778151 | 0        | 0        | 0        |\n",
    "| d5 |    0 |  0       |    0        | 0        | 0.176091 | 0        | 0        | 0        | 0        | 0       |   0.778151 |   0        | 0.30103 |  0        | 0        | 0        | 0        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8sQEjVshjQ7"
   },
   "source": [
    "## P5. Cosine-similarity (0.25 puntos)\n",
    "Ahora que tenemos el dataframe de TF-IDF, nos queda calcular la similitud coseno entre todos los vectores. Notar que la matriz resultante ser√° una matriz sim√©trica.\n",
    "\n",
    "Implemente la funci√≥n *cosine_similarity(v1, v2)* que recibe dos vectores (v1 y v2) y calcula la similitud coseno entre ambos. Concluya cu√°les son los dos documentos m√°s similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "_68mo-BLhmuV"
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(v1, v2):\n",
    "    ### Aqu√≠ inicia tu c√≥digo ###\n",
    "    n1 = np.dot(v1, v2)\n",
    "    n2 = np.linalg.norm(v1)* np.linalg.norm(v2)\n",
    "    return n1/n2\n",
    "    ### Aqu√≠ termina tu c√≥digo ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u5z-23CN2_lU",
    "outputId": "e63349b6-7546-42a0-a7a2-4567accc6f8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El p√°jaro come semillas\n",
      "> Mas similar: El p√°jaro canta y come semillas\n",
      "> Similitud: 0.7233435041520414 \n",
      "\n",
      "El p√°jaro se despierta y canta\n",
      "> Mas similar: El p√°jaro canta y come semillas\n",
      "> Similitud: 0.39320101823128945 \n",
      "\n",
      "El p√°jaro canta y come semillas\n",
      "> Mas similar: El p√°jaro come semillas\n",
      "> Similitud: 0.7233435041520414 \n",
      "\n",
      "El pez come y nada en el agua\n",
      "> Mas similar: El p√°jaro canta y come semillas\n",
      "> Similitud: 0.09171890791406166 \n",
      "\n",
      "El pez empieza a nadar\n",
      "> Mas similar: El pez come alimento\n",
      "> Similitud: 0.0769507840675271 \n",
      "\n",
      "El pez come alimento\n",
      "> Mas similar: El pez come y nada en el agua\n",
      "> Similitud: 0.08787900372173231 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix = np.zeros((6,6))\n",
    "for i, v1 in enumerate(tf_idf.index.values):\n",
    "  for j, v2 in enumerate(tf_idf.index.values):\n",
    "      similarity = cosine_similarity(tf_idf.loc[v1].values, tf_idf.loc[v2].values)\n",
    "      similarity_matrix[i][j] = similarity\n",
    "\n",
    "for i in range(6):\n",
    "  mask = [k != i for k in range(6)]\n",
    "  j = np.argmax(similarity_matrix[i][mask])\n",
    "\n",
    "  print(corpus[i])\n",
    "  print(\"> Mas similar:\", np.array(corpus)[mask][j])\n",
    "  print(\"> Similitud:\", similarity_matrix[i][mask][j], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71oH4JHXulGQ"
   },
   "source": [
    "Soluci√≥n esperada:\n",
    "```\n",
    "El p√°jaro come semillas\n",
    "> Mas similar: El p√°jaro canta y come semillas\n",
    "> Similitud: 0.7233435041520414\n",
    "\n",
    "El p√°jaro se despierta y canta\n",
    "> Mas similar: El p√°jaro canta y come semillas\n",
    "> Similitud: 0.39320101823128945\n",
    "\n",
    "El p√°jaro canta y come semillas\n",
    "> Mas similar: El p√°jaro come semillas\n",
    "> Similitud: 0.7233435041520414\n",
    "\n",
    "El pez come y nada en el agua\n",
    "> Mas similar: El p√°jaro canta y come semillas\n",
    "> Similitud: 0.09171890791406168\n",
    "\n",
    "El pez empieza a nadar\n",
    "> Mas similar: El pez come alimento\n",
    "> Similitud: 0.07695078406752713\n",
    "\n",
    "El pez come alimento\n",
    "> Mas similar: El pez come y nada en el agua\n",
    "> Similitud: 0.0878790037217323\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDZln45jfjMf"
   },
   "source": [
    "## P6 N-gramas (0.75 punto)\n",
    "\n",
    "En esta secci√≥n debera determinar los n-gramas del la cancion \"Oh algoritmo\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v7duKoBvlSgg"
   },
   "source": [
    "### 6.a Corpus de entrenamiento y test (0.25 puntos)\n",
    "\n",
    "En esta subsecci√≥n debera definir el conjunto de entrenamiento y test de un corpus. Eliga una particion del 80% y 20% del texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "juDVurFfl3eZ",
    "outputId": "fcc28736-948a-45eb-910d-45418e16fa20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo no se encuentra.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Abre el archivo en modo lectura (\"r\")\n",
    "    with open(\"oh_algoritmo.txt\", \"r\") as archivo:\n",
    "        # Lee el contenido del archivo\n",
    "        texto = archivo.read()\n",
    "        # Imprime el contenido\n",
    "        print(texto)\n",
    "except FileNotFoundError:\n",
    "    print(\"El archivo no se encuentra.\")\n",
    "except Exception as e:\n",
    "    print(\"Ocurri√≥ un error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYCw0AqOmlzD"
   },
   "source": [
    "Defina una funcion `get_sentences()` que entregue todas las oraciones del corpus que contengan al menos una palabra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "C88f9aVil9d_"
   },
   "outputs": [],
   "source": [
    "def get_sentences(texto):\n",
    "  ## Implementar aqu√≠\n",
    "  lines = texto.splitlines()\n",
    "  sentences_list = []\n",
    "\n",
    "  for line in lines:\n",
    "    if line != '':\n",
    "      sentences_list.append(line)\n",
    "  return sentences_list\n",
    "  ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BbZ8EhgHmR2c",
    "outputId": "fffff52b-dd8d-4ac2-eb94-85112044daa6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[Letra de \"¬°Oh, Algoritmo!\" ft. Nora Erez]',\n",
       " '[Refr√°n: Jorge Drexler]',\n",
       " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
       " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
       " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
       " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
       " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
       " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
       " '[Estribillo: Jorge Drexler]',\n",
       " 'Dime qu√© debo cantar',\n",
       " 'Oh, algoritmo',\n",
       " 'S√© que lo sabes mejor',\n",
       " 'Incluso que yo mismo',\n",
       " '[Verso 1: Nora Erez]',\n",
       " \"Wait, what's that money that you spent?\",\n",
       " \"What's that sitting on your plate?\",\n",
       " \"Do you want what you've been fed?\",\n",
       " 'Are you the fish or bait?',\n",
       " \"Mmm, I'm on the top of the roof and I feel like a jail\",\n",
       " 'Rather not pay the bail',\n",
       " 'To dangerous people with blood on their faces',\n",
       " \"So I'm sharing a cell with the masses\",\n",
       " 'The underground always strive for the main',\n",
       " \"Streaming like Grande's big-ass ring\",\n",
       " \"Screaming: I'll write you out my will\",\n",
       " 'Conscious is free, but not the will',\n",
       " 'Conscious is free, but not the will',\n",
       " 'You might also like',\n",
       " 'Amor al Arte',\n",
       " 'Jorge Drexler',\n",
       " 'Tinta y Tiempo',\n",
       " 'Jorge Drexler',\n",
       " 'Asilo',\n",
       " 'Jorge Drexler',\n",
       " '[Pre-Estribillo: Nora Erez]',\n",
       " 'So if you want me to want what I believe that I want',\n",
       " 'Can I choose to quit?',\n",
       " '[Estribillo: Jorge Drexler]',\n",
       " 'Dime qu√© debo cantar',\n",
       " 'Oh, algoritmo',\n",
       " 'S√© que lo sabes mejor',\n",
       " 'Incluso que yo mismo',\n",
       " '[Verso 2: Jorge Drexler]',\n",
       " 'Por ejemplo, esta canci√≥n',\n",
       " '¬øQu√© algoritmo la pari√≥?',\n",
       " 'Me pregunto si fui yo',\n",
       " '¬øLa elegiste o te eligi√≥?',\n",
       " '[Verso 3: Jorge Drexler]',\n",
       " 'Dios era la letra chica al final del papel',\n",
       " 'Ya no contamos con √âl',\n",
       " 'Fin de la Luna de miel',\n",
       " 'Y el libre albedr√≠o es un cauce vac√≠o',\n",
       " 'Un barco que no tiene r√≠o',\n",
       " 'Ni timonel',\n",
       " '[Verso 4: Jorge Drexler]',\n",
       " 'Todos aplauden, t√∫ tambi√©n',\n",
       " 'Pero no queda claro qui√©n',\n",
       " 'Tiene del mango a la sart√©n',\n",
       " 'Del sacrificio',\n",
       " 'Piel o silicio',\n",
       " 'Y el precipicio',\n",
       " 'Dice: Ven, ven, ven',\n",
       " '[Refr√°n: Jorge Drexler]',\n",
       " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
       " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
       " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
       " '(Dime qu√© debo cantar)',\n",
       " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
       " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
       " '(Oh, algoritmo)',\n",
       " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
       " '(S√© que lo sabes mejor)',\n",
       " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
       " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
       " '(Incluso que yo mismo)',\n",
       " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
       " '(Dime qu√© debo cantar)',\n",
       " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
       " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
       " '(Oh, algoritmo)',\n",
       " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
       " '(S√© que lo sabes mejor)',\n",
       " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
       " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
       " '(Incluso que yo mismo)',\n",
       " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
       " '(Wow)']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oraciones_limpias = get_sentences(texto)\n",
    "oraciones_limpias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kEBzcR6Ym0Us"
   },
   "source": [
    "Deber√≠a obtener en total 87 oraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3pDN1vGEmwRQ",
    "outputId": "d291f5cf-9ef1-4ff3-a989-5948902cc537"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oraciones_limpias) == 87"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fp9dq8omm7cD"
   },
   "source": [
    "Ahora definiremos el conjunto de entrenamiento y prueba para las oraciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zVHoR_-inEK1",
    "outputId": "ed26c737-4fc0-40ad-aa77-d58b3ebab382"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69, 18)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = int(len(oraciones_limpias) * 0.8)\n",
    "train_corpus = oraciones_limpias[:split]\n",
    "test_corpus = oraciones_limpias[split:]\n",
    "\n",
    "len(train_corpus), len(test_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csdw0qNsmjTF"
   },
   "source": [
    "### 6.b Estimaci√≥n de N-gramas (0.5 puntos)\n",
    "\n",
    "Defina una funci√≥n que reciba una lista de oraciones de un corpus y un N que indique el tama√±o de los N-gramas. La funci√≥n debe retornar un diccionario de Python donde la llave es un token (o palabra) y el valor es la cantidad de veces que ocurre el token, es decir, la frecuencia. En el caso de N-gramas con N mayor a 1 (como bi-gramas o tri-gramas) debe a√±adir un token especial al inicio o final de cada oraci√≥n seg√∫n corresponda (ver clases del curso)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "bB2_1y1etIBF"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "Lbrl3WVnmRzj"
   },
   "outputs": [],
   "source": [
    "def n_grams(corpus, n=3):\n",
    "  ## Implementar aqu√≠\n",
    "  # Diccionario para almacenar la frecuencia de los tokens\n",
    "  frequency_dict = {}\n",
    "\n",
    "  # Iterar sobre cada oraci√≥n en el corpus\n",
    "  for i in corpus:\n",
    "    #Revisar ac√°, cambiar por word_tokenize\n",
    "    tokens = get_tokens(i)\n",
    "\n",
    "    # Agregar tokens especiales al inicio y final de la oraci√≥n para n-gramas con n > 1\n",
    "    tokens = ['<s>'] * n + tokens + ['</s>']\n",
    "\n",
    "\n",
    "    # Generar n-gramas\n",
    "    for i in range(len(tokens) - n + 1):\n",
    "      ngram = tuple(tokens[i:i + n])\n",
    "\n",
    "      # Actualizar la frecuencia del n-grama en el diccionario\n",
    "      if ngram in frequency_dict:\n",
    "        frequency_dict[ngram] += 1\n",
    "      else:\n",
    "        frequency_dict[ngram] = 1\n",
    "\n",
    "  return frequency_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mAoYncsp3C7u",
    "outputId": "1374919f-1097-41af-a86e-949a1c15980f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('<s>',): 69,\n",
       " ('Letra',): 1,\n",
       " ('de',): 3,\n",
       " ('Oh',): 3,\n",
       " ('Algoritmo',): 1,\n",
       " ('ft',): 1,\n",
       " ('Nora',): 3,\n",
       " ('Erez',): 3,\n",
       " ('</s>',): 69,\n",
       " ('Refr√°n',): 2,\n",
       " ('Jorge',): 10,\n",
       " ('Drexler',): 10,\n",
       " ('Qui√©n',): 11,\n",
       " ('quiere',): 11,\n",
       " ('que',): 38,\n",
       " ('yo',): 14,\n",
       " ('quiera',): 11,\n",
       " ('lo',): 13,\n",
       " ('creo',): 11,\n",
       " ('quiero',): 11,\n",
       " ('Estribillo',): 3,\n",
       " ('Dime',): 3,\n",
       " ('qu√©',): 3,\n",
       " ('debo',): 3,\n",
       " ('cantar',): 3,\n",
       " ('algoritmo',): 3,\n",
       " ('S√©',): 2,\n",
       " ('sabes',): 2,\n",
       " ('mejor',): 2,\n",
       " ('Incluso',): 2,\n",
       " ('mismo',): 2,\n",
       " ('Verso',): 4,\n",
       " ('1',): 1,\n",
       " ('Wait',): 1,\n",
       " ('what',): 3,\n",
       " ('s',): 3,\n",
       " ('that',): 4,\n",
       " ('money',): 1,\n",
       " ('you',): 6,\n",
       " ('spent',): 1,\n",
       " ('What',): 1,\n",
       " ('sitting',): 1,\n",
       " ('on',): 3,\n",
       " ('your',): 1,\n",
       " ('plate',): 1,\n",
       " ('Do',): 1,\n",
       " ('want',): 4,\n",
       " ('ve',): 1,\n",
       " ('been',): 1,\n",
       " ('fed',): 1,\n",
       " ('Are',): 1,\n",
       " ('the',): 8,\n",
       " ('fish',): 1,\n",
       " ('or',): 1,\n",
       " ('bait',): 1,\n",
       " ('Mmm',): 1,\n",
       " ('I',): 7,\n",
       " ('m',): 2,\n",
       " ('top',): 1,\n",
       " ('of',): 1,\n",
       " ('roof',): 1,\n",
       " ('and',): 1,\n",
       " ('feel',): 1,\n",
       " ('like',): 3,\n",
       " ('a',): 3,\n",
       " ('jail',): 1,\n",
       " ('Rather',): 1,\n",
       " ('not',): 3,\n",
       " ('pay',): 1,\n",
       " ('bail',): 1,\n",
       " ('To',): 1,\n",
       " ('dangerous',): 1,\n",
       " ('people',): 1,\n",
       " ('with',): 2,\n",
       " ('blood',): 1,\n",
       " ('their',): 1,\n",
       " ('faces',): 1,\n",
       " ('So',): 2,\n",
       " ('sharing',): 1,\n",
       " ('cell',): 1,\n",
       " ('masses',): 1,\n",
       " ('The',): 1,\n",
       " ('underground',): 1,\n",
       " ('always',): 1,\n",
       " ('strive',): 1,\n",
       " ('for',): 1,\n",
       " ('main',): 1,\n",
       " ('Streaming',): 1,\n",
       " ('Grande',): 1,\n",
       " ('big',): 1,\n",
       " ('ass',): 1,\n",
       " ('ring',): 1,\n",
       " ('Screaming',): 1,\n",
       " ('ll',): 1,\n",
       " ('write',): 1,\n",
       " ('out',): 1,\n",
       " ('my',): 1,\n",
       " ('will',): 3,\n",
       " ('Conscious',): 2,\n",
       " ('is',): 2,\n",
       " ('free',): 2,\n",
       " ('but',): 2,\n",
       " ('You',): 1,\n",
       " ('might',): 1,\n",
       " ('also',): 1,\n",
       " ('Amor',): 1,\n",
       " ('al',): 2,\n",
       " ('Arte',): 1,\n",
       " ('Tinta',): 1,\n",
       " ('y',): 1,\n",
       " ('Tiempo',): 1,\n",
       " ('Asilo',): 1,\n",
       " ('Pre',): 1,\n",
       " ('if',): 1,\n",
       " ('me',): 1,\n",
       " ('to',): 2,\n",
       " ('believe',): 1,\n",
       " ('Can',): 1,\n",
       " ('choose',): 1,\n",
       " ('quit',): 1,\n",
       " ('2',): 1,\n",
       " ('Por',): 1,\n",
       " ('ejemplo',): 1,\n",
       " ('esta',): 1,\n",
       " ('canci√≥n',): 1,\n",
       " ('Qu√©',): 1,\n",
       " ('la',): 4,\n",
       " ('pari√≥',): 1,\n",
       " ('Me',): 1,\n",
       " ('pregunto',): 1,\n",
       " ('si',): 1,\n",
       " ('fui',): 1,\n",
       " ('La',): 1,\n",
       " ('elegiste',): 1,\n",
       " ('o',): 2,\n",
       " ('te',): 1,\n",
       " ('eligi√≥',): 1,\n",
       " ('3',): 1,\n",
       " ('Dios',): 1,\n",
       " ('era',): 1,\n",
       " ('letra',): 1,\n",
       " ('chica',): 1,\n",
       " ('final',): 1,\n",
       " ('del',): 2,\n",
       " ('papel',): 1,\n",
       " ('Ya',): 1,\n",
       " ('no',): 3,\n",
       " ('contamos',): 1,\n",
       " ('con',): 1,\n",
       " ('√âl',): 1,\n",
       " ('Fin',): 1,\n",
       " ('Luna',): 1,\n",
       " ('miel',): 1,\n",
       " ('Y',): 2,\n",
       " ('el',): 2,\n",
       " ('libre',): 1,\n",
       " ('albedr√≠o',): 1,\n",
       " ('es',): 1,\n",
       " ('un',): 1,\n",
       " ('cauce',): 1,\n",
       " ('vac√≠o',): 1,\n",
       " ('Un',): 1,\n",
       " ('barco',): 1,\n",
       " ('tiene',): 1,\n",
       " ('r√≠o',): 1,\n",
       " ('Ni',): 1,\n",
       " ('timonel',): 1,\n",
       " ('4',): 1,\n",
       " ('Todos',): 1,\n",
       " ('aplauden',): 1,\n",
       " ('t√∫',): 1,\n",
       " ('tambi√©n',): 1,\n",
       " ('Pero',): 1,\n",
       " ('queda',): 1,\n",
       " ('claro',): 1,\n",
       " ('qui√©n',): 1,\n",
       " ('Tiene',): 1,\n",
       " ('mango',): 1,\n",
       " ('sart√©n',): 1,\n",
       " ('Del',): 1,\n",
       " ('sacrificio',): 1,\n",
       " ('Piel',): 1,\n",
       " ('silicio',): 1,\n",
       " ('precipicio',): 1,\n",
       " ('Dice',): 1,\n",
       " ('Ven',): 1,\n",
       " ('ven',): 2}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_grams(train_corpus, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A8XDEuRF3Grx",
    "outputId": "1d155200-f731-4598-a7bc-007d9b495286"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('<s>', '<s>'): 69,\n",
       " ('<s>', 'Letra'): 1,\n",
       " ('Letra', 'de'): 1,\n",
       " ('de', 'Oh'): 1,\n",
       " ('Oh', 'Algoritmo'): 1,\n",
       " ('Algoritmo', 'ft'): 1,\n",
       " ('ft', 'Nora'): 1,\n",
       " ('Nora', 'Erez'): 3,\n",
       " ('Erez', '</s>'): 3,\n",
       " ('<s>', 'Refr√°n'): 2,\n",
       " ('Refr√°n', 'Jorge'): 2,\n",
       " ('Jorge', 'Drexler'): 10,\n",
       " ('Drexler', '</s>'): 10,\n",
       " ('<s>', 'Qui√©n'): 11,\n",
       " ('Qui√©n', 'quiere'): 11,\n",
       " ('quiere', 'que'): 11,\n",
       " ('que', 'yo'): 13,\n",
       " ('yo', 'quiera'): 11,\n",
       " ('quiera', 'lo'): 11,\n",
       " ('lo', 'que'): 11,\n",
       " ('que', 'creo'): 11,\n",
       " ('creo', 'que'): 11,\n",
       " ('que', 'quiero'): 11,\n",
       " ('quiero', '</s>'): 11,\n",
       " ('<s>', 'Estribillo'): 2,\n",
       " ('Estribillo', 'Jorge'): 2,\n",
       " ('<s>', 'Dime'): 3,\n",
       " ('Dime', 'qu√©'): 3,\n",
       " ('qu√©', 'debo'): 3,\n",
       " ('debo', 'cantar'): 3,\n",
       " ('cantar', '</s>'): 3,\n",
       " ('<s>', 'Oh'): 2,\n",
       " ('Oh', 'algoritmo'): 2,\n",
       " ('algoritmo', '</s>'): 2,\n",
       " ('<s>', 'S√©'): 2,\n",
       " ('S√©', 'que'): 2,\n",
       " ('que', 'lo'): 2,\n",
       " ('lo', 'sabes'): 2,\n",
       " ('sabes', 'mejor'): 2,\n",
       " ('mejor', '</s>'): 2,\n",
       " ('<s>', 'Incluso'): 2,\n",
       " ('Incluso', 'que'): 2,\n",
       " ('yo', 'mismo'): 2,\n",
       " ('mismo', '</s>'): 2,\n",
       " ('<s>', 'Verso'): 4,\n",
       " ('Verso', '1'): 1,\n",
       " ('1', 'Nora'): 1,\n",
       " ('<s>', 'Wait'): 1,\n",
       " ('Wait', 'what'): 1,\n",
       " ('what', 's'): 1,\n",
       " ('s', 'that'): 2,\n",
       " ('that', 'money'): 1,\n",
       " ('money', 'that'): 1,\n",
       " ('that', 'you'): 1,\n",
       " ('you', 'spent'): 1,\n",
       " ('spent', '</s>'): 1,\n",
       " ('<s>', 'What'): 1,\n",
       " ('What', 's'): 1,\n",
       " ('that', 'sitting'): 1,\n",
       " ('sitting', 'on'): 1,\n",
       " ('on', 'your'): 1,\n",
       " ('your', 'plate'): 1,\n",
       " ('plate', '</s>'): 1,\n",
       " ('<s>', 'Do'): 1,\n",
       " ('Do', 'you'): 1,\n",
       " ('you', 'want'): 2,\n",
       " ('want', 'what'): 2,\n",
       " ('what', 'you'): 1,\n",
       " ('you', 've'): 1,\n",
       " ('ve', 'been'): 1,\n",
       " ('been', 'fed'): 1,\n",
       " ('fed', '</s>'): 1,\n",
       " ('<s>', 'Are'): 1,\n",
       " ('Are', 'you'): 1,\n",
       " ('you', 'the'): 1,\n",
       " ('the', 'fish'): 1,\n",
       " ('fish', 'or'): 1,\n",
       " ('or', 'bait'): 1,\n",
       " ('bait', '</s>'): 1,\n",
       " ('<s>', 'Mmm'): 1,\n",
       " ('Mmm', 'I'): 1,\n",
       " ('I', 'm'): 2,\n",
       " ('m', 'on'): 1,\n",
       " ('on', 'the'): 1,\n",
       " ('the', 'top'): 1,\n",
       " ('top', 'of'): 1,\n",
       " ('of', 'the'): 1,\n",
       " ('the', 'roof'): 1,\n",
       " ('roof', 'and'): 1,\n",
       " ('and', 'I'): 1,\n",
       " ('I', 'feel'): 1,\n",
       " ('feel', 'like'): 1,\n",
       " ('like', 'a'): 1,\n",
       " ('a', 'jail'): 1,\n",
       " ('jail', '</s>'): 1,\n",
       " ('<s>', 'Rather'): 1,\n",
       " ('Rather', 'not'): 1,\n",
       " ('not', 'pay'): 1,\n",
       " ('pay', 'the'): 1,\n",
       " ('the', 'bail'): 1,\n",
       " ('bail', '</s>'): 1,\n",
       " ('<s>', 'To'): 1,\n",
       " ('To', 'dangerous'): 1,\n",
       " ('dangerous', 'people'): 1,\n",
       " ('people', 'with'): 1,\n",
       " ('with', 'blood'): 1,\n",
       " ('blood', 'on'): 1,\n",
       " ('on', 'their'): 1,\n",
       " ('their', 'faces'): 1,\n",
       " ('faces', '</s>'): 1,\n",
       " ('<s>', 'So'): 2,\n",
       " ('So', 'I'): 1,\n",
       " ('m', 'sharing'): 1,\n",
       " ('sharing', 'a'): 1,\n",
       " ('a', 'cell'): 1,\n",
       " ('cell', 'with'): 1,\n",
       " ('with', 'the'): 1,\n",
       " ('the', 'masses'): 1,\n",
       " ('masses', '</s>'): 1,\n",
       " ('<s>', 'The'): 1,\n",
       " ('The', 'underground'): 1,\n",
       " ('underground', 'always'): 1,\n",
       " ('always', 'strive'): 1,\n",
       " ('strive', 'for'): 1,\n",
       " ('for', 'the'): 1,\n",
       " ('the', 'main'): 1,\n",
       " ('main', '</s>'): 1,\n",
       " ('<s>', 'Streaming'): 1,\n",
       " ('Streaming', 'like'): 1,\n",
       " ('like', 'Grande'): 1,\n",
       " ('Grande', 's'): 1,\n",
       " ('s', 'big'): 1,\n",
       " ('big', 'ass'): 1,\n",
       " ('ass', 'ring'): 1,\n",
       " ('ring', '</s>'): 1,\n",
       " ('<s>', 'Screaming'): 1,\n",
       " ('Screaming', 'I'): 1,\n",
       " ('I', 'll'): 1,\n",
       " ('ll', 'write'): 1,\n",
       " ('write', 'you'): 1,\n",
       " ('you', 'out'): 1,\n",
       " ('out', 'my'): 1,\n",
       " ('my', 'will'): 1,\n",
       " ('will', '</s>'): 3,\n",
       " ('<s>', 'Conscious'): 2,\n",
       " ('Conscious', 'is'): 2,\n",
       " ('is', 'free'): 2,\n",
       " ('free', 'but'): 2,\n",
       " ('but', 'not'): 2,\n",
       " ('not', 'the'): 2,\n",
       " ('the', 'will'): 2,\n",
       " ('<s>', 'You'): 1,\n",
       " ('You', 'might'): 1,\n",
       " ('might', 'also'): 1,\n",
       " ('also', 'like'): 1,\n",
       " ('like', '</s>'): 1,\n",
       " ('<s>', 'Amor'): 1,\n",
       " ('Amor', 'al'): 1,\n",
       " ('al', 'Arte'): 1,\n",
       " ('Arte', '</s>'): 1,\n",
       " ('<s>', 'Jorge'): 3,\n",
       " ('<s>', 'Tinta'): 1,\n",
       " ('Tinta', 'y'): 1,\n",
       " ('y', 'Tiempo'): 1,\n",
       " ('Tiempo', '</s>'): 1,\n",
       " ('<s>', 'Asilo'): 1,\n",
       " ('Asilo', '</s>'): 1,\n",
       " ('<s>', 'Pre'): 1,\n",
       " ('Pre', 'Estribillo'): 1,\n",
       " ('Estribillo', 'Nora'): 1,\n",
       " ('So', 'if'): 1,\n",
       " ('if', 'you'): 1,\n",
       " ('want', 'me'): 1,\n",
       " ('me', 'to'): 1,\n",
       " ('to', 'want'): 1,\n",
       " ('what', 'I'): 1,\n",
       " ('I', 'believe'): 1,\n",
       " ('believe', 'that'): 1,\n",
       " ('that', 'I'): 1,\n",
       " ('I', 'want'): 1,\n",
       " ('want', '</s>'): 1,\n",
       " ('<s>', 'Can'): 1,\n",
       " ('Can', 'I'): 1,\n",
       " ('I', 'choose'): 1,\n",
       " ('choose', 'to'): 1,\n",
       " ('to', 'quit'): 1,\n",
       " ('quit', '</s>'): 1,\n",
       " ('Verso', '2'): 1,\n",
       " ('2', 'Jorge'): 1,\n",
       " ('<s>', 'Por'): 1,\n",
       " ('Por', 'ejemplo'): 1,\n",
       " ('ejemplo', 'esta'): 1,\n",
       " ('esta', 'canci√≥n'): 1,\n",
       " ('canci√≥n', '</s>'): 1,\n",
       " ('<s>', 'Qu√©'): 1,\n",
       " ('Qu√©', 'algoritmo'): 1,\n",
       " ('algoritmo', 'la'): 1,\n",
       " ('la', 'pari√≥'): 1,\n",
       " ('pari√≥', '</s>'): 1,\n",
       " ('<s>', 'Me'): 1,\n",
       " ('Me', 'pregunto'): 1,\n",
       " ('pregunto', 'si'): 1,\n",
       " ('si', 'fui'): 1,\n",
       " ('fui', 'yo'): 1,\n",
       " ('yo', '</s>'): 1,\n",
       " ('<s>', 'La'): 1,\n",
       " ('La', 'elegiste'): 1,\n",
       " ('elegiste', 'o'): 1,\n",
       " ('o', 'te'): 1,\n",
       " ('te', 'eligi√≥'): 1,\n",
       " ('eligi√≥', '</s>'): 1,\n",
       " ('Verso', '3'): 1,\n",
       " ('3', 'Jorge'): 1,\n",
       " ('<s>', 'Dios'): 1,\n",
       " ('Dios', 'era'): 1,\n",
       " ('era', 'la'): 1,\n",
       " ('la', 'letra'): 1,\n",
       " ('letra', 'chica'): 1,\n",
       " ('chica', 'al'): 1,\n",
       " ('al', 'final'): 1,\n",
       " ('final', 'del'): 1,\n",
       " ('del', 'papel'): 1,\n",
       " ('papel', '</s>'): 1,\n",
       " ('<s>', 'Ya'): 1,\n",
       " ('Ya', 'no'): 1,\n",
       " ('no', 'contamos'): 1,\n",
       " ('contamos', 'con'): 1,\n",
       " ('con', '√âl'): 1,\n",
       " ('√âl', '</s>'): 1,\n",
       " ('<s>', 'Fin'): 1,\n",
       " ('Fin', 'de'): 1,\n",
       " ('de', 'la'): 1,\n",
       " ('la', 'Luna'): 1,\n",
       " ('Luna', 'de'): 1,\n",
       " ('de', 'miel'): 1,\n",
       " ('miel', '</s>'): 1,\n",
       " ('<s>', 'Y'): 2,\n",
       " ('Y', 'el'): 2,\n",
       " ('el', 'libre'): 1,\n",
       " ('libre', 'albedr√≠o'): 1,\n",
       " ('albedr√≠o', 'es'): 1,\n",
       " ('es', 'un'): 1,\n",
       " ('un', 'cauce'): 1,\n",
       " ('cauce', 'vac√≠o'): 1,\n",
       " ('vac√≠o', '</s>'): 1,\n",
       " ('<s>', 'Un'): 1,\n",
       " ('Un', 'barco'): 1,\n",
       " ('barco', 'que'): 1,\n",
       " ('que', 'no'): 1,\n",
       " ('no', 'tiene'): 1,\n",
       " ('tiene', 'r√≠o'): 1,\n",
       " ('r√≠o', '</s>'): 1,\n",
       " ('<s>', 'Ni'): 1,\n",
       " ('Ni', 'timonel'): 1,\n",
       " ('timonel', '</s>'): 1,\n",
       " ('Verso', '4'): 1,\n",
       " ('4', 'Jorge'): 1,\n",
       " ('<s>', 'Todos'): 1,\n",
       " ('Todos', 'aplauden'): 1,\n",
       " ('aplauden', 't√∫'): 1,\n",
       " ('t√∫', 'tambi√©n'): 1,\n",
       " ('tambi√©n', '</s>'): 1,\n",
       " ('<s>', 'Pero'): 1,\n",
       " ('Pero', 'no'): 1,\n",
       " ('no', 'queda'): 1,\n",
       " ('queda', 'claro'): 1,\n",
       " ('claro', 'qui√©n'): 1,\n",
       " ('qui√©n', '</s>'): 1,\n",
       " ('<s>', 'Tiene'): 1,\n",
       " ('Tiene', 'del'): 1,\n",
       " ('del', 'mango'): 1,\n",
       " ('mango', 'a'): 1,\n",
       " ('a', 'la'): 1,\n",
       " ('la', 'sart√©n'): 1,\n",
       " ('sart√©n', '</s>'): 1,\n",
       " ('<s>', 'Del'): 1,\n",
       " ('Del', 'sacrificio'): 1,\n",
       " ('sacrificio', '</s>'): 1,\n",
       " ('<s>', 'Piel'): 1,\n",
       " ('Piel', 'o'): 1,\n",
       " ('o', 'silicio'): 1,\n",
       " ('silicio', '</s>'): 1,\n",
       " ('el', 'precipicio'): 1,\n",
       " ('precipicio', '</s>'): 1,\n",
       " ('<s>', 'Dice'): 1,\n",
       " ('Dice', 'Ven'): 1,\n",
       " ('Ven', 'ven'): 1,\n",
       " ('ven', 'ven'): 1,\n",
       " ('ven', '</s>'): 1}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_grams(train_corpus, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jCpbhiXp3Gpg",
    "outputId": "7bf95054-33e6-4b66-8ee9-552a5700d62a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('<s>', '<s>', '<s>'): 69,\n",
       " ('<s>', '<s>', 'Letra'): 1,\n",
       " ('<s>', 'Letra', 'de'): 1,\n",
       " ('Letra', 'de', 'Oh'): 1,\n",
       " ('de', 'Oh', 'Algoritmo'): 1,\n",
       " ('Oh', 'Algoritmo', 'ft'): 1,\n",
       " ('Algoritmo', 'ft', 'Nora'): 1,\n",
       " ('ft', 'Nora', 'Erez'): 1,\n",
       " ('Nora', 'Erez', '</s>'): 3,\n",
       " ('<s>', '<s>', 'Refr√°n'): 2,\n",
       " ('<s>', 'Refr√°n', 'Jorge'): 2,\n",
       " ('Refr√°n', 'Jorge', 'Drexler'): 2,\n",
       " ('Jorge', 'Drexler', '</s>'): 10,\n",
       " ('<s>', '<s>', 'Qui√©n'): 11,\n",
       " ('<s>', 'Qui√©n', 'quiere'): 11,\n",
       " ('Qui√©n', 'quiere', 'que'): 11,\n",
       " ('quiere', 'que', 'yo'): 11,\n",
       " ('que', 'yo', 'quiera'): 11,\n",
       " ('yo', 'quiera', 'lo'): 11,\n",
       " ('quiera', 'lo', 'que'): 11,\n",
       " ('lo', 'que', 'creo'): 11,\n",
       " ('que', 'creo', 'que'): 11,\n",
       " ('creo', 'que', 'quiero'): 11,\n",
       " ('que', 'quiero', '</s>'): 11,\n",
       " ('<s>', '<s>', 'Estribillo'): 2,\n",
       " ('<s>', 'Estribillo', 'Jorge'): 2,\n",
       " ('Estribillo', 'Jorge', 'Drexler'): 2,\n",
       " ('<s>', '<s>', 'Dime'): 3,\n",
       " ('<s>', 'Dime', 'qu√©'): 3,\n",
       " ('Dime', 'qu√©', 'debo'): 3,\n",
       " ('qu√©', 'debo', 'cantar'): 3,\n",
       " ('debo', 'cantar', '</s>'): 3,\n",
       " ('<s>', '<s>', 'Oh'): 2,\n",
       " ('<s>', 'Oh', 'algoritmo'): 2,\n",
       " ('Oh', 'algoritmo', '</s>'): 2,\n",
       " ('<s>', '<s>', 'S√©'): 2,\n",
       " ('<s>', 'S√©', 'que'): 2,\n",
       " ('S√©', 'que', 'lo'): 2,\n",
       " ('que', 'lo', 'sabes'): 2,\n",
       " ('lo', 'sabes', 'mejor'): 2,\n",
       " ('sabes', 'mejor', '</s>'): 2,\n",
       " ('<s>', '<s>', 'Incluso'): 2,\n",
       " ('<s>', 'Incluso', 'que'): 2,\n",
       " ('Incluso', 'que', 'yo'): 2,\n",
       " ('que', 'yo', 'mismo'): 2,\n",
       " ('yo', 'mismo', '</s>'): 2,\n",
       " ('<s>', '<s>', 'Verso'): 4,\n",
       " ('<s>', 'Verso', '1'): 1,\n",
       " ('Verso', '1', 'Nora'): 1,\n",
       " ('1', 'Nora', 'Erez'): 1,\n",
       " ('<s>', '<s>', 'Wait'): 1,\n",
       " ('<s>', 'Wait', 'what'): 1,\n",
       " ('Wait', 'what', 's'): 1,\n",
       " ('what', 's', 'that'): 1,\n",
       " ('s', 'that', 'money'): 1,\n",
       " ('that', 'money', 'that'): 1,\n",
       " ('money', 'that', 'you'): 1,\n",
       " ('that', 'you', 'spent'): 1,\n",
       " ('you', 'spent', '</s>'): 1,\n",
       " ('<s>', '<s>', 'What'): 1,\n",
       " ('<s>', 'What', 's'): 1,\n",
       " ('What', 's', 'that'): 1,\n",
       " ('s', 'that', 'sitting'): 1,\n",
       " ('that', 'sitting', 'on'): 1,\n",
       " ('sitting', 'on', 'your'): 1,\n",
       " ('on', 'your', 'plate'): 1,\n",
       " ('your', 'plate', '</s>'): 1,\n",
       " ('<s>', '<s>', 'Do'): 1,\n",
       " ('<s>', 'Do', 'you'): 1,\n",
       " ('Do', 'you', 'want'): 1,\n",
       " ('you', 'want', 'what'): 1,\n",
       " ('want', 'what', 'you'): 1,\n",
       " ('what', 'you', 've'): 1,\n",
       " ('you', 've', 'been'): 1,\n",
       " ('ve', 'been', 'fed'): 1,\n",
       " ('been', 'fed', '</s>'): 1,\n",
       " ('<s>', '<s>', 'Are'): 1,\n",
       " ('<s>', 'Are', 'you'): 1,\n",
       " ('Are', 'you', 'the'): 1,\n",
       " ('you', 'the', 'fish'): 1,\n",
       " ('the', 'fish', 'or'): 1,\n",
       " ('fish', 'or', 'bait'): 1,\n",
       " ('or', 'bait', '</s>'): 1,\n",
       " ('<s>', '<s>', 'Mmm'): 1,\n",
       " ('<s>', 'Mmm', 'I'): 1,\n",
       " ('Mmm', 'I', 'm'): 1,\n",
       " ('I', 'm', 'on'): 1,\n",
       " ('m', 'on', 'the'): 1,\n",
       " ('on', 'the', 'top'): 1,\n",
       " ('the', 'top', 'of'): 1,\n",
       " ('top', 'of', 'the'): 1,\n",
       " ('of', 'the', 'roof'): 1,\n",
       " ('the', 'roof', 'and'): 1,\n",
       " ('roof', 'and', 'I'): 1,\n",
       " ('and', 'I', 'feel'): 1,\n",
       " ('I', 'feel', 'like'): 1,\n",
       " ('feel', 'like', 'a'): 1,\n",
       " ('like', 'a', 'jail'): 1,\n",
       " ('a', 'jail', '</s>'): 1,\n",
       " ('<s>', '<s>', 'Rather'): 1,\n",
       " ('<s>', 'Rather', 'not'): 1,\n",
       " ('Rather', 'not', 'pay'): 1,\n",
       " ('not', 'pay', 'the'): 1,\n",
       " ('pay', 'the', 'bail'): 1,\n",
       " ('the', 'bail', '</s>'): 1,\n",
       " ('<s>', '<s>', 'To'): 1,\n",
       " ('<s>', 'To', 'dangerous'): 1,\n",
       " ('To', 'dangerous', 'people'): 1,\n",
       " ('dangerous', 'people', 'with'): 1,\n",
       " ('people', 'with', 'blood'): 1,\n",
       " ('with', 'blood', 'on'): 1,\n",
       " ('blood', 'on', 'their'): 1,\n",
       " ('on', 'their', 'faces'): 1,\n",
       " ('their', 'faces', '</s>'): 1,\n",
       " ('<s>', '<s>', 'So'): 2,\n",
       " ('<s>', 'So', 'I'): 1,\n",
       " ('So', 'I', 'm'): 1,\n",
       " ('I', 'm', 'sharing'): 1,\n",
       " ('m', 'sharing', 'a'): 1,\n",
       " ('sharing', 'a', 'cell'): 1,\n",
       " ('a', 'cell', 'with'): 1,\n",
       " ('cell', 'with', 'the'): 1,\n",
       " ('with', 'the', 'masses'): 1,\n",
       " ('the', 'masses', '</s>'): 1,\n",
       " ('<s>', '<s>', 'The'): 1,\n",
       " ('<s>', 'The', 'underground'): 1,\n",
       " ('The', 'underground', 'always'): 1,\n",
       " ('underground', 'always', 'strive'): 1,\n",
       " ('always', 'strive', 'for'): 1,\n",
       " ('strive', 'for', 'the'): 1,\n",
       " ('for', 'the', 'main'): 1,\n",
       " ('the', 'main', '</s>'): 1,\n",
       " ('<s>', '<s>', 'Streaming'): 1,\n",
       " ('<s>', 'Streaming', 'like'): 1,\n",
       " ('Streaming', 'like', 'Grande'): 1,\n",
       " ('like', 'Grande', 's'): 1,\n",
       " ('Grande', 's', 'big'): 1,\n",
       " ('s', 'big', 'ass'): 1,\n",
       " ('big', 'ass', 'ring'): 1,\n",
       " ('ass', 'ring', '</s>'): 1,\n",
       " ('<s>', '<s>', 'Screaming'): 1,\n",
       " ('<s>', 'Screaming', 'I'): 1,\n",
       " ('Screaming', 'I', 'll'): 1,\n",
       " ('I', 'll', 'write'): 1,\n",
       " ('ll', 'write', 'you'): 1,\n",
       " ('write', 'you', 'out'): 1,\n",
       " ('you', 'out', 'my'): 1,\n",
       " ('out', 'my', 'will'): 1,\n",
       " ('my', 'will', '</s>'): 1,\n",
       " ('<s>', '<s>', 'Conscious'): 2,\n",
       " ('<s>', 'Conscious', 'is'): 2,\n",
       " ('Conscious', 'is', 'free'): 2,\n",
       " ('is', 'free', 'but'): 2,\n",
       " ('free', 'but', 'not'): 2,\n",
       " ('but', 'not', 'the'): 2,\n",
       " ('not', 'the', 'will'): 2,\n",
       " ('the', 'will', '</s>'): 2,\n",
       " ('<s>', '<s>', 'You'): 1,\n",
       " ('<s>', 'You', 'might'): 1,\n",
       " ('You', 'might', 'also'): 1,\n",
       " ('might', 'also', 'like'): 1,\n",
       " ('also', 'like', '</s>'): 1,\n",
       " ('<s>', '<s>', 'Amor'): 1,\n",
       " ('<s>', 'Amor', 'al'): 1,\n",
       " ('Amor', 'al', 'Arte'): 1,\n",
       " ('al', 'Arte', '</s>'): 1,\n",
       " ('<s>', '<s>', 'Jorge'): 3,\n",
       " ('<s>', 'Jorge', 'Drexler'): 3,\n",
       " ('<s>', '<s>', 'Tinta'): 1,\n",
       " ('<s>', 'Tinta', 'y'): 1,\n",
       " ('Tinta', 'y', 'Tiempo'): 1,\n",
       " ('y', 'Tiempo', '</s>'): 1,\n",
       " ('<s>', '<s>', 'Asilo'): 1,\n",
       " ('<s>', 'Asilo', '</s>'): 1,\n",
       " ('<s>', '<s>', 'Pre'): 1,\n",
       " ('<s>', 'Pre', 'Estribillo'): 1,\n",
       " ('Pre', 'Estribillo', 'Nora'): 1,\n",
       " ('Estribillo', 'Nora', 'Erez'): 1,\n",
       " ('<s>', 'So', 'if'): 1,\n",
       " ('So', 'if', 'you'): 1,\n",
       " ('if', 'you', 'want'): 1,\n",
       " ('you', 'want', 'me'): 1,\n",
       " ('want', 'me', 'to'): 1,\n",
       " ('me', 'to', 'want'): 1,\n",
       " ('to', 'want', 'what'): 1,\n",
       " ('want', 'what', 'I'): 1,\n",
       " ('what', 'I', 'believe'): 1,\n",
       " ('I', 'believe', 'that'): 1,\n",
       " ('believe', 'that', 'I'): 1,\n",
       " ('that', 'I', 'want'): 1,\n",
       " ('I', 'want', '</s>'): 1,\n",
       " ('<s>', '<s>', 'Can'): 1,\n",
       " ('<s>', 'Can', 'I'): 1,\n",
       " ('Can', 'I', 'choose'): 1,\n",
       " ('I', 'choose', 'to'): 1,\n",
       " ('choose', 'to', 'quit'): 1,\n",
       " ('to', 'quit', '</s>'): 1,\n",
       " ('<s>', 'Verso', '2'): 1,\n",
       " ('Verso', '2', 'Jorge'): 1,\n",
       " ('2', 'Jorge', 'Drexler'): 1,\n",
       " ('<s>', '<s>', 'Por'): 1,\n",
       " ('<s>', 'Por', 'ejemplo'): 1,\n",
       " ('Por', 'ejemplo', 'esta'): 1,\n",
       " ('ejemplo', 'esta', 'canci√≥n'): 1,\n",
       " ('esta', 'canci√≥n', '</s>'): 1,\n",
       " ('<s>', '<s>', 'Qu√©'): 1,\n",
       " ('<s>', 'Qu√©', 'algoritmo'): 1,\n",
       " ('Qu√©', 'algoritmo', 'la'): 1,\n",
       " ('algoritmo', 'la', 'pari√≥'): 1,\n",
       " ('la', 'pari√≥', '</s>'): 1,\n",
       " ('<s>', '<s>', 'Me'): 1,\n",
       " ('<s>', 'Me', 'pregunto'): 1,\n",
       " ('Me', 'pregunto', 'si'): 1,\n",
       " ('pregunto', 'si', 'fui'): 1,\n",
       " ('si', 'fui', 'yo'): 1,\n",
       " ('fui', 'yo', '</s>'): 1,\n",
       " ('<s>', '<s>', 'La'): 1,\n",
       " ('<s>', 'La', 'elegiste'): 1,\n",
       " ('La', 'elegiste', 'o'): 1,\n",
       " ('elegiste', 'o', 'te'): 1,\n",
       " ('o', 'te', 'eligi√≥'): 1,\n",
       " ('te', 'eligi√≥', '</s>'): 1,\n",
       " ('<s>', 'Verso', '3'): 1,\n",
       " ('Verso', '3', 'Jorge'): 1,\n",
       " ('3', 'Jorge', 'Drexler'): 1,\n",
       " ('<s>', '<s>', 'Dios'): 1,\n",
       " ('<s>', 'Dios', 'era'): 1,\n",
       " ('Dios', 'era', 'la'): 1,\n",
       " ('era', 'la', 'letra'): 1,\n",
       " ('la', 'letra', 'chica'): 1,\n",
       " ('letra', 'chica', 'al'): 1,\n",
       " ('chica', 'al', 'final'): 1,\n",
       " ('al', 'final', 'del'): 1,\n",
       " ('final', 'del', 'papel'): 1,\n",
       " ('del', 'papel', '</s>'): 1,\n",
       " ('<s>', '<s>', 'Ya'): 1,\n",
       " ('<s>', 'Ya', 'no'): 1,\n",
       " ('Ya', 'no', 'contamos'): 1,\n",
       " ('no', 'contamos', 'con'): 1,\n",
       " ('contamos', 'con', '√âl'): 1,\n",
       " ('con', '√âl', '</s>'): 1,\n",
       " ('<s>', '<s>', 'Fin'): 1,\n",
       " ('<s>', 'Fin', 'de'): 1,\n",
       " ('Fin', 'de', 'la'): 1,\n",
       " ('de', 'la', 'Luna'): 1,\n",
       " ('la', 'Luna', 'de'): 1,\n",
       " ('Luna', 'de', 'miel'): 1,\n",
       " ('de', 'miel', '</s>'): 1,\n",
       " ('<s>', '<s>', 'Y'): 2,\n",
       " ('<s>', 'Y', 'el'): 2,\n",
       " ('Y', 'el', 'libre'): 1,\n",
       " ('el', 'libre', 'albedr√≠o'): 1,\n",
       " ('libre', 'albedr√≠o', 'es'): 1,\n",
       " ('albedr√≠o', 'es', 'un'): 1,\n",
       " ('es', 'un', 'cauce'): 1,\n",
       " ('un', 'cauce', 'vac√≠o'): 1,\n",
       " ('cauce', 'vac√≠o', '</s>'): 1,\n",
       " ('<s>', '<s>', 'Un'): 1,\n",
       " ('<s>', 'Un', 'barco'): 1,\n",
       " ('Un', 'barco', 'que'): 1,\n",
       " ('barco', 'que', 'no'): 1,\n",
       " ('que', 'no', 'tiene'): 1,\n",
       " ('no', 'tiene', 'r√≠o'): 1,\n",
       " ('tiene', 'r√≠o', '</s>'): 1,\n",
       " ('<s>', '<s>', 'Ni'): 1,\n",
       " ('<s>', 'Ni', 'timonel'): 1,\n",
       " ('Ni', 'timonel', '</s>'): 1,\n",
       " ('<s>', 'Verso', '4'): 1,\n",
       " ('Verso', '4', 'Jorge'): 1,\n",
       " ('4', 'Jorge', 'Drexler'): 1,\n",
       " ('<s>', '<s>', 'Todos'): 1,\n",
       " ('<s>', 'Todos', 'aplauden'): 1,\n",
       " ('Todos', 'aplauden', 't√∫'): 1,\n",
       " ('aplauden', 't√∫', 'tambi√©n'): 1,\n",
       " ('t√∫', 'tambi√©n', '</s>'): 1,\n",
       " ('<s>', '<s>', 'Pero'): 1,\n",
       " ('<s>', 'Pero', 'no'): 1,\n",
       " ('Pero', 'no', 'queda'): 1,\n",
       " ('no', 'queda', 'claro'): 1,\n",
       " ('queda', 'claro', 'qui√©n'): 1,\n",
       " ('claro', 'qui√©n', '</s>'): 1,\n",
       " ('<s>', '<s>', 'Tiene'): 1,\n",
       " ('<s>', 'Tiene', 'del'): 1,\n",
       " ('Tiene', 'del', 'mango'): 1,\n",
       " ('del', 'mango', 'a'): 1,\n",
       " ('mango', 'a', 'la'): 1,\n",
       " ('a', 'la', 'sart√©n'): 1,\n",
       " ('la', 'sart√©n', '</s>'): 1,\n",
       " ('<s>', '<s>', 'Del'): 1,\n",
       " ('<s>', 'Del', 'sacrificio'): 1,\n",
       " ('Del', 'sacrificio', '</s>'): 1,\n",
       " ('<s>', '<s>', 'Piel'): 1,\n",
       " ('<s>', 'Piel', 'o'): 1,\n",
       " ('Piel', 'o', 'silicio'): 1,\n",
       " ('o', 'silicio', '</s>'): 1,\n",
       " ('Y', 'el', 'precipicio'): 1,\n",
       " ('el', 'precipicio', '</s>'): 1,\n",
       " ('<s>', '<s>', 'Dice'): 1,\n",
       " ('<s>', 'Dice', 'Ven'): 1,\n",
       " ('Dice', 'Ven', 'ven'): 1,\n",
       " ('Ven', 'ven', 'ven'): 1,\n",
       " ('ven', 'ven', '</s>'): 1}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_grams(train_corpus, n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jHgEpVPj21fs"
   },
   "source": [
    "Debe mostrar que su m√©todo funciona para $N = 1,2,3$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vMzLfBLBk-i7"
   },
   "source": [
    "## P7. Perplexity (1 punto)\n",
    "\n",
    "En esta secci√≥n evaluar√°n su modelo de n-gramas y determinar√°n la probabilidad de oraciones y la perplejidad con un conjunto de test. Recuerde que la perplejidad se define de la siguiente manera:\n",
    "\n",
    "$$\n",
    "\\text{Perplexity} = 2^{-l} \\quad \\quad l = \\frac{1}{M} \\sum_{i=1}^{m} \\log p(s_i)\n",
    "$$\n",
    "\n",
    "con $m$ el n√∫mero de oraciones del corpus y $M$ el tama√±o del vocabulario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tas4KYhZ28_C"
   },
   "source": [
    "### 7.a Obtener probabilidades (0.5 puntos)\n",
    "\n",
    "En esta secci√≥n implementar√° una funci√≥n que determine la probabilidad de una oraci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYH0ScM44Jrb"
   },
   "source": [
    "Defina una funci√≥n que reciba una oraci√≥n, un diccionario con n-gramas y el valor de $n$. La funci√≥n debe entregar la probabilidad de cualquier oraci√≥n.\n",
    "\n",
    "**Hint**: No olvide los posibles casos borde, como palabras fuera del vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "aWGsq22H4Sxz"
   },
   "outputs": [],
   "source": [
    "def get_probability(sentence, n_grams_frequency, n):\n",
    "  ## Implementar aqu√≠\n",
    "  probability = 1\n",
    "  tokens = get_tokens(sentence)\n",
    "  n_tokens = len(tokens)\n",
    "  # Se a√±ade padding y STOP\n",
    "  tokens = ['<s>'] * (n - 1) + tokens + ['</s>']\n",
    "\n",
    "  # Se recorren los n-gramas\n",
    "  for i in range(n_tokens + 1):\n",
    "    n_gram = tuple(tokens[i:i+n])\n",
    "    n_1_gram = tuple(tokens[i:i+n-1])\n",
    "\n",
    "    # Frecuencias para n-grama y (n-1)-grama\n",
    "    n_gram_freq = n_grams_frequency[n_gram] if n_grams_frequency.get(n_gram) else 0\n",
    "    n_1_gram_freq = n_grams_frequency[n_1_gram] if n_grams_frequency.get(n_1_gram) else 0\n",
    "\n",
    "    # Se ignora si el n-grama no se conoce\n",
    "    if n_gram_freq == 0: continue\n",
    "\n",
    "    probability *= n_gram_freq / n_1_gram_freq\n",
    "\n",
    "  return probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G1UkfOz75W_P"
   },
   "source": [
    "Pruebe su funci√≥n con oraciones frecuentes y comente sus resultados\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ITfzYJx5fqV",
    "outputId": "eb343dde-72ee-41f4-8e3f-e16bac46e474"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13489409141583053\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "\n",
    "n_gram = n_grams(train_corpus, n)\n",
    "n_1_gram = n_grams(train_corpus, n-1)\n",
    "\n",
    "n_gram.update(n_1_gram)\n",
    "\n",
    "print(get_probability('Qui√©n quiere que yo quiera lo que creo que quiero', n_gram, n))\n",
    "print(get_probability('El perro ladra fuerte', n_gram, n))\n",
    "print(get_probability('elegiste letra final cantar', n_gram, n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oV2_oj-Icf7Q"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfnIFV7F3eOL"
   },
   "source": [
    "### 7.b Perplexity en conjunto de test (0.5 puntos)\n",
    "\n",
    "En esta sub-secci√≥n deber√° calcular la perplejidad del corpus de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N21I_mPl5Cqx"
   },
   "source": [
    "Defina una funci√≥n que reciba un corpus de test y retorne la perplexity (ver clases del curso). Utilice la funci√≥n de la secci√≥n anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "VC4Vbk3q5LsY"
   },
   "outputs": [],
   "source": [
    "def corpus_size(corpus):\n",
    "  size = 0\n",
    "  for sentence in corpus:\n",
    "    tokens = get_tokens(sentence)\n",
    "    size += len(tokens)\n",
    "  return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "Pdnl3Fy88z7l"
   },
   "outputs": [],
   "source": [
    "def get_perplexity(corpus, n):\n",
    "  ## implementar aqu√≠\n",
    "  n_grams_frequency = n_grams(train_corpus, n)\n",
    "  n_1_grams_frequency = n_grams(train_corpus, n-1) if n > 1 else {(): corpus_size(train_corpus)}\n",
    "  n_grams_frequency.update(n_1_grams_frequency)\n",
    "\n",
    "  M = corpus_size(corpus)\n",
    "  sum_prob = 0\n",
    "  for sentence in corpus:\n",
    "    sum_prob += np.log2(get_probability(sentence, n_grams_frequency, n))\n",
    "\n",
    "  l = sum_prob / M\n",
    "\n",
    "  return 2**(-l)\n",
    "  ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OAjpRDoG5sUJ",
    "outputId": "591cb582-232d-4b5c-bcef-938b8a2c22e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.46110496358599"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_perplexity(test_corpus, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E8SXx9t8Mcy0",
    "outputId": "e4ba2789-c8a0-4d6c-88f2-f0ee6bb24da4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_vocab(test_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhc07wXM5gyI"
   },
   "source": [
    "D√© una interpretacion de la perplexity en el corpus de test:\n",
    "\n",
    "**RESPUESTA:** En t√©rminos generales, la perplejidad de un modelo de lenguaje contrasta un modelo de lenguaje de probabilidad uniforme, donde la perplejidad de base es igual al tama√±o del vocabulario del corpus, con un modelo de lenguaje que aprovecha las propiedades estad√≠sticas del lenguaje, es decir, que tiene la capacidad de asignar mayores probabilidades a oraciones (n-gramas) que son m√°s frecuentes dentro de un corpus. En esa direcci√≥n, la perplejidad de un modelo de distribuci√≥n uniforme, para el corpus de test, es igual a 20 (que es la extensi√≥n del vocabulario que se puede extraer de √©l). Si dicha cifra la contrastamos con la perplejidad obtenida por el modelo de tri-grama entrenado (1.46), se puede decir que el modelo de lenguaje entrenado a partir de corpus de train, es bastante mejor en t√©rminos de que asigna probabilidades m√°s altas de determinadas oraciones que a otras en el corpus de test. Sin embargo, es necesario decir que la baja perplejidad obtenida por el modelo entrenado, tambi√©n puede explicarse en la medida que las oraciones presentes en el corpus de test, corresponden al coro de la canci√≥n, las que tambi√©n se encuentran en el corpus de train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UYNsmR4OPQQX"
   },
   "source": [
    "## P8. Interpolaci√≥n Lineal (0.5 puntos)\n",
    "\n",
    "Cree una funci√≥n que obtenga la probabilidad de una oraci√≥n interpolando linealmente modelos de unigrama, bigrama y trigrama ponderados por $\\lambda_1, \\lambda_2$ y $\\lambda_3$ respectivamente. Para esto use las funciones que cre√≥ anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "X7kcWusAPPv5"
   },
   "outputs": [],
   "source": [
    "def get_probability_lineal_interpol(sentence, corpus, l_1, l_2, l_3):\n",
    "  ## Implementar aqu√≠\n",
    "  n_grams_frequency = {(): corpus_size(corpus)}\n",
    "  for n in range(1, 4):\n",
    "    n_grams_frequency.update(n_grams(corpus, n))\n",
    "\n",
    "  probability = 1\n",
    "  tokens = get_tokens(sentence)\n",
    "  n_tokens = len(tokens)\n",
    "  # Se a√±ade padding y STOP\n",
    "  tokens = ['<s>', '<s>'] + tokens + ['</s>']\n",
    "\n",
    "  for i in range(n_tokens + 1):\n",
    "\n",
    "    # Se calculan los 3-grama, 2-grama y 1-grama\n",
    "    n_gram_1 = tuple(tokens[i:i+3])\n",
    "    n_1_gram_1 = tuple(tokens[i:i+2])\n",
    "\n",
    "    n_gram_2 = tuple(tokens[i+1:i+3])\n",
    "    n_1_gram_2 = tuple(tokens[i+1:i+2])\n",
    "\n",
    "    n_gram_3 = tuple(tokens[i+2:i+3])\n",
    "    n_1_gram_3 = tuple(tokens[i+3:i+3])\n",
    "\n",
    "    # Se calculan las frecuencias de cada grama\n",
    "    n_gram_1_freq = n_grams_frequency[n_gram_1] if n_grams_frequency.get(n_gram_1) else 0\n",
    "    n_1_gram_1_freq = n_grams_frequency[n_1_gram_1] if n_grams_frequency.get(n_1_gram_1) else 0\n",
    "\n",
    "    n_gram_2_freq = n_grams_frequency[n_gram_2] if n_grams_frequency.get(n_gram_2) else 0\n",
    "    n_1_gram_2_freq = n_grams_frequency[n_1_gram_2] if n_grams_frequency.get(n_1_gram_2) else 0\n",
    "\n",
    "    n_gram_3_freq = n_grams_frequency[n_gram_3] if n_grams_frequency.get(n_gram_3) else 0\n",
    "    n_1_gram_3_freq = n_grams_frequency[n_1_gram_3] if n_grams_frequency.get(n_1_gram_3) else 0\n",
    "\n",
    "    # Se calculan las probabilidades de cada grama\n",
    "    n1_prob = n_gram_1_freq / n_1_gram_1_freq if n_gram_1_freq != 0 else 0\n",
    "    n2_prob = n_gram_2_freq / n_1_gram_2_freq if n_gram_2_freq != 0 else 0\n",
    "    n3_prob = n_gram_3_freq / n_1_gram_3_freq if n_gram_3_freq != 0 else 0\n",
    "\n",
    "    # Si la probabilidad es 0, se pasa al siguiente\n",
    "    if ((n1_prob * l_1) + (n2_prob * l_2) + (n3_prob * l_3)) == 0: continue\n",
    "\n",
    "    probability *= (n1_prob * l_1) + (n2_prob * l_2) + (n3_prob * l_3)\n",
    "\n",
    "  return probability\n",
    "  ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RO1J_E77RQp3"
   },
   "source": [
    "Defina una funci√≥n para calcular la perplejidad de un corpus con interpolaci√≥n lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "oAS94E1UROkg"
   },
   "outputs": [],
   "source": [
    "def get_pp_interpol(corpus, l_1, l_2, l_3):\n",
    "  ## Implementar aqu√≠\n",
    "  M = corpus_size(corpus)\n",
    "  sum_prob = 0\n",
    "  for sentence in corpus:\n",
    "    sum_prob += np.log2(get_probability_lineal_interpol(sentence, train_corpus, l_1, l_2, l_3))\n",
    "\n",
    "  l = sum_prob / M\n",
    "\n",
    "  return 2**(-l)\n",
    "  ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dqoX9_o2SHOY"
   },
   "source": [
    "Ahora haga pruebas con distintos valores de $\\lambda_1, \\lambda_2$ y $\\lambda_3$, incluyendo valores extremos (por ejemplo $[1, 0, 0]$). Comente sus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0PZ2UvohRsvJ",
    "outputId": "c762c840-1120-459b-99fe-de13488acdd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity Interpolaci√≥n uni-grama: 38.9702\n",
      "Perplexity Interpolaci√≥n tri-grama: 1.4611\n",
      "Perplexity Interpolaci√≥n para bi-grama: 2.1914\n",
      "Perplexity Interpolaci√≥n equi-ponderada 2.6197\n"
     ]
    }
   ],
   "source": [
    "print(\"Perplexity Interpolaci√≥n uni-grama:\",get_pp_interpol(test_corpus, 0, 0, 1).round(4))\n",
    "print(\"Perplexity Interpolaci√≥n tri-grama:\",get_pp_interpol(test_corpus, 1, 0, 0).round(4))\n",
    "print(\"Perplexity Interpolaci√≥n para bi-grama:\",get_pp_interpol(test_corpus, 0, 1, 0).round(4))\n",
    "print(\"Perplexity Interpolaci√≥n equi-ponderada\",get_pp_interpol(test_corpus, 0.33, 0.33, 0.34).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SCJVrYbrXsad"
   },
   "source": [
    "An√°lisis:\n",
    "\n",
    "Los resultados de la interpolaci√≥n revela por un lado, que el modelo queda bien definido, resolviendo de forma adecuada el problema del sparness que deben afrontar los modelos probabil√≠sticos de lenguaje (que alguna oraci√≥n no est√© contenida en el corpus de entrenamiento y que s√≠ aparezca en el corpus de test, lo que llevar√≠a a que el modelo quedase indefinido; es decir, no podr√≠a asignar una probabilidad a una determinada oraci√≥n que no haya visto en el corpus de test). Los resultados arrojados para la perplexity seg√∫n hiperpar√°metros extremos (donde s√≥lo a un lambda se asigna el valor de 1, y cero para los dem√°s -dado que por definici√≥n, la suma de los hiperpar√°metros es 1), revela la perplexity m√°s alta para el modelo de uni-grama, la m√°s baja para el modelo de tri-gramas, y una perplexity un poco m√°s alta para el modelo de bi-gramas. Al asignar valores uniformes a los hiperpar√°metros, se observa puede observar una perplexity un poco m√°s alta que para el modelo de bi-gramas, pero a√∫n baja, en comparaci√≥n a la perplexity del modelo de uni-grama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ng8QnX1Rdq21"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
