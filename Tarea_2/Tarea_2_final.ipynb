{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AxrkZWMLZB8z"
   },
   "source": [
    "# Tarea 2: Naive Bayes, Linear Models y Neural Networks\n",
    "**Procesamiento de Lenguaje Natural (CC6205-1 - Oto帽o 2024)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b97b4IJjZGxM"
   },
   "source": [
    "## Tarjeta de identificaci贸n\n",
    "\n",
    "**Nombres:** ```Diego Acevedo, Benjam铆n Aguilar y Luis Montero```\n",
    "\n",
    "**Fecha l铆mite de entrega :** 06/05.\n",
    "\n",
    "**Tiempo estimado de dedicaci贸n:** 4 horas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKcZMFlmZ3b9"
   },
   "source": [
    "## Instrucciones\n",
    "Bienvenid@s a la segunda tarea en el curso de Natural Language Processing (NLP). Esta tarea tiene como objetivo evaluar los contenidos te贸ricos de las 煤ltimas semanas de clases posteriores a la tarea 1, enfocado principalmente en **Naive Bayes**, **Linear Models** y **Neural Networks**. Si a煤n no has visto las clases, se recomienda visitar los links de las referencias.\n",
    "\n",
    "La tarea consta de una una parte pr谩ctica con el f铆n de introducirlos a la programaci贸n en Python enfocada en NLP.\n",
    "\n",
    "* La tarea es en **grupo** (maximo hasta 3 personas).\n",
    "* La entrega es a trav茅s de u-cursos a m谩s tardar el d铆a estipulado arriba. No se aceptan atrasos.\n",
    "* El formato de entrega es este mismo Jupyter Notebook.\n",
    "* Al momento de la revisi贸n su c贸digo ser谩 ejecutado. Por favor verifiquen que su entrega no tenga errores de compilaci贸n.\n",
    "* Completar la tarjeta de identificaci贸n. Sin ella no podr谩 tener nota.\n",
    "\n",
    "> **Importante:** Esta tarea tiene varios resultados experimentales que pueden variar de acuerdo a sus propias implementaciones. No se busca que los resultados sean exactamente los mismos (por ejemplo, que el accuracy fue el mismo que el que esta en la tarea). Lo importante es que implementen sus funciones, las sepan explicar y que puedan hacer varios experimentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnTrhOKraAw2"
   },
   "source": [
    "## Material de referencia\n",
    "\n",
    "Diapositivas del curso \n",
    "    \n",
    "- [Naive Bayes](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-NB.pdf)\n",
    "- [Linear Models](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-linear.pdf)\n",
    "- [Neural Networks](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-neural.pdf)\n",
    "\n",
    "Videos del curso \n",
    "\n",
    "- Naive Bayes: [Parte 1](https://www.youtube.com/watch?v=kG9BK9Oy1hU), [Parte 2](https://www.youtube.com/watch?v=Iqte5kKHvzE), [Parte 3](https://www.youtube.com/watch?v=TSJg0_X3Abk)\n",
    "\n",
    "- Linear Models: [Parte 1](https://www.youtube.com/watch?v=zhBxDsNLZEA), [Parte 2](https://www.youtube.com/watch?v=Fooua_uaWSE), [Parte 3](https://www.youtube.com/watch?v=DqbzhdQa1eQ), [Parte 4](https://www.youtube.com/watch?v=1nfWWXqfAzA)\n",
    "\n",
    "- Neural Networks: [Parte 1](https://www.youtube.com/watch?v=oHZHA8h2xN0), [Parte 2](https://www.youtube.com/watch?v=2lXank0W6G4), [Parte 3](https://www.youtube.com/watch?v=BUDIi9qItzY), [Parte 4](https://www.youtube.com/watch?v=KKN2Ipy-vGk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FmC5SqOZfv1m"
   },
   "source": [
    "## P0. Cargar un dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ldJFqRlCYSa-"
   },
   "source": [
    "Importamos algunas librerias que seran utiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QytPBlbvhsU6",
    "outputId": "de531db1-29a2-40e4-c462-0b0d136d6cc1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\benja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NN-mzGtAYVu-"
   },
   "source": [
    "Inicializamos el dataset con particiones de entrenamiento y test. Es un dataset de clasificacion multi-clase de oraciones. Cada oracion puede tener una unica etiqueta ?, + o -. Donde ? indica que la oracion es una pregunta, - que la oracion es negativa y + positiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bcaT6DquoXOo"
   },
   "outputs": [],
   "source": [
    "document = namedtuple(\n",
    "    \"document\", (\"words\", \"class_\")  # avoid python's keyword collision\n",
    ")\n",
    "\n",
    "raw_train_set = [\n",
    "              ['Do you have plenty of time?', '?'],\n",
    "              ['Does she have enough money?','?'],\n",
    "              ['Did they have any useful advice?','?'],\n",
    "              ['What day is today?','?'],\n",
    "              [\"I don't have much time\",'-'],\n",
    "              [\"She doesn't have any money\",'-'],\n",
    "              [\"They didn't have any advice to offer\",'-'],\n",
    "              ['Have you plenty of time?','?'],\n",
    "              ['Has she enough money?','?'],\n",
    "              ['Had they any useful advice?','?'],\n",
    "              [\"I haven't much time\",'-'],\n",
    "              [\"She hasn't any money\",'-'],\n",
    "              [\"He hadn't any advice to offer\",'-'],\n",
    "              ['How are you?','?'],\n",
    "              ['How do you make questions in English?','?'],\n",
    "              ['How long have you lived here?','?'],\n",
    "              ['How often do you go to the cinema?','?'],\n",
    "              ['How much is this dress?','?'],\n",
    "              ['How old are you?','?'],\n",
    "              ['How many people came to the meeting?','?'],\n",
    "              ['Im from France','+'],\n",
    "              ['I come from the UK','+'],\n",
    "              ['My phone number is 61709832145','+'],\n",
    "              ['I work as a tour guide for a local tour company','+'],\n",
    "              ['Im not dating anyone','-'],\n",
    "              ['I live with my wife and children','+'],\n",
    "              ['I often do morning exercises at 6am','+'],\n",
    "              ['I run everyday','+'],\n",
    "              ['She walks very slowly','+'],\n",
    "              ['They eat a lot of meat daily','+'],\n",
    "              ['We were in France that day', '+'],\n",
    "              ['He speaks very fast', '+'],\n",
    "              ['They told us they came back early', '+'],\n",
    "              [\"I told her I'll be there\", '+']\n",
    "]\n",
    "tokenized_train_set = [document(words=tuple(word_tokenize(d[0].lower())), class_=d[1]) for d in raw_train_set]\n",
    "train_set = pd.DataFrame(data=tokenized_train_set)\n",
    "\n",
    "raw_test_set = [\n",
    "             ['Do you know who lives here?','?'],\n",
    "             ['What time is it?','?'],\n",
    "             ['Can you tell me where she comes from?','?'],\n",
    "             ['How are you?','?'],\n",
    "             ['I fill good today', '+'],\n",
    "             ['There is a lot of history here','+'],\n",
    "             ['I love programming','+'],\n",
    "             ['He told us not to make so much noise','+'],\n",
    "             ['We were asked not to park in front of the house','+'],\n",
    "             [\"I don't have much time\",'-'],\n",
    "             [\"She doesn't have any money\",'-'],\n",
    "             [\"They didn't have any advice to offer\",'-'],\n",
    "             ['I am not really sure','+']\n",
    "]\n",
    "tokenized_test_set = [document(words=tuple(word_tokenize(d[0].lower())), class_=d[1]) for d in raw_test_set]\n",
    "test_set = pd.DataFrame(data=tokenized_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cIkiUTOY8Ep"
   },
   "source": [
    "Separar en X e y, donde X son oraciones tokenizadas e y es la clase a predecir (o target)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "ALoL0Xk9pJhU",
    "outputId": "ff24cc06-2de9-46c0-daf1-297670d257a0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>class_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(i, come, from, the, uk)</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(did, they, have, any, useful, advice, ?)</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(i, have, n't, much, time)</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>(i, told, her, i, 'll, be, there)</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(do, you, have, plenty, of, time, ?)</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(how, much, is, this, dress, ?)</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(he, speaks, very, fast)</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(what, day, is, today, ?)</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(i, run, everyday)</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(i, often, do, morning, exercises, at, 6am)</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          words class_\n",
       "21                     (i, come, from, the, uk)      +\n",
       "2     (did, they, have, any, useful, advice, ?)      ?\n",
       "10                   (i, have, n't, much, time)      -\n",
       "33            (i, told, her, i, 'll, be, there)      +\n",
       "0          (do, you, have, plenty, of, time, ?)      ?\n",
       "17              (how, much, is, this, dress, ?)      ?\n",
       "31                     (he, speaks, very, fast)      +\n",
       "3                     (what, day, is, today, ?)      ?\n",
       "27                           (i, run, everyday)      +\n",
       "26  (i, often, do, morning, exercises, at, 6am)      +"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = train_set.drop(columns=\"class_\"), train_set[\"class_\"]\n",
    "pd.concat([X_train, y_train], axis=1).sample(10, random_state=934)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NSHQ_s9rZE6k"
   },
   "source": [
    "Cantidad de oraciones por clase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "djD7TovViVuB",
    "outputId": "c61bbe00-ebf3-4ed6-a71c-dccfceebd2e2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>+</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>?</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        words\n",
       "class_       \n",
       "+          13\n",
       "-           7\n",
       "?          14"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.groupby(\"class_\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZQNS_HatZKBg"
   },
   "source": [
    "(X, y) para el conjunto de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "5i0O-7-IpLbX",
    "outputId": "84b2ba44-575d-4700-81c6-1b65145e4fe0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>class_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(i, fill, good, today)</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(she, does, n't, have, any, money)</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(there, is, a, lot, of, history, here)</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(what, time, is, it, ?)</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(how, are, you, ?)</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(we, were, asked, not, to, park, in, front, of...</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(i, am, not, really, sure)</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(they, did, n't, have, any, advice, to, offer)</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(can, you, tell, me, where, she, comes, from, ?)</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(i, do, n't, have, much, time)</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                words class_\n",
       "4                              (i, fill, good, today)      +\n",
       "10                 (she, does, n't, have, any, money)      -\n",
       "5              (there, is, a, lot, of, history, here)      +\n",
       "1                             (what, time, is, it, ?)      ?\n",
       "3                                  (how, are, you, ?)      ?\n",
       "8   (we, were, asked, not, to, park, in, front, of...      +\n",
       "12                         (i, am, not, really, sure)      +\n",
       "11     (they, did, n't, have, any, advice, to, offer)      -\n",
       "2    (can, you, tell, me, where, she, comes, from, ?)      ?\n",
       "9                      (i, do, n't, have, much, time)      -"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test = test_set.drop(columns=\"class_\"), test_set[\"class_\"]\n",
    "pd.concat([X_test, y_test], axis=1).sample(10, random_state=934)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZdwzchFGZNmf"
   },
   "source": [
    "Cantidad de oraciones por clase en el conjunto de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "5FXC-oNNpQGw",
    "outputId": "9648b16b-fadc-4c09-da70-2d191b678a9d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>+</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>?</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        words\n",
       "class_       \n",
       "+           6\n",
       "-           3\n",
       "?           4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.groupby(\"class_\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTfP4UGXZUSX"
   },
   "source": [
    "**Importante:** Hasta el momento hemos creado nuestros conjuntos de train y test. A continuacion ustedes deben implementar tres modelos de clasificacion: Naive-bayes, Linear Model y Neural Network. Aqui va un resumen de cada pregunta y lo que se les pide implementar:\n",
    "\n",
    "* P1: Naive-bayes\n",
    " - Implementar `fit` y `predict`\n",
    " - Entrenar\n",
    " - Evaluar\n",
    "\n",
    "* P2: Linear Model\n",
    " - Implementar `fit` con *on-line gradient descent* y `predict`\n",
    " - Entrenar\n",
    " - Evaluar\n",
    "\n",
    "* P3: Neural Network\n",
    " - Implementar un iterador de datos con `datasets` y `dataloaders`\n",
    " - Implementar una red neuronal con `pytorch`\n",
    " - Implementar loop de entrenamiento de una NN\n",
    " - Entrenar\n",
    " - Evaluar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IxYRIr-Ob010"
   },
   "source": [
    "## P1. Implementar y evaluar Multinomial Naive-Bayes (2 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UWZGccxjcFE-"
   },
   "source": [
    "### Clase para clasificador\n",
    "\n",
    "Cree una clase MyMultinomialNB que en su inicializador reciba el par谩metro alpha para su clasficador.\n",
    "\n",
    "Adem谩s, debe implementar los m茅todos `fit(X, y)`y `predict(X)`.\n",
    "\n",
    "```python\n",
    "class MyMultinomialNB():\n",
    "  def __init__(self, alpha, ...):\n",
    "    ...\n",
    "\n",
    "  def fit(self, X, y):\n",
    "    ...\n",
    "  \n",
    "  def predict(self, X):\n",
    "    ...\n",
    "    return prediction\n",
    "```\n",
    "Para computar el entrenamiento de nuestro clasificador debemos:\n",
    "- extraer el vocabulario,\n",
    "- determinar las probabilidades $p(c_j)$ para cada una de las clases posibles,\n",
    "- determinar las probabilidades $p(w_i|c_j)$ para cada una de las palabras y cada una de las clases.\n",
    "\n",
    "Para lograr lo anterior, tambi茅n deber谩n implementar el m茅todo `predict_proba(X)`:\n",
    "\n",
    "```python\n",
    "  def predict_proba(self, X):\n",
    "    return prob\n",
    "```\n",
    "\n",
    "**Underflow prevention:** En vez de hacer muchas multiplicaciones de `float`s, reempl谩cenlas por sumas de logaritmos para prevenir errores de precisi贸n. (Revisen la diapo 26 de las slides).\n",
    "\n",
    "En su implementaci贸n deben considerar la tecnica de *Laplace Smoothing* vista en clases. Especificamente considere que su clase `MyMultinomialNB` reciba un par谩metro `alpha` no negativo (es decir, mayor o igual a cero). De tal forma que el la probabilidad de una palabra $w$ dado la clase $c$ viene dado por lo siguiente:\n",
    "\n",
    "$$\n",
    "p_\\alpha (w|c) = \\frac{\\#(w, c) + \\alpha}{N + \\alpha |V|}\n",
    "$$\n",
    "\n",
    "donde $\\alpha$ es el par谩metro `alpha` de *Laplace Smoothing*. Mientras que los otras notaciones corresponden a\n",
    "\n",
    "* $\\#(w, c)$ numero de veces que ocurre la palabra $w$ en documentos con la clase $c$ (pensar en un gran documento $D_c$ que concatena todos los documentos de clase $c$ y luego calcula la frecuencia de la palabra $w$ en $D_c$),\n",
    "* $N$ es igual a $\\sum \\{\\#(w', c): w' \\in V\\}$ donde $V$ es el vocabulario,\n",
    "* $|V|$ tama帽o del vocabulario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0hFPME1aU9o"
   },
   "source": [
    "### Implementaci贸n (1.5 pts.)\n",
    "\n",
    "Escriba aqu铆 la implementaci贸n de la clase `MyMultinomialNB`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "JU5i9li8g7CS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MyMultinomialNB():\n",
    "    ## Implementar aqu铆 su clase\n",
    "    def __init__(self, classes, alpha=1.0):\n",
    "        self.alpha = alpha\n",
    "        self.classes = classes\n",
    "        self.term_prob = {}\n",
    "        self.prior_prob = {}\n",
    "        self.vocabulary = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Ajusta el modelo a partir de datos de entrenamiento\n",
    "\n",
    "        Args:\n",
    "          X: Serie de pandas con documentos\n",
    "          y: Serie de pandas con clases (\"class_\") de los documentos\n",
    "\n",
    "        Returns:\n",
    "          None\n",
    "        \"\"\"\n",
    "        df = pd.concat([X, y], axis=1)\n",
    "        corpus_size_class = {}\n",
    "        word_per_class = {}\n",
    "\n",
    "        # Primer loop para precalcular valores 煤tiles\n",
    "        for cj in self.classes:\n",
    "            df_cj = df[df[\"class_\"] == cj] # Se filtra por clase\n",
    "            corpus_size_class[cj] = 0\n",
    "            word_per_class[cj] = {}\n",
    "            for phrase in df_cj[\"words\"]:\n",
    "                for word in phrase:\n",
    "                    # Se a帽ade la palabra al vocabulario si no est谩\n",
    "                    if word not in self.vocabulary:\n",
    "                        self.vocabulary.append(word)\n",
    "                    corpus_size_class[cj] += 1\n",
    "                    # Se cuenta la aparici贸n de la palabra en la clase\n",
    "                    if word_per_class[cj].get(word):\n",
    "                        word_per_class[cj][word] += 1\n",
    "                    else:\n",
    "                        word_per_class[cj][word] = 1\n",
    "\n",
    "        # Segundo loop para calcular probabilidades\n",
    "        for cj in self.classes:\n",
    "            df_cj = df[df[\"class_\"] == cj]\n",
    "            # Probabilidad prior, cantidad de documentos de la clase c_j / documentos totales\n",
    "            self.prior_prob[cj] = len(df_cj) / len(df)\n",
    "            self.term_prob[cj] = {}\n",
    "            for word in self.vocabulary:\n",
    "                n_k = word_per_class[cj][word] if word_per_class[cj].get(word) else 0\n",
    "                # Probabilidad de la palabra en un documento de clase c_j\n",
    "                self.term_prob[cj][word] = (n_k + self.alpha) / (corpus_size_class[cj] + self.alpha * len(self.vocabulary))\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predice las clases m谩s probables de una serie de documentos\n",
    "\n",
    "        Args:\n",
    "          X: Serie de pandas con documentos\n",
    "\n",
    "        Returns:\n",
    "          Serie de pandas con las clase de cada documento de X\n",
    "        \"\"\"\n",
    "\n",
    "        pred = []\n",
    "\n",
    "        for phrase in X[\"words\"]:\n",
    "            first = True\n",
    "            pred_class = None, -np.inf\n",
    "            for cj in self.classes:\n",
    "                prob = np.log(self.prior_prob[cj])\n",
    "                for word in phrase:\n",
    "                    if word in self.vocabulary:\n",
    "                        prob += np.log(self.term_prob[cj][word])\n",
    "                _, curr_prob = pred_class\n",
    "                if prob > curr_prob or first:\n",
    "                    first = False\n",
    "                    pred_class = cj, prob\n",
    "            max_class, _ = pred_class\n",
    "            pred.append(max_class)\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eY0j4Ruy0Cxr"
   },
   "source": [
    "### Entrenamiento (0.2 pts.)\n",
    "A continuaci贸n, inicialicen y entrenen (ajusten) su clasificador con los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "EuLl606ZjN4U"
   },
   "outputs": [],
   "source": [
    "nb_model = MyMultinomialNB([\"+\", \"-\", \"?\"], alpha=0.1)\n",
    "nb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvTzP9vPjfFH"
   },
   "source": [
    "Pru茅benlo utilizando el m茅todo `predict()` que implementaron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "j5wph2IQuAzo"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RQtmK4jfi8mP",
    "outputId": "296e2ea1-eb10-44ae-b91a-6bbcd503cc63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['?', '?', '?', '?', '-', '-', '-', '?', '?', '?', '-', '-', '-', '?', '?', '?', '?', '?', '?', '?', '+', '+', '+', '+', '-', '+', '+', '+', '+', '+', '+', '+', '+', '+']\n"
     ]
    }
   ],
   "source": [
    "# Predict train-set\n",
    "y_pred = nb_model.predict(X_train)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "702uKpJLtPJj",
    "outputId": "2a8c549a-939d-410e-f286-b9263b63d30b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           +       1.00      1.00      1.00        13\n",
      "           -       1.00      1.00      1.00         7\n",
      "           ?       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           1.00        34\n",
      "   macro avg       1.00      1.00      1.00        34\n",
      "weighted avg       1.00      1.00      1.00        34\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Metricas en el conjunto de train\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzRqkuso1PWT"
   },
   "source": [
    "### Evaluaci贸n (0.3 pts.)\n",
    "\n",
    "Ahora probar谩n el funcionamiento de su clasificador con un conjunto de test.  Habiendo entrenado su clasificador, clasifiquen los documentos del conjunto de prueba `test_set` usando el m茅todo `predict`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UjMuND9djskK",
    "outputId": "bda9e6b9-d66a-4b18-8620-ccf1fba523b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           +       1.00      0.67      0.80         6\n",
      "           -       0.60      1.00      0.75         3\n",
      "           ?       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           0.85        13\n",
      "   macro avg       0.87      0.89      0.85        13\n",
      "weighted avg       0.91      0.85      0.85        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = nb_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjvzyLHJVFdg"
   },
   "source": [
    "Comenten sus resultados. Estudien que ocurre para alpha=0, 1 y L donde L es un numero muy grande.\n",
    "\n",
    "A partir de los datos de test, se puede observar que el modelo es capaz de predecir con gran precisi贸n las frases de interrogaci贸n,\n",
    "pero le cuesta diferenciar entre frases positivas y negativas. Esto puede ser porque para las interrogaciones, siempre debe haber un\n",
    "signo de interrogaci贸n, por lo que si una frase tiene un signo ? se le asigna una mayor probabilidad de pertenecer a esa clase,\n",
    "mientras que para las negaciones se tienen varios casos de falsos positivos, probablemente porque hay keywords muy comunes en frases\n",
    "negativas, como not, que pueden estar presentes en una frase positiva, como \"he told us not to make so much noise\". De esta forma, el\n",
    "modelo aprendi贸 que not es una frase que muy probablemente es parte de una frase negativa, lo que es cierto, pero es incapaz de examinar\n",
    "con mayor detalle el contexto de la oraci贸n para determinar si efectivamente es una negaci贸n o no.\n",
    "\n",
    "En el caso de usar alpha=0, se tiene el caso donde no se usa suavizado, por lo que se tienen palabras con probabilidad 0, causando que\n",
    "toda la expresi贸n se vaya a 0. Este valor de alpha dio peores resultados que antes (donde se us贸 un valor de 0.1). Para el caso de\n",
    "alpha=1 se tiene la situaci贸n del Add-1, donde todas las palabras tienen al menos una aparici贸n en cada clase. No hay mucha variaci贸n en\n",
    "comparaci贸n con el modelo con alpha=0.1, pero si se perdi贸 precisi贸n con respecto a la predicci贸n de oraciones de interrogaci贸n. Para el\n",
    "caso de alpha=L, se tiene que al ser L un valor muy grande, el valor real del conteo es depreciable, por lo que todas las palabras\n",
    "aparecer铆an de forma equiprobable en el corpus. Esto hace que la predicci贸n solo se realice a partir de la probabilidad prior. Esto\n",
    "genera un mal rendimiento en el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNSdg__vb6J7"
   },
   "source": [
    "## P2. Implementar y evaluar Linear Models (2 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sSlhzDQ5ac3u"
   },
   "source": [
    "### Clase para clasificador\n",
    "\n",
    "Cree una clase MyLinearModel para su clasficador. Debe implementar los m茅todos `fit(X, y, learning_rate, epochs)`y `predict(X)`.\n",
    "\n",
    "```python\n",
    "class MyLinearModel():\n",
    "  def __init__(self, ...):\n",
    "    ...\n",
    "\n",
    "  def fit(self, X, y, learning_rate, epochs):\n",
    "    ...\n",
    "  \n",
    "  def predict(self, X):\n",
    "    ...\n",
    "    return prediction\n",
    "```\n",
    "\n",
    "El modelo lineal que debe implementar viene dado por:\n",
    "$$\n",
    "\\vec{\\hat{y}} = \\text{softmax}(\\vec{x} \\cdot W + \\vec{b})\\\\\n",
    "\\vec{\\hat{y}}_{[i]} = \\frac{\\exp{z_i}}{\\sum_{j} \\exp{z_j}}\\\\\n",
    "z_i = \\vec{x} \\cdot W_{[:, i]} + \\vec{b}_{[i]}\n",
    "$$\n",
    "donde $\\vec{x}$ es un documento representado con bolsas de palabras (BoW), $W$ es la matriz de pesos y $\\vec{b}$ el bias.\n",
    "\n",
    "El modelo linea debe ajustarlo considerando como objetivo minimizar la cross-entropy loss, es decir:\n",
    "\n",
    "$$\n",
    "L_\\text{cross-entropy}(\\vec{\\hat{y}}, \\vec{y}) = - \\sum_i \\vec{y}_{[i]} \\log{ \\left( \\vec{\\hat{y}}_{[i]} \\right) }\n",
    "$$\n",
    "\n",
    "Para representar un documento `(i, am, not, really, sure)` vectorialmente, utilice `CountVectorizer` de sklearn. De esta manera, el documento queda representado como sigue:\n",
    "\n",
    "|    |   i |   he |   am |   are |   not |   yes |   really |   sure |\n",
    "|---:|----:|-----:|-----:|------:|------:|------:|---------:|-------:|\n",
    "|  0 |   1 |    0 |    1 |     0 |     1 |     0 |        1 |      1 |\n",
    "\n",
    "**Observaci贸n:** Si el documento repite palabras entonces tendr谩 un n煤mero mayor a 1. Si el documento no tiene la palabra entonces tiene un 0. Pensar que las palabras `(he, are, yes)` provienen de otros documentos. Recuerde que el `CountVectorizer` se entrena con m谩s de un documento (es decir, un corpus). Aqu铆 debe usar el conjunto de train.\n",
    "\n",
    "El m茅todo `fit(X, y, learning_rate, epochs)` debe ajustar un `CountVectorizer` para representar vectorialmente el documento. Debe guardar el `CountVectorizer` para cuando quiera hacer predicciones. Dentro del m茅todo `fit(X, y, learning_rate, epochs)` debe implementar *On-line gradient descent* (visto en clases), es decir, descenso de gradiente usando un data-point por iteraci贸n. Su m茅todo debe ser capaz de recibir un `learning_rate` para ponderar el gradiente en cada iteraci贸n y fijar un n煤mero de `epochs`. Luego de entrenar debe guardar los pesos de su modelo lineal, es decir, $(W, \\vec{b})$.\n",
    "\n",
    "En el algoritmo de descenso de gradiente usando un data-point por iteraci贸n, o *On-line gradient descent*, debe implementar manualmente las derivadas. Como conoce el modelo lineal y la funcion objetivo, entonces puede calcular manualmente las derivadas. Para ejemplificar, en cada paso del algoritmo de optimizacion debe actualizar los pesos $(W, \\vec{b})$ del siguiente modo:\n",
    "\n",
    "$$\n",
    "W \\leftarrow W - \\lambda \\nabla_{W} L_\\text{cross-entropy}\\\\\n",
    "\\vec{b} \\leftarrow \\vec{b} - \\lambda \\nabla_{\\vec{b}} L_\\text{cross-entropy}\\\\\n",
    "$$\n",
    "donde $\\lambda$ es el par谩metro `learning_rate`, $\\nabla_{W} L_\\text{cross-entropy}$ el gradiente de la Loss con repecto a la matriz de pesos $W$ y $\\nabla_{\\vec{b}} L_\\text{cross-entropy}$ para el bias $\\vec{b}$.\n",
    "\n",
    "Para implementar el algoritmo *On-line gradient descent* les recomendamos (no es obligatorio hacerlo de este modo) definir una funci贸n `get_derivative_W(x, y_target, y_pred, n_classes)` que calcule $\\nabla_{W} L_\\text{cross-entropy}$ y lo mismo con una funci贸n `get_derivative_b(y_target, y_pred, n_classes)` que calcule $\\nabla_{\\vec{b}} L_\\text{cross-entropy}$.\n",
    "\n",
    "Para implementar el m茅todo `predict(self, X)` debera usar su `CountVectorizer` definido en `fit(X, y, learning_rate, epochs)` para representar del mismo modo cualquier documento tanto en train como en test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dqJhGTQS0rpv"
   },
   "source": [
    "### Implementaci贸n (1.5 pts.)\n",
    "Implemente un modelo lineal con m茅todos `fit(X, y)` y `predict(X)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "lO5zE2ArjifE"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Calcula la funci贸n softmax de un vector de entrada\n",
    "    \n",
    "    Args:\n",
    "        x (numpy.ndarray): Vector de entrada\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Resultado de aplicar la funci贸n softmax a x\n",
    "    \"\"\"\n",
    "    soft_max_value = np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True)\n",
    "    return soft_max_value\n",
    "\n",
    "def get_derivative_W(x, y_target, y_pred, n_classes):\n",
    "    \"\"\"Calcula el gradiente de la funci贸n de p茅rdida con respecto a los pesos W\n",
    "    \n",
    "    Args:\n",
    "        x (numpy.ndarray): Vector de caracter铆sticas\n",
    "        y_target (numpy.ndarray): Vector de etiquetas de clase reales\n",
    "        y_pred (numpy.ndarray): Vector de etiquetas de clase predichas\n",
    "        n_classes (int): N煤mero de clases\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Gradiente de la funci贸n de p茅rdida con respecto a los pesos W\n",
    "    \"\"\"\n",
    "    if n_classes == 2:\n",
    "        # Si es un problema de clasificaci贸n binaria\n",
    "        gradient = np.dot(x.T, (y_pred - y_target))\n",
    "    else:\n",
    "        # Si es un problema de clasificaci贸n multiclase\n",
    "        gradient = np.dot(x.T, (y_pred - y_target)) / len(y_target)\n",
    "    return gradient\n",
    "\n",
    "def get_derivative_b(y_target, y_pred, n_classes):\n",
    "    \"\"\"Calcula el gradiente de la funci贸n de p茅rdida con respecto al sesgo b\n",
    "    \n",
    "    Args:\n",
    "        y_target (numpy.ndarray): Vector de etiquetas de clase reales\n",
    "        y_pred (numpy.ndarray): Vector de etiquetas de clase predichas\n",
    "        n_classes (int): N煤mero de clases\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Gradiente de la funci贸n de p茅rdida con respecto al sesgo b\n",
    "    \"\"\"\n",
    "    if n_classes == 2:\n",
    "        # Si es un problema de clasificaci贸n binaria\n",
    "        gradient = np.sum(y_pred - y_target)\n",
    "    else:\n",
    "        # Si es un problema de clasificaci贸n multiclase\n",
    "        gradient = np.sum(y_pred - y_target, axis=0) / len(y_target)\n",
    "    return gradient\n",
    "    \n",
    "def get_preds_tests(X, y, linear_layer):\n",
    "    \"\"\"Obtiene las predicciones y el ground-truth a partir de los datos de entrada\n",
    "    \n",
    "    Args:\n",
    "        X (numpy.ndarray): Datos de entrada\n",
    "        y (numpy.ndarray): Etiquetas de clase reales\n",
    "        linear_layer (dict): Diccionario con los pesos (W) y el sesgo (b) del modelo\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Predicciones del modelo\n",
    "        numpy.ndarray: Ground-truth a partir de las etiquetas de clase reales\n",
    "    \"\"\"\n",
    "    y_pred = softmax(np.dot(X, linear_layer['W']) + linear_layer['b'])\n",
    "    predictions = np.argmax(y_pred, axis=1)\n",
    "    return predictions, y\n",
    "\n",
    "Document = namedtuple(\"Document\", (\"words\", \"class_\"))\n",
    "\n",
    "class MyLinearModel():\n",
    "    def __init__(self):\n",
    "        self.W = None\n",
    "        self.b = None\n",
    "        self.vectorizer = None\n",
    "\n",
    "    def fit(self, X, y, learning_rate, epochs, verbose=False):\n",
    "        \"\"\"Entrena el modelo a partir de datos de entrenamiento\n",
    "\n",
    "        Args:\n",
    "          X: DataFrame de pandas con documentos\n",
    "          y: Serie de pandas con clases de los documentos\n",
    "          learning_rate: tasa de aprendizaje del modelo\n",
    "          epochs: n煤mero de 茅pocas de entrenamiento\n",
    "          verbose: para imprimir mensajes de progreso\n",
    "\n",
    "        Returns:\n",
    "          None\n",
    "        \"\"\"\n",
    "        # Preprocesamiento de los datos\n",
    "        text_data = [' '.join(doc) for doc in X[\"words\"]]\n",
    "        self.vectorizer = CountVectorizer(tokenizer=lambda x: x, stop_words=None)\n",
    "        bow_model = self.vectorizer.fit_transform(text_data)\n",
    "        X_vec = pd.DataFrame(bow_model.toarray())\n",
    "\n",
    "        # Convertir y_train a lista de Python (si no lo est谩)\n",
    "        y_train_list = y.tolist() if isinstance(y, pd.Series) else y\n",
    "\n",
    "        # Crear un diccionario que mapee cada clase 煤nica a un entero\n",
    "        class_to_int = {c: i for i, c in enumerate(np.unique(y_train_list))}\n",
    "\n",
    "        # Convertir los valores de y_train_list a enteros utilizando el diccionario\n",
    "        y_train_int = [class_to_int[c] for c in y_train_list]\n",
    "\n",
    "        # Inicializar pesos y sesgo\n",
    "        n_samples, n_features = X_vec.shape\n",
    "        n_classes = len(np.unique(y_train_list))\n",
    "        self.W = np.zeros((n_features, n_classes))\n",
    "        self.b = np.zeros(n_classes)\n",
    "\n",
    "        # Entrenamiento con descenso de gradiente\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(n_samples):\n",
    "                # Obtener el documento vectorizado y el target\n",
    "                x = X_vec.iloc[i].values.reshape(1, -1)\n",
    "\n",
    "                # Inicializar y_target con el n煤mero de clases 煤nicas\n",
    "                y_target = np.zeros((1, n_classes))\n",
    "\n",
    "                # Asignar 1 a la posici贸n correspondiente al valor de y_train_int\n",
    "                y_target[0, y_train_int[i]] = 1\n",
    "\n",
    "                # Forward pass\n",
    "                z = np.dot(x, self.W) + self.b\n",
    "                y_pred = softmax(z)\n",
    "\n",
    "                # Calcular gradientes\n",
    "                dW = get_derivative_W(x, y_target, y_pred, n_classes)\n",
    "                db = get_derivative_b(y_target, y_pred, n_classes)\n",
    "\n",
    "                # Actualizar pesos y sesgo\n",
    "                self.W -= learning_rate * dW\n",
    "                self.b -= learning_rate * db\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Epoca {epoch} completada!\")\n",
    "\n",
    "            # Calcular precisi贸n despu茅s de todas las 茅pocas\n",
    "            predictions = get_preds_tests(X_vec.values, y_train_int, {'W': self.W, 'b': self.b})\n",
    "        \n",
    "            accuracy = np.mean(predictions == np.array(y_train_int))\n",
    "            print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predice las clases m谩s probables de una serie de documentos\n",
    "\n",
    "        Args:\n",
    "          X: DataFrame de pandas con documentos\n",
    "\n",
    "        Returns:\n",
    "          Serie de pandas con las clase de cada documento de X\n",
    "        \"\"\"\n",
    "        # Preprocesamiento de los datos\n",
    "        X_vec = self.vectorizer.transform([' '.join(doc) for doc in X[\"words\"]])\n",
    "\n",
    "        # Realizar la predicci贸n\n",
    "        y_pred = softmax(X_vec.dot(self.W) + self.b)\n",
    "\n",
    "        # Obtener la clase con la probabilidad m谩s alta para cada documento\n",
    "        predictions = np.argmax(y_pred, axis=1)\n",
    "        label_map = {0: '+', 1: '-', 2: '?'}\n",
    "        predictions = [label_map[pred] for pred in predictions]\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ANT3rY1QkhyZ"
   },
   "source": [
    "### Entrenamiento (0.2 pts.)\n",
    "Inicialicen y entrenen su clasificador con los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YXY8ACuVIRb9",
    "outputId": "e5776a5f-27e9-4d78-cd16-ec3d35fa99db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca 0 completada!\n",
      "Accuracy: 0.6911764705882353\n",
      "Epoca 1 completada!\n",
      "Accuracy: 0.6911764705882353\n",
      "Epoca 2 completada!\n",
      "Accuracy: 0.6911764705882353\n",
      "Epoca 3 completada!\n",
      "Accuracy: 0.6911764705882353\n",
      "Epoca 4 completada!\n",
      "Accuracy: 0.7205882352941176\n",
      "Epoca 5 completada!\n",
      "Accuracy: 0.7352941176470589\n",
      "Epoca 6 completada!\n",
      "Accuracy: 0.8529411764705882\n",
      "Epoca 7 completada!\n",
      "Accuracy: 0.8970588235294118\n",
      "Epoca 8 completada!\n",
      "Accuracy: 0.9411764705882353\n",
      "Epoca 9 completada!\n",
      "Accuracy: 0.9411764705882353\n",
      "Epoca 10 completada!\n",
      "Accuracy: 0.9558823529411765\n",
      "Epoca 11 completada!\n",
      "Accuracy: 0.9852941176470589\n",
      "Epoca 12 completada!\n",
      "Accuracy: 0.9852941176470589\n",
      "Epoca 13 completada!\n",
      "Accuracy: 0.9852941176470589\n",
      "Epoca 14 completada!\n",
      "Accuracy: 0.9852941176470589\n"
     ]
    }
   ],
   "source": [
    "linear_model = MyLinearModel()\n",
    "linear_model.fit(\n",
    "    X_train, y_train,\n",
    "    learning_rate=0.02,\n",
    "    epochs=15,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RDUL-ubzh04B"
   },
   "source": [
    "Pru茅benlo utilizando el m茅todo `predict()` que implementaron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5JKjK3pUwL1w",
    "outputId": "d1fceb7a-70af-4029-a4c7-1a85f2d4c686"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['?', '?', '?', '?', '-', '-', '-', '?', '?', '?', '-', '-', '-', '?', '?', '?', '?', '?', '?', '+', '+', '+', '+', '+', '-', '+', '+', '+', '+', '+', '+', '+', '+', '+']\n"
     ]
    }
   ],
   "source": [
    "# Predict train-set\n",
    "y_pred = linear_model.predict(X_train)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8i6Qiu0RwP-w",
    "outputId": "1d9476ef-8d91-4531-c7f6-2ee2b425044c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           +       0.93      1.00      0.96        13\n",
      "           -       1.00      1.00      1.00         7\n",
      "           ?       1.00      0.93      0.96        14\n",
      "\n",
      "    accuracy                           0.97        34\n",
      "   macro avg       0.98      0.98      0.98        34\n",
      "weighted avg       0.97      0.97      0.97        34\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Metricas en el conjunto de train\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gGzafGqr1GBX"
   },
   "source": [
    "### Evaluaci贸n (0.3 pts.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_3Tj_g-Qh7hD"
   },
   "source": [
    "Ahora probar谩n el funcionamiento de su clasificador con un conjunto de test.  Habiendo entrenado su clasificador, clasifiquen los documentos del conjunto de prueba `test_set` usando el m茅todo `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-03hyMeQ94e0",
    "outputId": "ada077ba-2ba1-49c3-87c0-3a7a66e99c13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           +       0.67      0.67      0.67         6\n",
      "           -       1.00      1.00      1.00         3\n",
      "           ?       0.50      0.50      0.50         4\n",
      "\n",
      "    accuracy                           0.69        13\n",
      "   macro avg       0.72      0.72      0.72        13\n",
      "weighted avg       0.69      0.69      0.69        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = linear_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9gVYYq5h_CU"
   },
   "source": [
    "Comenten sus resultados. Estudien que ocurre para al menos tres combinaciones de learning rates y epochs, por ejemplo `learning_rate, epochs = (0.02, 15), (0.1, 10), (0.005, 30)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primer combinaci贸n de par谩metros (0.02, 15)\n",
    "\n",
    "**learning_rate = 0.02** \n",
    "\n",
    "**epochs = 15**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca 0 completada!\n",
      "Accuracy: 0.6911764705882353\n",
      "Epoca 1 completada!\n",
      "Accuracy: 0.6911764705882353\n",
      "Epoca 2 completada!\n",
      "Accuracy: 0.6911764705882353\n",
      "Epoca 3 completada!\n",
      "Accuracy: 0.6911764705882353\n",
      "Epoca 4 completada!\n",
      "Accuracy: 0.7205882352941176\n",
      "Epoca 5 completada!\n",
      "Accuracy: 0.7352941176470589\n",
      "Epoca 6 completada!\n",
      "Accuracy: 0.8529411764705882\n",
      "Epoca 7 completada!\n",
      "Accuracy: 0.8970588235294118\n",
      "Epoca 8 completada!\n",
      "Accuracy: 0.9411764705882353\n",
      "Epoca 9 completada!\n",
      "Accuracy: 0.9411764705882353\n",
      "Epoca 10 completada!\n",
      "Accuracy: 0.9558823529411765\n",
      "Epoca 11 completada!\n",
      "Accuracy: 0.9852941176470589\n",
      "Epoca 12 completada!\n",
      "Accuracy: 0.9852941176470589\n",
      "Epoca 13 completada!\n",
      "Accuracy: 0.9852941176470589\n",
      "Epoca 14 completada!\n",
      "Accuracy: 0.9852941176470589\n"
     ]
    }
   ],
   "source": [
    "#Entrenamiento del modelo\n",
    "linear_model = MyLinearModel()\n",
    "linear_model.fit(\n",
    "    X_train, y_train,\n",
    "    learning_rate=0.02,\n",
    "    epochs=15,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           +       0.67      0.67      0.67         6\n",
      "           -       1.00      1.00      1.00         3\n",
      "           ?       0.50      0.50      0.50         4\n",
      "\n",
      "    accuracy                           0.69        13\n",
      "   macro avg       0.72      0.72      0.72        13\n",
      "weighted avg       0.69      0.69      0.69        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluaci贸n del modelo\n",
    "y_pred = linear_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segunda combinaci贸n de par谩metros (0.01, 10)\n",
    "\n",
    "**learning_rate = 0.01** \n",
    "\n",
    "**epochs = 10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca 0 completada!\n",
      "Accuracy: 0.6911764705882353\n",
      "Epoca 1 completada!\n",
      "Accuracy: 0.6911764705882353\n",
      "Epoca 2 completada!\n",
      "Accuracy: 0.6911764705882353\n",
      "Epoca 3 completada!\n",
      "Accuracy: 0.7058823529411765\n",
      "Epoca 4 completada!\n",
      "Accuracy: 0.7205882352941176\n",
      "Epoca 5 completada!\n",
      "Accuracy: 0.7352941176470589\n",
      "Epoca 6 completada!\n",
      "Accuracy: 0.8088235294117647\n",
      "Epoca 7 completada!\n",
      "Accuracy: 0.8823529411764706\n",
      "Epoca 8 completada!\n",
      "Accuracy: 0.9117647058823529\n",
      "Epoca 9 completada!\n",
      "Accuracy: 0.9411764705882353\n"
     ]
    }
   ],
   "source": [
    "#Entrenamiento del modelo\n",
    "linear_model = MyLinearModel()\n",
    "linear_model.fit(\n",
    "    X_train, y_train,\n",
    "    learning_rate=0.01,\n",
    "    epochs=10,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           +       0.67      1.00      0.80         6\n",
      "           -       1.00      0.67      0.80         3\n",
      "           ?       1.00      0.50      0.67         4\n",
      "\n",
      "    accuracy                           0.77        13\n",
      "   macro avg       0.89      0.72      0.76        13\n",
      "weighted avg       0.85      0.77      0.76        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluaci贸n del modelo\n",
    "y_pred = linear_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tercera combinaci贸n de par谩metros (0.005, 30)\n",
    "\n",
    "**learning_rate = 0.005** \n",
    "\n",
    "**epochs = 30**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca 0 completada!\n",
      "Accuracy: 0.6911764705882353\n",
      "Epoca 1 completada!\n",
      "Accuracy: 0.6911764705882353\n",
      "Epoca 2 completada!\n",
      "Accuracy: 0.6911764705882353\n",
      "Epoca 3 completada!\n",
      "Accuracy: 0.7205882352941176\n",
      "Epoca 4 completada!\n",
      "Accuracy: 0.7205882352941176\n",
      "Epoca 5 completada!\n",
      "Accuracy: 0.7352941176470589\n",
      "Epoca 6 completada!\n",
      "Accuracy: 0.7794117647058824\n",
      "Epoca 7 completada!\n",
      "Accuracy: 0.8235294117647058\n",
      "Epoca 8 completada!\n",
      "Accuracy: 0.8970588235294118\n",
      "Epoca 9 completada!\n",
      "Accuracy: 0.9117647058823529\n",
      "Epoca 10 completada!\n",
      "Accuracy: 0.9117647058823529\n",
      "Epoca 11 completada!\n",
      "Accuracy: 0.9558823529411765\n",
      "Epoca 12 completada!\n",
      "Accuracy: 0.9705882352941176\n",
      "Epoca 13 completada!\n",
      "Accuracy: 0.9852941176470589\n",
      "Epoca 14 completada!\n",
      "Accuracy: 0.9852941176470589\n",
      "Epoca 15 completada!\n",
      "Accuracy: 0.9852941176470589\n",
      "Epoca 16 completada!\n",
      "Accuracy: 0.9852941176470589\n",
      "Epoca 17 completada!\n",
      "Accuracy: 0.9852941176470589\n",
      "Epoca 18 completada!\n",
      "Accuracy: 0.9852941176470589\n",
      "Epoca 19 completada!\n",
      "Accuracy: 0.9852941176470589\n",
      "Epoca 20 completada!\n",
      "Accuracy: 0.9852941176470589\n",
      "Epoca 21 completada!\n",
      "Accuracy: 0.9852941176470589\n",
      "Epoca 22 completada!\n",
      "Accuracy: 0.9852941176470589\n",
      "Epoca 23 completada!\n",
      "Accuracy: 1.0\n",
      "Epoca 24 completada!\n",
      "Accuracy: 1.0\n",
      "Epoca 25 completada!\n",
      "Accuracy: 1.0\n",
      "Epoca 26 completada!\n",
      "Accuracy: 1.0\n",
      "Epoca 27 completada!\n",
      "Accuracy: 1.0\n",
      "Epoca 28 completada!\n",
      "Accuracy: 1.0\n",
      "Epoca 29 completada!\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Entrenamiento del modelo\n",
    "linear_model = MyLinearModel()\n",
    "linear_model.fit(\n",
    "    X_train, y_train,\n",
    "    learning_rate=0.005,\n",
    "    epochs=30,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           +       0.67      0.67      0.67         6\n",
      "           -       1.00      1.00      1.00         3\n",
      "           ?       0.50      0.50      0.50         4\n",
      "\n",
      "    accuracy                           0.69        13\n",
      "   macro avg       0.72      0.72      0.72        13\n",
      "weighted avg       0.69      0.69      0.69        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluaci贸n del modelo\n",
    "y_pred = linear_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An谩lisis de los resultados en las 3 experimentaciones\n",
    "\n",
    "Tras el an谩lisis de los resultados experimentales obtenidos, se destacan las siguientes observaciones:\n",
    "\n",
    "En el primer grupo de hiperpar谩metros, caracterizado por una tasa de aprendizaje de 0.02 y 15 epochs de entrenamiento, se observa un accuracy en el test de 0.69, un valor que podr铆a considerarse algo bajo para garantizar la fiabilidad del modelo. Es notable que la precisi贸n, el recall y el f1-score para la clase \"-\" alcanzan valores de 1.0 en todas las m茅tricas evaluadas, mientras que las clases \"+\" y \"?\" muestran desequilibrios, generando valores menos precisos.\n",
    "\n",
    "Para el segundo caso, donde se emplea una tasa de aprendizaje de 0.01 y 10 epochs de entrenamiento, se logra mejorar el accuracy del modelo, obteniendo un valor de 0.77, lo que lo hace m谩s confiable. En contraste con el caso anterior, se observa un equilibrio en las m茅tricas de rendimiento entre las tres clases, lo que indica una mejora en la capacidad del modelo para distinguir entre las diferentes clases.\n",
    "\n",
    "En cuanto al tercer caso, con una tasa de aprendizaje de 0.005 y 30 epochs de entrenamiento, se obtienen resultados similares al primer conjunto de hiperpar谩metros, con un accuracy nuevamente de 0.69. De manera consistente, la clase \"-\" muestra un desempe帽o perfecto en todas las m茅tricas evaluadas, mientras que las otras dos clases presentan resultados m谩s variados.\n",
    "\n",
    "En t茅rminos generales, los modelos exhiben una tendencia al sesgo, lo que se traduce en una incapacidad para lograr una convergencia estable en los resultados. Es especialmente notable la dificultad de los modelos para distinguir entre las clasificaciones de \"+\" y \"?\", en contraste con \"-\", que se predice con una precisi贸n perfecta, en dos de las 3 experimentaciones.\n",
    "\n",
    "Adem谩s, se observa que peque帽as variaciones en los hiperpar谩metros provocan un comportamiento err谩tico en el clasificador, lo que resulta en sesgos hacia ciertas clases. De igual manera, resulta interesante notar que con 2 hiperpar谩metros distintos, como es el caso de la experimentaci贸n 1 y 3, se pueden llegar a obtener resultados muy similares\n",
    "\n",
    "Una posible explicaci贸n para este comportamiento err谩tico de accuracy en el total de las experimentaciones podr铆a residir en el tama帽o reducido del corpus de entrenamiento y prueba utilizado en este estudio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a71d7NNCfTna"
   },
   "source": [
    "## P3. Implementar y evaluar Neural Networks (2 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6eCZbdHkVvt"
   },
   "source": [
    "### Especificaciones del clasificador\n",
    "\n",
    "<img src=\"https://docs.google.com/drawings/d/e/2PACX-1vSXJm5I61m6w0RHTwBL-iMyeFLr2wXBrKNYxdU8Bu1ymuCFPD9dAPsCzPfvIqwSr8uCiYvWMdnGy1if/pub?w=818&h=503\" >\n",
    "\n",
    "En esta 煤ltima pregunta, ustedes deber谩nimplementar y evaluar redes neuronales (como la de la figura de arriba). Para esto debera implementar tres secciones principales:\n",
    "\n",
    "1. Secci贸n iterador,\n",
    "2. Secci贸n modelo, y\n",
    "3. Secci贸n loop de entrenamiento.\n",
    "\n",
    "> **Recomendaci贸n:** Para completar esta pregunta puede guiarse del Auxiliar 2 (clase del d铆a 18/04)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HEtleHcI94Ae"
   },
   "source": [
    "*Seccion iterador*\n",
    "\n",
    "Para ayudarnos a con el entrenamiento y testing, vamos a utilizar las clases `Dataset` y `DataLoader` de `pytorch` ([ver documentaci贸n](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)). En esta secci贸n deber谩 implementar un contenedor para su conjunto de datos usando la clase `Dataset` de `pytorch`. Para esto deber谩 crear su propia clase `MyDataset` para gestionar los datos. sto le permitir谩 iterar sobre el conjunto mediante el iterador `DataLoader` de `pytorch` y entrenar sin hacer ning煤n pre-procesamiento extra a los datos.\n",
    "\n",
    "**Observaci贸n:** Si considera por funcionalidad cambiar los par谩metros de la clase `MyDataset` puede hacerlo. Asimismo, puede definir otros par谩metros para los m茅todos de su clase.\n",
    "\n",
    "\n",
    "```python\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, bow_cols):\n",
    "      ...\n",
    "\n",
    "    def __len__(self):\n",
    "      ...\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "      ...\n",
    "      return x_bow, label\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "758StzD796q6"
   },
   "source": [
    "*Secci贸n modelo*\n",
    "\n",
    "En esta secci贸n deber谩n implementar la clase `MyNeuralNetwork` del modulo de `pytorch` llamado `nn.Module` con el proposito de dise帽ar una red neuronal como la figura de arriba. Para mas detalle sobre las redes ver Clase NLP-Neural.pdf Slide n煤mero 8.\n",
    "\n",
    "**Observaci贸n:** La figura de arriba es solo ilustrativa, ustedes pueden variar la dimension input y output de la capa oculta. Sin embargo deben mantener fija la dimension de la entrada y salida de la red. La entrada depende del tama帽o del vocabulario. Mientras que la salida depende de la cantidad de clases de su problema de clasificaci贸n (en nuestro caso igual a 3).\n",
    "\n",
    "Es importante que la clase `MyNeuralNetwork` tenga implementadas apropiadamente el `__init__` con las dimensiones y el `forward` con entrada tipo BoW retornando el 煤ltimo estado de la red (output layer). En el `forward` recomendamos utilizar funciones de activaci贸n tipo `nn.ReLU`. Sin embargo, no es completamente obligatorio por lo que pueden usar otras.\n",
    "\n",
    "```python\n",
    "class MyNeuralNetwork(nn.Module):\n",
    "    def __init__(self,\n",
    "                 dim_vocab,\n",
    "                 num_classes,\n",
    "                 dim_hidden_input,\n",
    "                 dim_hidden_output):\n",
    "\n",
    "        super(MyNeuralNetwork, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "      ...\n",
    "\n",
    "    def forward(self, xs_bow):\n",
    "      ...\n",
    "      return last_state\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1K2ocUUF99X5"
   },
   "source": [
    "*Secci贸n loop de entrenamiento*\n",
    "\n",
    "En esta secci贸n deber谩n implementar el loop de entrenamiento de su red neuronal. Para esto, primero deben definir un `criterion`, en nuestro caso `nn.CrossEntropyLoss()` con la libreria de `pytorch`. Sucesivamente debera definir un optimizador, en nuestro caso `optim.SGD` desde el modulo `optim` de `pytorch`.\n",
    "\n",
    "El loop de entrenamiento debe seguir la siguiente estructura:\n",
    "```python\n",
    "for epoch in range(epochs):\n",
    "  for (xs_bow, labels) in train_loader:\n",
    "    ...\n",
    "```\n",
    "\n",
    "donde `train_loader` proviene del iterador generado en la \"secci贸n iterador\".\n",
    "\n",
    "Dentro de \"doble for\" debera conjugar apropiadamente `opti.zero_grad()`, `loss = criterion(...)`, `loss.backward()` y `opti.step()` con tal de entrenar correctamente su red neuronal. Incluso entrenar, ya que a veces si no se hace de forma correcta entonces tristemente 隆su red no entrena!\n",
    "\n",
    "> **Recomendaci贸n:** Puede guiarse del Auxiliar 2 para implementar el loop de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yi1fdYw3kd-j"
   },
   "source": [
    "### Preparaci贸n de la GPU y los datos de train/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-iWhEKOtgp0"
   },
   "source": [
    "Importar la libreria `pytorch` y `numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zWBi-34WAKnC"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8mprHO5tbJv"
   },
   "source": [
    "Verificar que esta usando GPU. Sino, dir铆gase a **Runtime > Change runtime type** y seleccione la opci贸n **T4 GPU**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nZU9DqaeAX-o",
    "outputId": "47d81b4c-ea07-4b53-f402-00551f5930a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                (do, you, know, who, lives, here, ?)\n",
       "1                             (what, time, is, it, ?)\n",
       "2    (can, you, tell, me, where, she, comes, from, ?)\n",
       "Name: words, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['words'][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3BvxVN-uefp"
   },
   "source": [
    "Preparaci贸n de los conjuntos train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "MfXfl3SZBSmF"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow = CountVectorizer(tokenizer=lambda x: list(x), preprocessor=lambda x: x, token_pattern=None)\n",
    "\n",
    "bow_train = pd.DataFrame(\n",
    "    bow.fit_transform(train_set[\"words\"]).toarray(),\n",
    "    columns=bow.get_feature_names_out()\n",
    ")\n",
    "\n",
    "bow_test = pd.DataFrame(\n",
    "    bow.transform(test_set[\"words\"]).toarray(),\n",
    "    columns=bow.get_feature_names_out()\n",
    ")\n",
    "\n",
    "bow_label_train = bow_train.astype(float).copy()\n",
    "bow_label_test = bow_test.astype(float).copy()\n",
    "\n",
    "map_from_class_to_int = {\n",
    "    \"?\": 0,\n",
    "    \"+\": 1,\n",
    "    \"-\": 2\n",
    "}\n",
    "\n",
    "bow_label_train[\"class_\"] = train_set[\"class_\"] # se a帽ade la clase original a la bolsa de palabras de entrenamiento\n",
    "bow_label_train[\"int_class_\"] = train_set[\"class_\"].apply(lambda x: map_from_class_to_int[x]) # se a帽ade la clase en formato num茅rico\n",
    "\n",
    "bow_label_test[\"class_\"] = test_set[\"class_\"] # se a帽ade la clase original a la bolsa de palabras de test\n",
    "bow_label_test[\"int_class_\"] = test_set[\"class_\"].apply(lambda x: map_from_class_to_int[x]) # se a帽ade la clase en formato num茅rico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4     1\n",
       "10    2\n",
       "5     1\n",
       "1     0\n",
       "3     0\n",
       "Name: int_class_, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_label_test['int_class_'].sample(5, random_state=934)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>'ll</th>\n",
       "      <th>61709832145</th>\n",
       "      <th>6am</th>\n",
       "      <th>?</th>\n",
       "      <th>a</th>\n",
       "      <th>advice</th>\n",
       "      <th>and</th>\n",
       "      <th>any</th>\n",
       "      <th>anyone</th>\n",
       "      <th>are</th>\n",
       "      <th>as</th>\n",
       "      <th>at</th>\n",
       "      <th>back</th>\n",
       "      <th>be</th>\n",
       "      <th>came</th>\n",
       "      <th>children</th>\n",
       "      <th>cinema</th>\n",
       "      <th>come</th>\n",
       "      <th>company</th>\n",
       "      <th>daily</th>\n",
       "      <th>dating</th>\n",
       "      <th>day</th>\n",
       "      <th>did</th>\n",
       "      <th>do</th>\n",
       "      <th>does</th>\n",
       "      <th>dress</th>\n",
       "      <th>early</th>\n",
       "      <th>eat</th>\n",
       "      <th>english</th>\n",
       "      <th>enough</th>\n",
       "      <th>everyday</th>\n",
       "      <th>exercises</th>\n",
       "      <th>fast</th>\n",
       "      <th>for</th>\n",
       "      <th>france</th>\n",
       "      <th>from</th>\n",
       "      <th>go</th>\n",
       "      <th>guide</th>\n",
       "      <th>had</th>\n",
       "      <th>has</th>\n",
       "      <th>have</th>\n",
       "      <th>he</th>\n",
       "      <th>her</th>\n",
       "      <th>here</th>\n",
       "      <th>how</th>\n",
       "      <th>i</th>\n",
       "      <th>in</th>\n",
       "      <th>is</th>\n",
       "      <th>live</th>\n",
       "      <th>lived</th>\n",
       "      <th>local</th>\n",
       "      <th>long</th>\n",
       "      <th>lot</th>\n",
       "      <th>m</th>\n",
       "      <th>make</th>\n",
       "      <th>many</th>\n",
       "      <th>meat</th>\n",
       "      <th>meeting</th>\n",
       "      <th>money</th>\n",
       "      <th>morning</th>\n",
       "      <th>much</th>\n",
       "      <th>my</th>\n",
       "      <th>n't</th>\n",
       "      <th>not</th>\n",
       "      <th>number</th>\n",
       "      <th>of</th>\n",
       "      <th>offer</th>\n",
       "      <th>often</th>\n",
       "      <th>old</th>\n",
       "      <th>people</th>\n",
       "      <th>phone</th>\n",
       "      <th>plenty</th>\n",
       "      <th>questions</th>\n",
       "      <th>run</th>\n",
       "      <th>she</th>\n",
       "      <th>slowly</th>\n",
       "      <th>speaks</th>\n",
       "      <th>that</th>\n",
       "      <th>the</th>\n",
       "      <th>there</th>\n",
       "      <th>they</th>\n",
       "      <th>this</th>\n",
       "      <th>time</th>\n",
       "      <th>to</th>\n",
       "      <th>today</th>\n",
       "      <th>told</th>\n",
       "      <th>tour</th>\n",
       "      <th>uk</th>\n",
       "      <th>us</th>\n",
       "      <th>useful</th>\n",
       "      <th>very</th>\n",
       "      <th>walks</th>\n",
       "      <th>we</th>\n",
       "      <th>were</th>\n",
       "      <th>what</th>\n",
       "      <th>wife</th>\n",
       "      <th>with</th>\n",
       "      <th>work</th>\n",
       "      <th>you</th>\n",
       "      <th></th>\n",
       "      <th>class_</th>\n",
       "      <th>int_class_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>+</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    'll  61709832145  6am    ?    a  advice  and  any  anyone  are   as   at  \\\n",
       "21  0.0          0.0  0.0  0.0  0.0     0.0  0.0  0.0     0.0  0.0  0.0  0.0   \n",
       "2   0.0          0.0  0.0  1.0  0.0     1.0  0.0  1.0     0.0  0.0  0.0  0.0   \n",
       "\n",
       "    back   be  came  children  cinema  come  company  daily  dating  day  did  \\\n",
       "21   0.0  0.0   0.0       0.0     0.0   1.0      0.0    0.0     0.0  0.0  0.0   \n",
       "2    0.0  0.0   0.0       0.0     0.0   0.0      0.0    0.0     0.0  0.0  1.0   \n",
       "\n",
       "     do  does  dress  early  eat  english  enough  everyday  exercises  fast  \\\n",
       "21  0.0   0.0    0.0    0.0  0.0      0.0     0.0       0.0        0.0   0.0   \n",
       "2   0.0   0.0    0.0    0.0  0.0      0.0     0.0       0.0        0.0   0.0   \n",
       "\n",
       "    for  france  from   go  guide  had  has  have   he  her  here  how    i  \\\n",
       "21  0.0     0.0   1.0  0.0    0.0  0.0  0.0   0.0  0.0  0.0   0.0  0.0  1.0   \n",
       "2   0.0     0.0   0.0  0.0    0.0  0.0  0.0   1.0  0.0  0.0   0.0  0.0  0.0   \n",
       "\n",
       "     in   is  live  lived  local  long  lot    m  make  many  meat  meeting  \\\n",
       "21  0.0  0.0   0.0    0.0    0.0   0.0  0.0  0.0   0.0   0.0   0.0      0.0   \n",
       "2   0.0  0.0   0.0    0.0    0.0   0.0  0.0  0.0   0.0   0.0   0.0      0.0   \n",
       "\n",
       "    money  morning  much   my  n't  not  number   of  offer  often  old  \\\n",
       "21    0.0      0.0   0.0  0.0  0.0  0.0     0.0  0.0    0.0    0.0  0.0   \n",
       "2     0.0      0.0   0.0  0.0  0.0  0.0     0.0  0.0    0.0    0.0  0.0   \n",
       "\n",
       "    people  phone  plenty  questions  run  she  slowly  speaks  that  the  \\\n",
       "21     0.0    0.0     0.0        0.0  0.0  0.0     0.0     0.0   0.0  1.0   \n",
       "2      0.0    0.0     0.0        0.0  0.0  0.0     0.0     0.0   0.0  0.0   \n",
       "\n",
       "    there  they  this  time   to  today  told  tour   uk   us  useful  very  \\\n",
       "21    0.0   0.0   0.0   0.0  0.0    0.0   0.0   0.0  1.0  0.0     0.0   0.0   \n",
       "2     0.0   1.0   0.0   0.0  0.0    0.0   0.0   0.0  0.0  0.0     1.0   0.0   \n",
       "\n",
       "    walks   we  were  what  wife  with  work  you     class_  int_class_  \n",
       "21    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  0.0      +           1  \n",
       "2     0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  0.0      ?           0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_label_train.sample(2, random_state=934)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 102)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_label_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jWdzeqbb1reG"
   },
   "source": [
    "### Implementaci贸n (1.7 pts.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1rvXmHBqlUfR"
   },
   "source": [
    "#### Iterador de conjunto de datos\n",
    "Implemente su clase `MyDataset` para acceder al dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se borra columna de clases originales (pues arroja error dado que numpy no maneja strings)\n",
    "\n",
    "bow_label_train.drop(columns=[\"class_\"], inplace=True)\n",
    "bow_label_test.drop(columns=[\"class_\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "7s8tFWCuBCin"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "  # Implementar aqu铆 su iterador de datos\n",
    "\n",
    "    def __init__(self, data, bow_cols):\n",
    "        self.data = data # dataset\n",
    "        self.bow_cols = bow_cols # columnas de bag-of-words\n",
    "        pass\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) # ta帽amo del dataset\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = int(self.data.loc[index,\"int_class_\"]) # obtener la etiqueta (se le asigna un n煤mero a la etiqueta)\n",
    "        x_bow = torch.tensor(self.data.loc[index, self.bow_cols].values, dtype=torch.float32) # \n",
    "        return x_bow, label # retorna la bolsa de palabras y con las etiquetas respectivas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JK7lLpkXup49"
   },
   "source": [
    "Inicializar cada dataloader con sus cotenedor datos para train y test, y n煤mero de batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "UeJi-t9dCi4p"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Se deja un batch de tama帽o 4 para entrenamiento y test\n",
    "\n",
    "# Cargador de datos de entrenamiento\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    MyDataset(data = bow_label_train, bow_cols = bow_train.columns),\n",
    "    batch_size = 4, num_workers = 0, shuffle=False)\n",
    "\n",
    "# Cargador de datos de test\n",
    "test_loader = DataLoader(\n",
    "    MyDataset(data = bow_label_test, bow_cols = bow_test.columns),\n",
    "    batch_size = 4, num_workers = 0, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]) 0\n"
     ]
    }
   ],
   "source": [
    "# Probamos que el iterador funcione correctamente. Se aprecia que se obtiene la bolsa de palabras y la etiqueta para un ejemplo.\n",
    "\n",
    "dat = MyDataset(data = bow_label_train, bow_cols = bow_train.columns)   \n",
    "\n",
    "for file, label in dat:\n",
    "    print(file, label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DdOpdUnicoc"
   },
   "source": [
    "**Ejemplo de prueba para un batch de entrenamiento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]]), tensor([0, 0, 0, 0])]\n",
      "torch.Size([4, 100])\n"
     ]
    }
   ],
   "source": [
    "# Probamos que el cargador de datos funcione correctamente. Se aprecia que se obtiene un batch de tama帽o 4 con la bolsa de palabras y las etiquetas respectivas.\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "print(batch)\n",
    "print(batch[0].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i2qotKTXmDue"
   },
   "source": [
    "#### Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BwBRaPKLhdoU"
   },
   "source": [
    "Implemente a continuaci贸n su red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class MyNeuralNetwork(nn.Module):\n",
    "    def __init__(self,\n",
    "                 dim_vocab, # Tama帽o del vocabulacio\n",
    "                 num_classes, # N煤mero de clases\n",
    "                 dim_hidden_input, # Tama帽o de la capa oculta entrada\n",
    "                 dim_hidden_output): # Tama帽o de la capa oculta salida\n",
    "      \n",
    "        \"\"\"Inicializa la red neuronal\n",
    "        \n",
    "        Los argumentos son: tama帽o del vocabulario, n煤mero de clases, tama帽o de la capa oculta de entrada y tama帽o de la capa oculta de salida\n",
    "        \n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        super(MyNeuralNetwork, self).__init__()\n",
    "        torch.manual_seed(934) # Semilla aleatoria para reproducibilidad\n",
    "    \n",
    "        self.fc1 = nn.Linear(dim_vocab, dim_hidden_input) # 1ra capa oculta lineal. Tama帽o entrada: Dimensi贸n vocabulario (n palabras); Tama帽o salida: Dimensi贸n 1ra capa oculta\n",
    "        self.fc2 = nn.Linear(dim_hidden_input, dim_hidden_output) # 2da capa oculta lineal. Tama帽o entrada: Dimensi贸n 1ra capa oculta; Tama帽o salida: Dimensi贸n 2da capa oculta\n",
    "        self.fc3 = nn.Linear(dim_hidden_output, num_classes) # 3ra capa oculta. Tama帽o entrada: Dimensi贸n 2da capa oculta, con salida de tama帽o numero de classes\n",
    "        self.relu = nn.ReLU(inplace=False) # Funci贸n de activaci贸n ReLU\n",
    "        self.softmax = nn.Softmax(dim=1) # Funci贸n de activaci贸n Softmax ***\n",
    "\n",
    "\n",
    "    def forward(self, xs_bow):\n",
    "      \"\"\"Calcula la ultima capa mediante las capas intermedias de la red\n",
    "      Args:\n",
    "        xs_bow: Tensor\n",
    "\n",
    "      Returns:\n",
    "        Tensor con los valores de prediccion\n",
    "      \"\"\"\n",
    "      ## Implementar aqu铆 el forward-pass\n",
    "      \n",
    "      first_state = self.fc1(xs_bow)\n",
    "      first_state = self.relu(first_state)\n",
    "\n",
    "      hidden_state1 = self.fc2(first_state)\n",
    "      hidden_state2 = self.relu(hidden_state1)\n",
    "      \n",
    "      last_state = self.fc3(hidden_state2)\n",
    "\n",
    "      output = self.softmax(last_state)  # Se aplica Softmax a la salida para dar una interpretaci贸n probabil铆stica al resultados de los outputs***\n",
    "\n",
    "      return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jlUntk5IhX26"
   },
   "source": [
    "Ejemplo de prueba para su modelo NN para un batch de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "82_O2fAXEclt",
    "outputId": "39357b9e-c801-4b3e-c1f6-3dfbefcd6b03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2496, 0.5052, 0.2452],\n",
       "        [0.2453, 0.5140, 0.2407],\n",
       "        [0.2496, 0.5003, 0.2501],\n",
       "        [0.2473, 0.4947, 0.2580]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = MyNeuralNetwork(\n",
    "    dim_vocab=len(train_loader.dataset.bow_cols),\n",
    "    num_classes=3,\n",
    "    dim_hidden_input=10,\n",
    "    dim_hidden_output=5).cuda()\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "test(batch[0].cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urgN_j-HlKqm"
   },
   "source": [
    "#### Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8NHDkwwlla-H"
   },
   "source": [
    "Consideren las siguientes funciones que les ser谩n utiles. Si lo desea puede modificarlas a su conveniencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "Nj5Ws_0hlYT0"
   },
   "outputs": [],
   "source": [
    "def get_loss(net, iterator, criterion, device):\n",
    "  net.eval()\n",
    "  total_loss = 0\n",
    "  num_evals = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "     for xs_bow, labels in iterator:\n",
    "      xs_bow, labels = xs_bow.to(device), labels.to(device)\n",
    "      logits = net(xs_bow)\n",
    "      loss = criterion(logits, labels)\n",
    "      total_loss += loss.item() * xs_bow.shape[0]\n",
    "      num_evals += xs_bow.shape[0]\n",
    "\n",
    "  return total_loss / num_evals\n",
    "\n",
    "\n",
    "def get_preds_tests_nn(net, iterator, device):\n",
    "  net.eval()\n",
    "  preds, tests = [], []\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    for xs_bow, labels in iterator:\n",
    "        xs_bow, labels = xs_bow.to(device), labels.to(device)\n",
    "        logits = net(xs_bow)\n",
    "        soft_probs = nn.Sigmoid()(logits)\n",
    "        preds += np.argmax(soft_probs.tolist(), axis=1).tolist()\n",
    "        tests += labels.tolist()\n",
    "\n",
    "  return np.array(preds), np.array(tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2ASceXqlblb"
   },
   "source": [
    "A continuaci贸n, inicialicen y entrenen su clasificador con los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gh2sqTWXGCmK",
    "outputId": "15c723f9-ce5e-4553-a07d-0cc3efff615e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca 14 completada! Loss: 0.7329799497828764 Accuracy: 0.7941176470588235\n",
      "Epoca 14 completada en 0 minutos, 0 segundos\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "params = {\n",
    "    \"dim_vocab\": len(train_loader.dataset.bow_cols),\n",
    "    \"num_classes\": 3,\n",
    "    \"dim_hidden_input\": 5,\n",
    "    \"dim_hidden_output\": 5,\n",
    "    \"learning_rate\": 0.4,\n",
    "    \"epochs\": 15\n",
    "}\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # Se dispone de GPU en local. Se asigna el dispositivo correspondiente\n",
    "\n",
    "# Inicialice su red neuronal\n",
    "net = MyNeuralNetwork(\n",
    "    dim_vocab=params[\"dim_vocab\"],\n",
    "    num_classes=params[\"num_classes\"],\n",
    "    dim_hidden_input=params[\"dim_hidden_input\"],\n",
    "    dim_hidden_output=params[\"dim_hidden_output\"]).to(device)\n",
    "\n",
    "# Definir la Loss = Cross-entropy\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# Definir el optimizador = SGD: Stochastic-gradient Descent\n",
    "opti = optim.SGD(net.parameters(), lr = params[\"learning_rate\"])\n",
    "\n",
    "# Definir el numero de epocas de entrenamiento\n",
    "epochs = params[\"epochs\"]\n",
    "import time\n",
    "\n",
    "## Implementar desde aqui el ciclo de entrenamiento\n",
    "## para cada epoca en el conjunto de train\n",
    "for epoch in range(epochs):\n",
    "  start_time = time.time()\n",
    "  for (xs_bow, labels) in train_loader:\n",
    "    opti.zero_grad()\n",
    "    \n",
    "    xs_bow, labels = xs_bow.to(device), labels.to(device)\n",
    "    logits = net(xs_bow)\n",
    "    loss = criterion(logits, labels)\n",
    "    loss.backward()\n",
    "    opti.step()\n",
    "\n",
    "\n",
    "total_loss = get_loss(net, train_loader, criterion, device)\n",
    "y_preds, y_tests = get_preds_tests_nn(net, train_loader, device)\n",
    "acc = (y_preds == y_tests).sum() / y_preds.shape[0]\n",
    "\n",
    "secs = int(time.time() - start_time)\n",
    "mins = secs // 60\n",
    "secs = secs % 60\n",
    "\n",
    "\n",
    "print(\"Epoca {} completada! Loss: {} Accuracy: {}\".format(epoch, total_loss, acc))\n",
    "print(f\"Epoca {epoch} completada en {mins} minutos, {secs} segundos\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sAbQjdlrno1o"
   },
   "source": [
    "Pruebe su modelo entrenado con la funci贸n `get_preds_tests_nn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P1Ncs0lPbYKz",
    "outputId": "79536bb9-82a2-4efe-c628-efe64199fdc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        14\n",
      "           1       0.76      1.00      0.87        13\n",
      "           2       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.79        34\n",
      "   macro avg       0.53      0.67      0.59        34\n",
      "weighted avg       0.63      0.79      0.70        34\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\luian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\luian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Ya no necesitara calcular gradientes para hacer inferencia\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "for param in net.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Calcule el la predicci贸n de su modelo y el ground-truth\n",
    "y_preds, y_tests = get_preds_tests_nn(net, train_loader, device)\n",
    "print(classification_report(y_tests, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-3tp4jR12TR"
   },
   "source": [
    "### Evaluaci贸n (0.3 pts.)\n",
    "\n",
    "Ahora probar谩n el funcionamiento de su clasificador con un conjunto de test.  Habiendo entrenado su clasificador, clasifiquen los documentos del conjunto de prueba `test_set` usando la funci贸n `get_preds_tests_nn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71KR1updZ4eL",
    "outputId": "81dc65e2-d3a2-4880-b222-715db6e36019"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      1.00      0.73         4\n",
      "           1       1.00      1.00      1.00         6\n",
      "           2       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.77        13\n",
      "   macro avg       0.52      0.67      0.58        13\n",
      "weighted avg       0.64      0.77      0.69        13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\luian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\luian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preds, y_tests = get_preds_tests_nn(net, test_loader, device)\n",
    "print(classification_report(y_tests, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1ra combinaci贸n de hiperpar谩metros\n",
    "---  \n",
    "\n",
    "**dim_hidden_input: 4,**  \n",
    "**dim_hidden_output: 4,**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Entrenamiento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca 14 completada en 0 minutos, 0 segundos\n",
      "Train Loss: 1.0986543262706083, Train Accuracy: 0.4117647058823529\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"dim_vocab\": len(train_loader.dataset.bow_cols),\n",
    "    \"num_classes\": 3,\n",
    "    \"dim_hidden_input\": 4,\n",
    "    \"dim_hidden_output\": 4,\n",
    "    \"learning_rate\": 0.4,\n",
    "    \"epochs\": 15\n",
    "}\n",
    "\n",
    "net1 = MyNeuralNetwork(\n",
    "    dim_vocab=params[\"dim_vocab\"],\n",
    "    num_classes=params[\"num_classes\"],\n",
    "    dim_hidden_input=params[\"dim_hidden_input\"],\n",
    "    dim_hidden_output=params[\"dim_hidden_output\"]).to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  start_time = time.time()\n",
    "  for (xs_bow, labels) in train_loader:\n",
    "    opti.zero_grad()\n",
    "    \n",
    "    xs_bow, labels = xs_bow.to(device), labels.to(device)\n",
    "    logits = net1(xs_bow)\n",
    "    loss = criterion(logits, labels)\n",
    "    loss.backward()\n",
    "    opti.step()\n",
    "\n",
    "\n",
    "total_loss = get_loss(net1, train_loader, criterion, device)\n",
    "y_preds, y_tests = get_preds_tests_nn(net1, train_loader, device)\n",
    "acc = (y_preds == y_tests).sum() / y_preds.shape[0]\n",
    "\n",
    "secs = int(time.time() - start_time)\n",
    "mins = secs // 60\n",
    "secs = secs % 60\n",
    "\n",
    "print(f\"Epoca {epoch} completada en {mins} minutos, {secs} segundos\")\n",
    "print(f\"Train Loss: {total_loss}, Train Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Evaluaci贸n del clasificador NN en train y test** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de m茅tricas clasificador en set de entrenamiento:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      1.00      0.58        14\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.41        34\n",
      "   macro avg       0.14      0.33      0.19        34\n",
      "weighted avg       0.17      0.41      0.24        34\n",
      "\n",
      "\n",
      "Reporte de m茅tricas clasificador en set de validaci贸n:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      1.00      0.47         4\n",
      "           1       0.00      0.00      0.00         6\n",
      "           2       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.31        13\n",
      "   macro avg       0.10      0.33      0.16        13\n",
      "weighted avg       0.09      0.31      0.14        13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\luian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\luian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\luian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\luian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\luian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Calcule el la predicci贸n de su modelo y el ground-truth\n",
    "y_preds, y_tests = get_preds_tests_nn(net1, train_loader, device)\n",
    "print(\"Reporte de m茅tricas clasificador en set de entrenamiento:\\n\",classification_report(y_tests, y_preds))\n",
    "\n",
    "y_preds, y_tests = get_preds_tests_nn(net1, test_loader, device)\n",
    "print(\"\\nReporte de m茅tricas clasificador en set de validaci贸n:\\n\",classification_report(y_tests, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2da combinaci贸n de hiperpar谩metros  \n",
    "---  \n",
    "\n",
    "**dim_hidden_input: 6,**  \n",
    "**dim_hidden_output: 6,**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Entrenamiento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca 14 completada en 0 minutos, 0 segundos\n",
      "Train Loss: 1.1191212990704704, Train Accuracy: 0.20588235294117646\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"dim_vocab\": len(train_loader.dataset.bow_cols),\n",
    "    \"num_classes\": 3,\n",
    "    \"dim_hidden_input\": 6,\n",
    "    \"dim_hidden_output\": 6,\n",
    "    \"learning_rate\": 0.4,\n",
    "    \"epochs\": 15\n",
    "}\n",
    "\n",
    "net2 = MyNeuralNetwork(\n",
    "    dim_vocab=params[\"dim_vocab\"],\n",
    "    num_classes=params[\"num_classes\"],\n",
    "    dim_hidden_input=params[\"dim_hidden_input\"],\n",
    "    dim_hidden_output=params[\"dim_hidden_output\"]).to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  start_time = time.time()\n",
    "  for (xs_bow, labels) in train_loader:\n",
    "    opti.zero_grad()\n",
    "    \n",
    "    xs_bow, labels = xs_bow.to(device), labels.to(device)\n",
    "    logits = net2(xs_bow)\n",
    "    loss = criterion(logits, labels)\n",
    "    loss.backward()\n",
    "    opti.step()\n",
    "\n",
    "\n",
    "total_loss = get_loss(net2, train_loader, criterion, device)\n",
    "y_preds, y_tests = get_preds_tests_nn(net2, train_loader, device)\n",
    "acc = (y_preds == y_tests).sum() / y_preds.shape[0]\n",
    "\n",
    "secs = int(time.time() - start_time)\n",
    "mins = secs // 60\n",
    "secs = secs % 60\n",
    "\n",
    "print(f\"Epoca {epoch} completada en {mins} minutos, {secs} segundos\")\n",
    "print(f\"Train Loss: {total_loss}, Train Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Evaluaci贸n**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de m茅tricas clasificador en set de entrenamiento:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.21      1.00      0.34         7\n",
      "\n",
      "    accuracy                           0.21        34\n",
      "   macro avg       0.07      0.33      0.11        34\n",
      "weighted avg       0.04      0.21      0.07        34\n",
      "\n",
      "\n",
      "Reporte de m茅tricas clasificador en set de validaci贸n:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.00      0.00      0.00         6\n",
      "           2       0.23      1.00      0.38         3\n",
      "\n",
      "    accuracy                           0.23        13\n",
      "   macro avg       0.08      0.33      0.12        13\n",
      "weighted avg       0.05      0.23      0.09        13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\luian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\luian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\luian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\luian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\luian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Calcule el la predicci贸n de su modelo y el ground-truth\n",
    "y_preds, y_tests = get_preds_tests_nn(net2, train_loader, device)\n",
    "print(\"Reporte de m茅tricas clasificador en set de entrenamiento:\\n\",classification_report(y_tests, y_preds))\n",
    "\n",
    "y_preds, y_tests = get_preds_tests_nn(net2, test_loader, device)\n",
    "print(\"\\nReporte de m茅tricas clasificador en set de validaci贸n:\\n\",classification_report(y_tests, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3ra combinaci贸n de hiperpar谩metros  \n",
    "---  \n",
    "\n",
    "**dim_hidden_input: 6,**  \n",
    "**dim_hidden_output: 4,**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Entrenamiento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca 14 completada en 0 minutos, 0 segundos\n",
      "Train Loss: 1.096057232688455, Train Accuracy: 0.38235294117647056\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"dim_vocab\": len(train_loader.dataset.bow_cols),\n",
    "    \"num_classes\": 3,\n",
    "    \"dim_hidden_input\": 6,\n",
    "    \"dim_hidden_output\": 4,\n",
    "    \"learning_rate\": 0.4,\n",
    "    \"epochs\": 15\n",
    "}\n",
    "\n",
    "net3 = MyNeuralNetwork(\n",
    "    dim_vocab=params[\"dim_vocab\"],\n",
    "    num_classes=params[\"num_classes\"],\n",
    "    dim_hidden_input=params[\"dim_hidden_input\"],\n",
    "    dim_hidden_output=params[\"dim_hidden_output\"]).to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  start_time = time.time()\n",
    "  for (xs_bow, labels) in train_loader:\n",
    "    opti.zero_grad()\n",
    "    \n",
    "    xs_bow, labels = xs_bow.to(device), labels.to(device)\n",
    "    logits = net2(xs_bow)\n",
    "    loss = criterion(logits, labels)\n",
    "    loss.backward()\n",
    "    opti.step()\n",
    "\n",
    "\n",
    "total_loss = get_loss(net3, train_loader, criterion, device)\n",
    "y_preds, y_tests = get_preds_tests_nn(net3, train_loader, device)\n",
    "acc = (y_preds == y_tests).sum() / y_preds.shape[0]\n",
    "\n",
    "secs = int(time.time() - start_time)\n",
    "mins = secs // 60\n",
    "secs = secs % 60\n",
    "\n",
    "print(f\"Epoca {epoch} completada en {mins} minutos, {secs} segundos\")\n",
    "print(f\"Train Loss: {total_loss}, Train Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Evaluaci贸n**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de m茅tricas clasificador en set de entrenamiento:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.38      1.00      0.55        13\n",
      "           2       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.38        34\n",
      "   macro avg       0.13      0.33      0.18        34\n",
      "weighted avg       0.15      0.38      0.21        34\n",
      "\n",
      "\n",
      "Reporte de m茅tricas clasificador en set de validaci贸n:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.46      1.00      0.63         6\n",
      "           2       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.46        13\n",
      "   macro avg       0.15      0.33      0.21        13\n",
      "weighted avg       0.21      0.46      0.29        13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\luian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\luian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\luian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\luian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\luian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Calcule el la predicci贸n de su modelo y el ground-truth\n",
    "y_preds, y_tests = get_preds_tests_nn(net3, train_loader, device)\n",
    "print(\"Reporte de m茅tricas clasificador en set de entrenamiento:\\n\",classification_report(y_tests, y_preds))\n",
    "\n",
    "y_preds, y_tests = get_preds_tests_nn(net3, test_loader, device)\n",
    "print(\"\\nReporte de m茅tricas clasificador en set de validaci贸n:\\n\",classification_report(y_tests, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Z2BxxUQoINV"
   },
   "source": [
    "Comenten sus resultados. Estudien que ocurre para al menos tres combinaciones de `(dim_hidden_input, dim_hidden_output)`.\n",
    "\n",
    "```\n",
    "Comentar aqu铆. \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANLISIS DE LOS RESUTLADOS DE LOS 3 EXPERIMENTOS IMPLEMENTADOS**  \n",
    "===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar se puede anotar que el modelo de base (con capas ocultas de tama帽o 5 neuronas), arroja en test un accuracy de 0.77 (se debe indicar que se agreg贸 una funci贸n softmax a la capa de salida para dar una interpretaci贸n probabil铆stica a los vectores de salida). Al testear el modelo en los datos de test, se puede apreciar un recall de 1 para las clases 0 (interrogaci贸n) y 1 (clase positiva), pero a costa de la precision. En el caso de la clase negativa, el modelo base no reconoce en los nuevos datos este tipo de texto. Esto se debe a que en entrenamiento no reconoce este tipo de texto. Se puede indicar que el modelo de entrada queda sesgado, pues no reconoce este tipo de oraciones dentro del corpus. De ah铆 que mientras el F1 para la clase positiva sea 1, este indicador queda indefinido para la clase \n",
    "\n",
    "En segundo lugar, al probarse la combinaci贸n de 4 capas ocultas de entrada y de salida, el accuracy en test empeora: desciende a 0.41; quedando el modelo sesgado completamente a la clase 0 (interrogaci贸n). El recall para esa clase es 1 pero a costa de la precision (0.31), dando un F1 Score de 0.47. Dado que el modelo no asigna ning煤n ejemplo del test a las clases restantes, precision y recall es cero, quedando indefinido el F1. \n",
    "\n",
    "En tercer lugar, al probarse la combinaci贸n de 6 capas ocultas de entrada y de salida, nuevamente el accuracy en test empeora: desciende ahora a 0.21; quedando el modelo sesgado completamente a la clase 2 (clase negativa). Nuevamente, el recall para esa clase es 1 pero a costa de la precision (0.23), dando un F1 Score de 0.38. Dado que el modelo no asigna ning煤n ejemplo del test a las clases restantes, precision y recall es cero, quedando indefinido en ambos casos el F1. \n",
    "\n",
    "Por 煤ltimo, al probarse la combinaci贸n de 6 capas ocultas de entrada y 4 capas ocultas de salida, el accuracy en test, respecto del experimento anterior mejora, aunque sigue siendo deficiente: desciende a 0.46. En este 煤ltimo experimento, el modelo queda sesgado a la clase 1 (positiva). El recall para esa clase es 1 y la precision es 0.46, dando un F1 Score de 0.63. Dado que el modelo no asigna ning煤n ejemplo del test a las clases restantes, precision y recall es cero, quedando indefinido el F1.\n",
    "\n",
    "En s铆ntesis, en funci贸n del an谩lisis de los resultados arrojados por el clasificador en testing se puede indicar que presenta problemas de sesgo, no logrando converger a resultados estables: la realizar peque帽as variaciones en los hiperpar谩metros indicados (capas ocultas de entrada y capas ocultas de salida), el clasificador exhibe un comportamiento err谩tico; siempre sesg谩ndose hacia clases distintas en cada experimiento. Se hipotetiza que el clasificar exhibe este comportamiento por lo reducido del tama帽o del copus (pocos documentos de train y de testing). \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
